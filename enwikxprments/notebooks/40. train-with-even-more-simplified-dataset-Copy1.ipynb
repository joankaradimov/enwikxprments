{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for physical_device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_device, enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE=np.int16\n",
    "\n",
    "class Articles:\n",
    "    EMPTY_ARTICLE = np.array([], dtype=TYPE) # used for padding\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        with open(path, 'rb') as text_file:\n",
    "            data = text_file.read()\n",
    "\n",
    "        self.articles = sorted(set(data.split(b'\\0')), key=len)\n",
    "        self.articles = [np.array(list(article), dtype=TYPE) for article in self.articles]\n",
    "\n",
    "    def articles_generator(self, batch_size = 1, start = 0, end = None):\n",
    "        end = end or len(self.articles)\n",
    "\n",
    "        for _ in range(batch_size - ((end - start - 1) % batch_size + 1)):\n",
    "            yield self.EMPTY_ARTICLE\n",
    "\n",
    "        for article in itertools.islice(self.articles, start, end):\n",
    "            yield article\n",
    "\n",
    "    def subbatch_generator(self, batch_size, batch_length, start = 0, end = None):\n",
    "        end = end or len(self.articles)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(self.articles_generator, args=(batch_size, start, end), output_types=TYPE)\n",
    "        dataset = dataset.padded_batch(batch_size, padded_shapes=([None]), drop_remainder=True)\n",
    "        dataset = dataset.shuffle(100)\n",
    "\n",
    "        for batch in dataset.as_numpy_iterator():\n",
    "            remaining = batch\n",
    "            while remaining.shape[1] > batch_length + 1:\n",
    "                yield remaining[:, :batch_length + 1]\n",
    "                remaining = remaining[:, batch_length:]\n",
    "\n",
    "            if remaining.shape[1] == batch_length + 1:\n",
    "                yield remaining\n",
    "                yield np.zeros((batch_size, batch_length + 1), dtype=TYPE)\n",
    "            else:\n",
    "                yield np.hstack([remaining, np.zeros([batch_size, batch_length - remaining.shape[1] + 1])])\n",
    "\n",
    "    def steps(self, batch_size, batch_length):\n",
    "        articles = self.articles_generator(batch_size, batch_length)\n",
    "        return sum(math.ceil(len(article) / batch_length + 1) for i, article in enumerate(articles) if (i + 1) % batch_size == 0)\n",
    "\n",
    "    def dataset(self, batch_size, batch_length, start = 0, end = None):\n",
    "        end = end or len(self.articles)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(self.subbatch_generator, args=(batch_size, batch_length, start, end), output_types=TYPE, output_shapes=(batch_size, batch_length + 1))\n",
    "        return dataset.map(lambda batch: (batch[:, :-1], batch[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "def average_final_batch_ratio(true_labels, predictions):\n",
    "    return 0 ** tf.math.abs(true_labels[-1, -1])\n",
    "\n",
    "class ModelStateResetter(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.last_final_batch_count = 0\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        average_final_batch_ratio = logs.get('average_final_batch_ratio', 0)\n",
    "        final_batch_count = int(round(average_final_batch_ratio * (batch + 1)))\n",
    "        is_final = final_batch_count - self.last_final_batch_count\n",
    "        self.last_final_batch_count = final_batch_count\n",
    "        \n",
    "        if is_final:\n",
    "            self.model.reset_states()\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, articles, checkpoint_dir, vocab_size, embedding_dim, rnn_units):\n",
    "        self._articles = articles\n",
    "        self._batch_size = None\n",
    "        self._batched_item_length = None\n",
    "        self._training_model = None\n",
    "        self._predicting_model = None\n",
    "        self._vocab_size = vocab_size\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._rnn_units = rnn_units\n",
    "\n",
    "        self._checkpoint_dir = checkpoint_dir\n",
    "        self._checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\") # Name of the checkpoint files\n",
    "\n",
    "    def training_model(self, batch_size, batched_item_length):\n",
    "        if self._training_model == None or batch_size != self._batch_size or batched_item_length != self._batched_item_length:\n",
    "            self._batch_size = batch_size\n",
    "            self._batched_item_length = batched_item_length\n",
    "            self._training_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Masking(mask_value=0, batch_input_shape=[batch_size, batched_item_length]),\n",
    "                tf.keras.layers.Embedding(self._vocab_size, self._embedding_dim),\n",
    "                tf.keras.layers.LSTM(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.LSTM(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.Dense(self._vocab_size),\n",
    "            ])\n",
    "\n",
    "            if os.path.isdir(self._checkpoint_dir):\n",
    "                self._training_model.load_weights(tf.train.latest_checkpoint(self._checkpoint_dir))\n",
    "\n",
    "            self._training_model.compile(optimizer='adam', loss=loss, metrics=[average_final_batch_ratio])\n",
    "            self._predicting_model = None\n",
    "        \n",
    "        return self._training_model\n",
    "\n",
    "    @property\n",
    "    def callbacks(self):\n",
    "        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=self._checkpoint_prefix, save_weights_only=True)\n",
    "        model_state_resetter_callback = ModelStateResetter()\n",
    "        \n",
    "        return [checkpoint_callback, model_state_resetter_callback]\n",
    "    \n",
    "    def train(self, batch_size, batched_item_length, epochs=1):\n",
    "        dataset = self._articles.dataset(batch_size, batched_item_length)\n",
    "\n",
    "        model = self.training_model(batch_size, batched_item_length)\n",
    "\n",
    "        model.fit(dataset, epochs=epochs, callbacks=self.callbacks)\n",
    "    \n",
    "    @property\n",
    "    def predicting_model(self):\n",
    "        if self._predicting_model == None:\n",
    "            self._predicting_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Masking(mask_value=0, batch_input_shape=[1, 1]),\n",
    "                tf.keras.layers.Embedding(self._vocab_size, self._embedding_dim),\n",
    "                tf.keras.layers.LSTM(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.LSTM(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.Dense(self._vocab_size),\n",
    "            ])\n",
    "            \n",
    "            self._predicting_model.load_weights(tf.train.latest_checkpoint(self._checkpoint_dir))\n",
    "            self._training_model = None\n",
    "        \n",
    "        return self._predicting_model\n",
    "    \n",
    "    def predict(self, input_eval):\n",
    "        return self.predicting_model(input_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = Articles('page_revisions_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size:      4\t batch item length: 12288\tsteps per epoch: 108880\n",
      "batch size:      8\t batch item length: 6144\tsteps per epoch:  62536\n",
      "batch size:     16\t batch item length: 3072\tsteps per epoch:  39720\n",
      "batch size:     32\t batch item length: 1536\tsteps per epoch:  29133\n",
      "batch size:     64\t batch item length:  768\tsteps per epoch:  24202\n",
      "batch size:    128\t batch item length:  384\tsteps per epoch:  22296\n",
      "batch size:    256\t batch item length:  192\tsteps per epoch:  22744\n",
      "batch size:    512\t batch item length:   96\tsteps per epoch:  25706\n",
      "batch size:   1024\t batch item length:   48\tsteps per epoch:  32707\n",
      "batch size:   2048\t batch item length:   24\tsteps per epoch:  47309\n",
      "batch size:   4096\t batch item length:   12\tsteps per epoch:  76958\n",
      "batch size:   8192\t batch item length:    6\tsteps per epoch: 136758\n",
      "batch size:  16384\t batch item length:    3\tsteps per epoch: 257153\n"
     ]
    }
   ],
   "source": [
    "steps = 13\n",
    "\n",
    "for i in range(steps):\n",
    "    batch_size = 4 * 2**i\n",
    "    batch_item_length = 3 * 2**(steps - i - 1)\n",
    "    count = articles.steps(batch_size, batch_item_length)\n",
    "    print(\"batch size: %6d\\t batch item length: %4d\\tsteps per epoch: %6d\" % (batch_size, batch_item_length, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(articles, './training_checkpoints-19',\n",
    "              vocab_size=73,\n",
    "              embedding_dim=16,\n",
    "              rnn_units=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (256, 256)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (256, 256, 16)            1168      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (256, 256, 1024)          4263936   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (256, 256, 1024)          8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (256, 256, 73)            74825     \n",
      "=================================================================\n",
      "Total params: 12,732,633\n",
      "Trainable params: 12,732,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.training_model(256, 256).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16559/16559 [==============================] - 13930s 841ms/step - loss: 1.1509 - average_final_batch_ratio: 0.0513\n",
      "Epoch 2/5\n",
      "16559/16559 [==============================] - 13770s 832ms/step - loss: 0.8135 - average_final_batch_ratio: 0.0513\n",
      "Epoch 3/5\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16559/16559 [==============================] - 13906s 840ms/step - loss: 0.7659 - average_final_batch_ratio: 0.0513\n",
      "Epoch 2/3\n",
      "16559/16559 [==============================] - 13857s 837ms/step - loss: 0.7480 - average_final_batch_ratio: 0.0513\n",
      "Epoch 3/3\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Да опитаме с GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "def average_final_batch_ratio(true_labels, predictions):\n",
    "    return 0 ** tf.math.abs(true_labels[-1, -1])\n",
    "\n",
    "class ModelStateResetter(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.last_final_batch_count = 0\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        average_final_batch_ratio = logs.get('average_final_batch_ratio', 0)\n",
    "        final_batch_count = int(round(average_final_batch_ratio * (batch + 1)))\n",
    "        is_final = final_batch_count - self.last_final_batch_count\n",
    "        self.last_final_batch_count = final_batch_count\n",
    "        \n",
    "        if is_final:\n",
    "            self.model.reset_states()\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, articles, checkpoint_dir, vocab_size, embedding_dim, rnn_units):\n",
    "        self._articles = articles\n",
    "        self._batch_size = None\n",
    "        self._batched_item_length = None\n",
    "        self._training_model = None\n",
    "        self._predicting_model = None\n",
    "        self._vocab_size = vocab_size\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._rnn_units = rnn_units\n",
    "\n",
    "        self._checkpoint_dir = checkpoint_dir\n",
    "        self._checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\") # Name of the checkpoint files\n",
    "\n",
    "    def training_model(self, batch_size, batched_item_length):\n",
    "        if self._training_model == None or batch_size != self._batch_size or batched_item_length != self._batched_item_length:\n",
    "            self._batch_size = batch_size\n",
    "            self._batched_item_length = batched_item_length\n",
    "            self._training_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Masking(mask_value=0, batch_input_shape=[batch_size, batched_item_length]),\n",
    "                tf.keras.layers.Embedding(self._vocab_size, self._embedding_dim),\n",
    "                tf.keras.layers.GRU(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.GRU(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.Dense(self._vocab_size),\n",
    "            ])\n",
    "\n",
    "            if os.path.isdir(self._checkpoint_dir):\n",
    "                self._training_model.load_weights(tf.train.latest_checkpoint(self._checkpoint_dir))\n",
    "\n",
    "            self._training_model.compile(optimizer='adam', loss=loss, metrics=[average_final_batch_ratio])\n",
    "            self._predicting_model = None\n",
    "        \n",
    "        return self._training_model\n",
    "\n",
    "    @property\n",
    "    def callbacks(self):\n",
    "        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=self._checkpoint_prefix, save_weights_only=True)\n",
    "        model_state_resetter_callback = ModelStateResetter()\n",
    "        \n",
    "        return [checkpoint_callback, model_state_resetter_callback]\n",
    "    \n",
    "    def train(self, batch_size, batched_item_length, epochs=1):\n",
    "        dataset = self._articles.dataset(batch_size, batched_item_length)\n",
    "\n",
    "        model = self.training_model(batch_size, batched_item_length)\n",
    "\n",
    "        model.fit(dataset, epochs=epochs, callbacks=self.callbacks)\n",
    "    \n",
    "    @property\n",
    "    def predicting_model(self):\n",
    "        if self._predicting_model == None:\n",
    "            self._predicting_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Masking(mask_value=0, batch_input_shape=[1, 1]),\n",
    "                tf.keras.layers.Embedding(self._vocab_size, self._embedding_dim),\n",
    "                tf.keras.layers.GRU(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.GRU(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.Dense(self._vocab_size),\n",
    "            ])\n",
    "            \n",
    "            self._predicting_model.load_weights(tf.train.latest_checkpoint(self._checkpoint_dir))\n",
    "            self._training_model = None\n",
    "        \n",
    "        return self._predicting_model\n",
    "    \n",
    "    def predict(self, input_eval):\n",
    "        return self.predicting_model(input_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(articles, './training_checkpoints-20-new',\n",
    "              vocab_size=72,\n",
    "              embedding_dim=16,\n",
    "              rnn_units=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (256, 256)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (256, 256, 16)            1152      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (256, 256, 1024)          3201024   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (256, 256, 1024)          6297600   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (256, 256, 72)            73800     \n",
      "=================================================================\n",
      "Total params: 9,573,576\n",
      "Trainable params: 9,573,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.training_model(256, 256).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "16559/16559 [==============================] - 10869s 656ms/step - loss: 0.9139 - average_final_batch_ratio: 0.0513\n",
      "Epoch 2/4\n",
      "16559/16559 [==============================] - 10978s 663ms/step - loss: 0.7932 - average_final_batch_ratio: 0.0513\n",
      "Epoch 3/4\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " [_Derived_]  Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1024, 1024, 1, 256, 256, 0] \n\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\n\t [[StatefulPartitionedCall]]\n\t [[gradient_tape/sequential/embedding/embedding_lookup/Reshape/_24]] [Op:__inference_train_function_4529]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9f94ba8ab8a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-74936f3ed6d5>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, batch_size, batched_item_length, epochs)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched_item_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m:  [_Derived_]  Failed to call ThenRnnBackward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 1024, 1024, 1, 256, 256, 0] \n\t [[{{node gradients/CudnnRNN_grad/CudnnRNNBackprop}}]]\n\t [[StatefulPartitionedCall]]\n\t [[gradient_tape/sequential/embedding/embedding_lookup/Reshape/_24]] [Op:__inference_train_function_4529]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "16559/16559 [==============================] - 10828s 654ms/step - loss: 0.7729 - average_final_batch_ratio: 0.0513\n",
      "Epoch 2/2\n",
      "16559/16559 [==============================] - 10823s 654ms/step - loss: 1.3016 - average_final_batch_ratio: 0.0513\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "\n",
    "class Huffman:\n",
    "    huffman = ctypes.CDLL('x64/Release/huffman')\n",
    "    \n",
    "    huffman.create_tree.restype = ctypes.c_void_p\n",
    "    huffman.destroy_tree.restype = None\n",
    "    huffman.load_weights.restype = None\n",
    "    huffman.create_code_string.restype = ctypes.c_char_p\n",
    "    \n",
    "    def __init__(self, category_count):\n",
    "        self.category_count = category_count\n",
    "        self.tree = ctypes.c_void_p(self.huffman.create_tree(category_count))\n",
    "\n",
    "    def __del__(self):\n",
    "        self.huffman.destroy_tree(self.tree)\n",
    "        \n",
    "    def load_weights(self, weights):\n",
    "        self.huffman.load_weights(self.tree, weights.ctypes.data_as(ctypes.POINTER(ctypes.c_float)))\n",
    "    \n",
    "    def get_code_length(self, category):\n",
    "        return self.huffman.get_code_length(self.tree, category)\n",
    "\n",
    "    def get_code_zero_count(self, category):\n",
    "        return self.huffman.get_code_zero_count(self.tree, category)\n",
    "    \n",
    "    def archive_size(self, model, text):\n",
    "        archived_size = math.ceil(math.log2(self.category_count))\n",
    "        input_eval = np.array([[text[0]]], dtype=TYPE)\n",
    "\n",
    "        model.predicting_model.reset_states()\n",
    "\n",
    "        for byte in text[1:]:\n",
    "            predictions = model.predict(input_eval)\n",
    "            predictions = tf.squeeze(predictions, 0) # remove the batch dimension\n",
    "\n",
    "            weights = tf.nn.softmax(predictions[0]).numpy()\n",
    "            self.load_weights(weights)\n",
    "            archived_size += self.get_code_length(byte.item())\n",
    "\n",
    "            input_eval = tf.expand_dims([byte], 0)\n",
    "\n",
    "        return archived_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 1000:\tLength: 18\tAvg Compression: 0.270833\n",
      "Article 2000:\tLength: 19\tAvg Compression: 0.256757\n",
      "Article 3000:\tLength: 20\tAvg Compression: 0.254386\n",
      "Article 4000:\tLength: 21\tAvg Compression: 0.253205\n",
      "Article 5000:\tLength: 21\tAvg Compression: 0.253788\n",
      "Article 6000:\tLength: 22\tAvg Compression: 0.253099\n",
      "Article 7000:\tLength: 22\tAvg Compression: 0.256119\n",
      "Article 8000:\tLength: 23\tAvg Compression: 0.251506\n",
      "Article 9000:\tLength: 23\tAvg Compression: 0.250000\n",
      "Article 10000:\tLength: 24\tAvg Compression: 0.248826\n",
      "Article 11000:\tLength: 24\tAvg Compression: 0.252637\n",
      "Article 12000:\tLength: 25\tAvg Compression: 0.250954\n",
      "Article 13000:\tLength: 25\tAvg Compression: 0.251307\n",
      "Article 14000:\tLength: 26\tAvg Compression: 0.249601\n",
      "Article 15000:\tLength: 26\tAvg Compression: 0.254425\n",
      "Article 16000:\tLength: 27\tAvg Compression: 0.253415\n",
      "Article 17000:\tLength: 27\tAvg Compression: 0.258270\n",
      "Article 18000:\tLength: 27\tAvg Compression: 0.256845\n",
      "Article 19000:\tLength: 28\tAvg Compression: 0.265346\n",
      "Article 20000:\tLength: 28\tAvg Compression: 0.266282\n",
      "Article 21000:\tLength: 29\tAvg Compression: 0.263614\n",
      "Article 22000:\tLength: 29\tAvg Compression: 0.264279\n",
      "Article 23000:\tLength: 30\tAvg Compression: 0.261968\n",
      "Article 24000:\tLength: 30\tAvg Compression: 0.258838\n",
      "Article 25000:\tLength: 30\tAvg Compression: 0.258614\n",
      "Article 26000:\tLength: 31\tAvg Compression: 0.257443\n",
      "Article 27000:\tLength: 31\tAvg Compression: 0.257653\n",
      "Article 28000:\tLength: 32\tAvg Compression: 0.258182\n",
      "Article 29000:\tLength: 32\tAvg Compression: 0.259000\n",
      "Article 30000:\tLength: 33\tAvg Compression: 0.259259\n",
      "Article 31000:\tLength: 33\tAvg Compression: 0.262255\n",
      "Article 32000:\tLength: 34\tAvg Compression: 0.265294\n",
      "Article 33000:\tLength: 34\tAvg Compression: 0.267393\n",
      "Article 34000:\tLength: 35\tAvg Compression: 0.266458\n",
      "Article 35000:\tLength: 36\tAvg Compression: 0.271597\n",
      "Article 36000:\tLength: 36\tAvg Compression: 0.269046\n",
      "Article 37000:\tLength: 37\tAvg Compression: 0.267510\n",
      "Article 38000:\tLength: 38\tAvg Compression: 0.268293\n",
      "Article 39000:\tLength: 39\tAvg Compression: 0.266403\n",
      "Article 40000:\tLength: 40\tAvg Compression: 0.264956\n",
      "Article 41000:\tLength: 41\tAvg Compression: 0.262858\n",
      "Article 42000:\tLength: 42\tAvg Compression: 0.262724\n",
      "Article 43000:\tLength: 43\tAvg Compression: 0.261015\n",
      "Article 44000:\tLength: 44\tAvg Compression: 0.266540\n",
      "Article 45000:\tLength: 46\tAvg Compression: 0.264052\n",
      "Article 46000:\tLength: 48\tAvg Compression: 0.264017\n",
      "Article 47000:\tLength: 50\tAvg Compression: 0.265593\n",
      "Article 48000:\tLength: 52\tAvg Compression: 0.263484\n",
      "Article 49000:\tLength: 56\tAvg Compression: 0.265954\n",
      "Article 50000:\tLength: 60\tAvg Compression: 0.265519\n",
      "Article 51000:\tLength: 66\tAvg Compression: 0.272298\n",
      "Article 52000:\tLength: 75\tAvg Compression: 0.273261\n",
      "Article 53000:\tLength: 90\tAvg Compression: 0.273345\n",
      "Article 54000:\tLength: 110\tAvg Compression: 0.274200\n",
      "Article 55000:\tLength: 133\tAvg Compression: 0.275524\n",
      "Article 56000:\tLength: 153\tAvg Compression: 0.279059\n",
      "Article 57000:\tLength: 173\tAvg Compression: 0.278945\n",
      "Article 58000:\tLength: 196\tAvg Compression: 0.281310\n",
      "Article 59000:\tLength: 220\tAvg Compression: 0.281701\n",
      "Article 60000:\tLength: 249\tAvg Compression: 0.279350\n",
      "Article 61000:\tLength: 280\tAvg Compression: 0.279322\n",
      "Article 62000:\tLength: 314\tAvg Compression: 0.279029\n",
      "Article 63000:\tLength: 349\tAvg Compression: 0.278160\n",
      "Article 64000:\tLength: 384\tAvg Compression: 0.270791\n",
      "Article 65000:\tLength: 421\tAvg Compression: 0.265186\n",
      "Article 66000:\tLength: 458\tAvg Compression: 0.263755\n",
      "Article 67000:\tLength: 495\tAvg Compression: 0.259537\n",
      "Article 68000:\tLength: 532\tAvg Compression: 0.256344\n",
      "Article 69000:\tLength: 568\tAvg Compression: 0.259122\n",
      "Article 70000:\tLength: 598\tAvg Compression: 0.255623\n",
      "Article 71000:\tLength: 631\tAvg Compression: 0.252940\n",
      "Article 72000:\tLength: 666\tAvg Compression: 0.250484\n",
      "Article 73000:\tLength: 701\tAvg Compression: 0.250316\n",
      "Article 74000:\tLength: 738\tAvg Compression: 0.247641\n",
      "Article 75000:\tLength: 778\tAvg Compression: 0.247456\n",
      "Article 76000:\tLength: 816\tAvg Compression: 0.247663\n",
      "Article 77000:\tLength: 853\tAvg Compression: 0.250355\n",
      "Article 78000:\tLength: 891\tAvg Compression: 0.246876\n",
      "Article 79000:\tLength: 926\tAvg Compression: 0.244169\n",
      "Article 80000:\tLength: 966\tAvg Compression: 0.245350\n",
      "Article 81000:\tLength: 1007\tAvg Compression: 0.244776\n",
      "Article 82000:\tLength: 1047\tAvg Compression: 0.244382\n",
      "Article 83000:\tLength: 1086\tAvg Compression: 0.244287\n",
      "Article 84000:\tLength: 1129\tAvg Compression: 0.244468\n",
      "Article 85000:\tLength: 1168\tAvg Compression: 0.242857\n",
      "Article 86000:\tLength: 1208\tAvg Compression: 0.242608\n",
      "Article 87000:\tLength: 1251\tAvg Compression: 0.242940\n",
      "Article 88000:\tLength: 1295\tAvg Compression: 0.244812\n",
      "Article 89000:\tLength: 1339\tAvg Compression: 0.245979\n",
      "Article 90000:\tLength: 1387\tAvg Compression: 0.243840\n",
      "Article 91000:\tLength: 1430\tAvg Compression: 0.243391\n",
      "Article 92000:\tLength: 1477\tAvg Compression: 0.243024\n",
      "Article 93000:\tLength: 1524\tAvg Compression: 0.242112\n",
      "Article 94000:\tLength: 1571\tAvg Compression: 0.242719\n",
      "Article 95000:\tLength: 1616\tAvg Compression: 0.242827\n",
      "Article 96000:\tLength: 1662\tAvg Compression: 0.241075\n",
      "Article 97000:\tLength: 1711\tAvg Compression: 0.240095\n",
      "Article 98000:\tLength: 1761\tAvg Compression: 0.241514\n",
      "Article 99000:\tLength: 1810\tAvg Compression: 0.241192\n",
      "Article 100000:\tLength: 1862\tAvg Compression: 0.242428\n",
      "Article 101000:\tLength: 1915\tAvg Compression: 0.241685\n",
      "Article 102000:\tLength: 1970\tAvg Compression: 0.242353\n",
      "Article 103000:\tLength: 2026\tAvg Compression: 0.240917\n",
      "Article 104000:\tLength: 2079\tAvg Compression: 0.241074\n",
      "Article 105000:\tLength: 2133\tAvg Compression: 0.241233\n",
      "Article 106000:\tLength: 2192\tAvg Compression: 0.240096\n",
      "Article 107000:\tLength: 2249\tAvg Compression: 0.240152\n",
      "Article 108000:\tLength: 2305\tAvg Compression: 0.238447\n",
      "Article 109000:\tLength: 2358\tAvg Compression: 0.238282\n",
      "Article 110000:\tLength: 2415\tAvg Compression: 0.238583\n",
      "Article 111000:\tLength: 2457\tAvg Compression: 0.235123\n",
      "Article 112000:\tLength: 2478\tAvg Compression: 0.234972\n",
      "Article 113000:\tLength: 2501\tAvg Compression: 0.231820\n",
      "Article 114000:\tLength: 2511\tAvg Compression: 0.228897\n",
      "Article 115000:\tLength: 2520\tAvg Compression: 0.226157\n",
      "Article 116000:\tLength: 2532\tAvg Compression: 0.223654\n",
      "Article 117000:\tLength: 2546\tAvg Compression: 0.224932\n",
      "Article 118000:\tLength: 2563\tAvg Compression: 0.222626\n",
      "Article 119000:\tLength: 2578\tAvg Compression: 0.220366\n",
      "Article 120000:\tLength: 2592\tAvg Compression: 0.221111\n",
      "Article 121000:\tLength: 2603\tAvg Compression: 0.219088\n",
      "Article 122000:\tLength: 2613\tAvg Compression: 0.217162\n",
      "Article 123000:\tLength: 2621\tAvg Compression: 0.215306\n",
      "Article 124000:\tLength: 2628\tAvg Compression: 0.213577\n",
      "Article 125000:\tLength: 2636\tAvg Compression: 0.211949\n",
      "Article 126000:\tLength: 2643\tAvg Compression: 0.210471\n",
      "Article 127000:\tLength: 2652\tAvg Compression: 0.209000\n",
      "Article 128000:\tLength: 2661\tAvg Compression: 0.207660\n",
      "Article 129000:\tLength: 2672\tAvg Compression: 0.206307\n",
      "Article 130000:\tLength: 2685\tAvg Compression: 0.205064\n",
      "Article 131000:\tLength: 2697\tAvg Compression: 0.203880\n",
      "Article 132000:\tLength: 2710\tAvg Compression: 0.202720\n",
      "Article 133000:\tLength: 2725\tAvg Compression: 0.203587\n",
      "Article 134000:\tLength: 2741\tAvg Compression: 0.202475\n",
      "Article 135000:\tLength: 2760\tAvg Compression: 0.203498\n",
      "Article 136000:\tLength: 2781\tAvg Compression: 0.202615\n",
      "Article 137000:\tLength: 2804\tAvg Compression: 0.201512\n",
      "Article 138000:\tLength: 2831\tAvg Compression: 0.202922\n",
      "Article 139000:\tLength: 2860\tAvg Compression: 0.203447\n",
      "Article 140000:\tLength: 2892\tAvg Compression: 0.204214\n",
      "Article 141000:\tLength: 2927\tAvg Compression: 0.204992\n",
      "Article 142000:\tLength: 2963\tAvg Compression: 0.206115\n",
      "Article 143000:\tLength: 3005\tAvg Compression: 0.207256\n",
      "Article 144000:\tLength: 3047\tAvg Compression: 0.208376\n",
      "Article 145000:\tLength: 3092\tAvg Compression: 0.208834\n",
      "Article 146000:\tLength: 3141\tAvg Compression: 0.209607\n",
      "Article 147000:\tLength: 3192\tAvg Compression: 0.210163\n",
      "Article 148000:\tLength: 3240\tAvg Compression: 0.209451\n",
      "Article 149000:\tLength: 3290\tAvg Compression: 0.210181\n",
      "Article 150000:\tLength: 3345\tAvg Compression: 0.209382\n",
      "Article 151000:\tLength: 3398\tAvg Compression: 0.210909\n",
      "Article 152000:\tLength: 3452\tAvg Compression: 0.211191\n",
      "Article 153000:\tLength: 3509\tAvg Compression: 0.212739\n",
      "Article 154000:\tLength: 3568\tAvg Compression: 0.213873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 155000:\tLength: 3628\tAvg Compression: 0.215053\n",
      "Article 156000:\tLength: 3687\tAvg Compression: 0.215683\n",
      "Article 157000:\tLength: 3753\tAvg Compression: 0.214713\n",
      "Article 158000:\tLength: 3822\tAvg Compression: 0.214198\n",
      "Article 159000:\tLength: 3892\tAvg Compression: 0.214388\n",
      "Article 160000:\tLength: 3967\tAvg Compression: 0.214943\n",
      "Article 161000:\tLength: 4040\tAvg Compression: 0.214271\n",
      "Article 162000:\tLength: 4121\tAvg Compression: 0.214468\n",
      "Article 163000:\tLength: 4201\tAvg Compression: 0.215267\n",
      "Article 164000:\tLength: 4285\tAvg Compression: 0.215996\n",
      "Article 165000:\tLength: 4373\tAvg Compression: 0.216029\n",
      "Article 166000:\tLength: 4462\tAvg Compression: 0.216042\n",
      "Article 167000:\tLength: 4556\tAvg Compression: 0.216277\n",
      "Article 168000:\tLength: 4646\tAvg Compression: 0.217735\n",
      "Article 169000:\tLength: 4743\tAvg Compression: 0.218487\n",
      "Article 170000:\tLength: 4851\tAvg Compression: 0.218739\n",
      "Article 171000:\tLength: 4956\tAvg Compression: 0.219318\n",
      "Article 172000:\tLength: 5075\tAvg Compression: 0.218677\n",
      "Article 173000:\tLength: 5191\tAvg Compression: 0.219446\n",
      "Article 174000:\tLength: 5312\tAvg Compression: 0.219491\n",
      "Article 175000:\tLength: 5440\tAvg Compression: 0.219505\n",
      "Article 176000:\tLength: 5575\tAvg Compression: 0.219249\n",
      "Article 177000:\tLength: 5713\tAvg Compression: 0.219627\n",
      "Article 178000:\tLength: 5858\tAvg Compression: 0.219858\n",
      "Article 179000:\tLength: 6018\tAvg Compression: 0.220311\n",
      "Article 180000:\tLength: 6181\tAvg Compression: 0.220959\n",
      "Article 181000:\tLength: 6355\tAvg Compression: 0.220913\n",
      "Article 182000:\tLength: 6525\tAvg Compression: 0.221578\n",
      "Article 183000:\tLength: 6707\tAvg Compression: 0.222274\n",
      "Article 184000:\tLength: 6892\tAvg Compression: 0.221680\n",
      "Article 185000:\tLength: 7096\tAvg Compression: 0.222144\n",
      "Article 186000:\tLength: 7299\tAvg Compression: 0.223042\n",
      "Article 187000:\tLength: 7525\tAvg Compression: 0.223377\n",
      "Article 188000:\tLength: 7763\tAvg Compression: 0.223899\n",
      "Article 189000:\tLength: 7993\tAvg Compression: 0.224147\n",
      "Article 190000:\tLength: 8237\tAvg Compression: 0.224574\n",
      "Article 191000:\tLength: 8501\tAvg Compression: 0.225041\n",
      "Article 192000:\tLength: 8798\tAvg Compression: 0.225650\n",
      "Article 193000:\tLength: 9091\tAvg Compression: 0.225681\n",
      "Article 194000:\tLength: 9432\tAvg Compression: 0.225969\n",
      "Article 195000:\tLength: 9787\tAvg Compression: 0.226450\n",
      "Article 196000:\tLength: 10137\tAvg Compression: 0.226821\n",
      "Article 197000:\tLength: 10532\tAvg Compression: 0.227349\n",
      "Article 198000:\tLength: 10960\tAvg Compression: 0.227126\n",
      "Article 199000:\tLength: 11388\tAvg Compression: 0.227603\n",
      "Article 200000:\tLength: 11900\tAvg Compression: 0.228149\n",
      "Article 201000:\tLength: 12435\tAvg Compression: 0.228810\n",
      "Article 202000:\tLength: 12999\tAvg Compression: 0.228838\n",
      "Article 203000:\tLength: 13620\tAvg Compression: 0.229273\n",
      "Article 204000:\tLength: 14278\tAvg Compression: 0.228697\n",
      "Article 205000:\tLength: 15011\tAvg Compression: 0.231199\n",
      "Article 206000:\tLength: 15892\tAvg Compression: 0.231401\n",
      "Article 207000:\tLength: 16820\tAvg Compression: 0.231871\n",
      "Article 208000:\tLength: 17971\tAvg Compression: 0.232448\n",
      "Article 209000:\tLength: 19191\tAvg Compression: 0.232620\n",
      "Article 210000:\tLength: 20634\tAvg Compression: 0.234008\n",
      "Article 211000:\tLength: 22413\tAvg Compression: 0.234329\n",
      "Article 212000:\tLength: 24413\tAvg Compression: 0.234828\n",
      "Article 213000:\tLength: 26962\tAvg Compression: 0.235373\n",
      "Article 214000:\tLength: 30243\tAvg Compression: 0.236215\n",
      "Article 215000:\tLength: 34965\tAvg Compression: 0.236880\n",
      "Article 216000:\tLength: 42586\tAvg Compression: 0.237857\n",
      "Article 217000:\tLength: 63658\tAvg Compression: 0.236699\n"
     ]
    }
   ],
   "source": [
    "total_raw = 0\n",
    "total_compressed = 0\n",
    "\n",
    "huffman = Huffman(72)\n",
    "for index, article in enumerate(articles.articles_generator(1)):\n",
    "    if index % 1000 == 0:\n",
    "        if len(article) == 0:\n",
    "            continue\n",
    "        total_raw += len(article) * 8\n",
    "        total_compressed += huffman.archive_size(model, article)\n",
    "        print('Article %d:\\tLength: %d\\tAvg Compression: %f' % (index, len(article), total_compressed/total_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Да опитаме без embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "def average_final_batch_ratio(true_labels, predictions):\n",
    "    return 0 ** tf.math.abs(true_labels[-1, -1])\n",
    "\n",
    "class ModelStateResetter(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.last_final_batch_count = 0\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        average_final_batch_ratio = logs.get('average_final_batch_ratio', 0)\n",
    "        final_batch_count = int(round(average_final_batch_ratio * (batch + 1)))\n",
    "        is_final = final_batch_count - self.last_final_batch_count\n",
    "        self.last_final_batch_count = final_batch_count\n",
    "        \n",
    "        if is_final:\n",
    "            self.model.reset_states()\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, articles, checkpoint_dir, vocab_size, rnn_units):\n",
    "        self._articles = articles\n",
    "        self._batch_size = None\n",
    "        self._batched_item_length = None\n",
    "        self._training_model = None\n",
    "        self._predicting_model = None\n",
    "        self._vocab_size = vocab_size\n",
    "        self._rnn_units = rnn_units\n",
    "\n",
    "        self._checkpoint_dir = checkpoint_dir\n",
    "        self._checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\") # Name of the checkpoint files\n",
    "\n",
    "    def training_model(self, batch_size, batched_item_length):\n",
    "        if self._training_model == None or batch_size != self._batch_size or batched_item_length != self._batched_item_length:\n",
    "            self._batch_size = batch_size\n",
    "            self._batched_item_length = batched_item_length\n",
    "            self._training_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Masking(mask_value=0, batch_input_shape=[batch_size, batched_item_length]),\n",
    "                tf.keras.layers.Embedding(self._vocab_size, self._vocab_size, embeddings_initializer='identity', trainable=False, name='onehot'),\n",
    "                tf.keras.layers.LSTM(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.LSTM(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.Dense(self._vocab_size),\n",
    "            ])\n",
    "\n",
    "            if os.path.isdir(self._checkpoint_dir):\n",
    "                self._training_model.load_weights(tf.train.latest_checkpoint(self._checkpoint_dir))\n",
    "\n",
    "            self._training_model.compile(optimizer='adam', loss=loss, metrics=[average_final_batch_ratio])\n",
    "            self._predicting_model = None\n",
    "        \n",
    "        return self._training_model\n",
    "\n",
    "    @property\n",
    "    def callbacks(self):\n",
    "        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=self._checkpoint_prefix, save_weights_only=True)\n",
    "        model_state_resetter_callback = ModelStateResetter()\n",
    "        \n",
    "        return [checkpoint_callback, model_state_resetter_callback]\n",
    "    \n",
    "    def train(self, batch_size, batched_item_length, epochs=1):\n",
    "        dataset = self._articles.dataset(batch_size, batched_item_length)\n",
    "\n",
    "        model = self.training_model(batch_size, batched_item_length)\n",
    "\n",
    "        model.fit(dataset, epochs=epochs, callbacks=self.callbacks)\n",
    "    \n",
    "    @property\n",
    "    def predicting_model(self):\n",
    "        if self._predicting_model == None:\n",
    "            self._predicting_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Masking(mask_value=0, batch_input_shape=[1, 1]),\n",
    "                tf.keras.layers.Embedding(self._vocab_size, self._vocab_size, embeddings_initializer='identity', trainable=False, name='onehot'),\n",
    "                tf.keras.layers.LSTM(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.LSTM(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.Dense(self._vocab_size),\n",
    "            ])\n",
    "            \n",
    "            self._predicting_model.load_weights(tf.train.latest_checkpoint(self._checkpoint_dir))\n",
    "            self._training_model = None\n",
    "        \n",
    "        return self._predicting_model\n",
    "    \n",
    "    def predict(self, input_eval):\n",
    "        return self.predicting_model(input_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(articles, './training_checkpoints-21', vocab_size=72, rnn_units=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_4 (Masking)          (256, 256)                0         \n",
      "_________________________________________________________________\n",
      "onehot (Embedding)           (256, 256, 72)            5184      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (256, 256, 1024)          4493312   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (256, 256, 1024)          8392704   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (256, 256, 72)            73800     \n",
      "=================================================================\n",
      "Total params: 12,965,000\n",
      "Trainable params: 12,959,816\n",
      "Non-trainable params: 5,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.training_model(256, 256).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16559/16559 [==============================] - 13950s 842ms/step - loss: 2.5701 - average_final_batch_ratio: 0.0513\n",
      "Epoch 2/5\n",
      "16559/16559 [==============================] - 14001s 846ms/step - loss: 1.0843 - average_final_batch_ratio: 0.0513\n",
      "Epoch 3/5\n",
      "16559/16559 [==============================] - 14065s 849ms/step - loss: 0.9064 - average_final_batch_ratio: 0.0513\n",
      "Epoch 4/5\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "16559/16559 [==============================] - 14179s 856ms/step - loss: 0.8545 - average_final_batch_ratio: 0.0513\n",
      "Epoch 5/5\n",
      "16559/16559 [==============================] - 14228s 859ms/step - loss: 0.8258 - average_final_batch_ratio: 0.0513\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 1000:\tLength: 18\tAvg Compression: 0.270833\n",
      "Article 2000:\tLength: 19\tAvg Compression: 0.280405\n",
      "Article 3000:\tLength: 20\tAvg Compression: 0.296053\n",
      "Article 4000:\tLength: 21\tAvg Compression: 0.285256\n",
      "Article 5000:\tLength: 21\tAvg Compression: 0.281566\n",
      "Article 6000:\tLength: 22\tAvg Compression: 0.273760\n",
      "Article 7000:\tLength: 22\tAvg Compression: 0.278846\n",
      "Article 8000:\tLength: 23\tAvg Compression: 0.270331\n",
      "Article 9000:\tLength: 23\tAvg Compression: 0.269841\n",
      "Article 10000:\tLength: 24\tAvg Compression: 0.265845\n",
      "Article 11000:\tLength: 24\tAvg Compression: 0.264768\n",
      "Article 12000:\tLength: 25\tAvg Compression: 0.264790\n",
      "Article 13000:\tLength: 25\tAvg Compression: 0.264808\n",
      "Article 14000:\tLength: 26\tAvg Compression: 0.263179\n",
      "Article 15000:\tLength: 26\tAvg Compression: 0.270280\n",
      "Article 16000:\tLength: 27\tAvg Compression: 0.267418\n",
      "Article 17000:\tLength: 27\tAvg Compression: 0.270674\n",
      "Article 18000:\tLength: 27\tAvg Compression: 0.270238\n",
      "Article 19000:\tLength: 28\tAvg Compression: 0.276507\n",
      "Article 20000:\tLength: 28\tAvg Compression: 0.278624\n",
      "Article 21000:\tLength: 29\tAvg Compression: 0.274752\n",
      "Article 22000:\tLength: 29\tAvg Compression: 0.274110\n",
      "Article 23000:\tLength: 30\tAvg Compression: 0.274379\n",
      "Article 24000:\tLength: 30\tAvg Compression: 0.271465\n",
      "Article 25000:\tLength: 30\tAvg Compression: 0.271835\n",
      "Article 26000:\tLength: 31\tAvg Compression: 0.270611\n",
      "Article 27000:\tLength: 31\tAvg Compression: 0.269133\n",
      "Article 28000:\tLength: 32\tAvg Compression: 0.266365\n",
      "Article 29000:\tLength: 32\tAvg Compression: 0.266167\n",
      "Article 30000:\tLength: 33\tAvg Compression: 0.265166\n",
      "Article 31000:\tLength: 33\tAvg Compression: 0.268229\n",
      "Article 32000:\tLength: 34\tAvg Compression: 0.270882\n",
      "Article 33000:\tLength: 34\tAvg Compression: 0.273331\n",
      "Article 34000:\tLength: 35\tAvg Compression: 0.272171\n",
      "Article 35000:\tLength: 36\tAvg Compression: 0.277880\n",
      "Article 36000:\tLength: 36\tAvg Compression: 0.275227\n",
      "Article 37000:\tLength: 37\tAvg Compression: 0.273225\n",
      "Article 38000:\tLength: 38\tAvg Compression: 0.274742\n",
      "Article 39000:\tLength: 39\tAvg Compression: 0.273416\n",
      "Article 40000:\tLength: 40\tAvg Compression: 0.272162\n",
      "Article 41000:\tLength: 41\tAvg Compression: 0.270658\n",
      "Article 42000:\tLength: 42\tAvg Compression: 0.268831\n",
      "Article 43000:\tLength: 43\tAvg Compression: 0.266424\n",
      "Article 44000:\tLength: 44\tAvg Compression: 0.270342\n",
      "Article 45000:\tLength: 46\tAvg Compression: 0.268369\n",
      "Article 46000:\tLength: 48\tAvg Compression: 0.267566\n",
      "Article 47000:\tLength: 50\tAvg Compression: 0.268849\n",
      "Article 48000:\tLength: 52\tAvg Compression: 0.266876\n",
      "Article 49000:\tLength: 56\tAvg Compression: 0.269304\n",
      "Article 50000:\tLength: 60\tAvg Compression: 0.268900\n",
      "Article 51000:\tLength: 66\tAvg Compression: 0.275620\n",
      "Article 52000:\tLength: 75\tAvg Compression: 0.278068\n",
      "Article 53000:\tLength: 90\tAvg Compression: 0.277987\n",
      "Article 54000:\tLength: 110\tAvg Compression: 0.279281\n",
      "Article 55000:\tLength: 133\tAvg Compression: 0.281473\n",
      "Article 56000:\tLength: 153\tAvg Compression: 0.284106\n",
      "Article 57000:\tLength: 173\tAvg Compression: 0.285950\n",
      "Article 58000:\tLength: 196\tAvg Compression: 0.286456\n",
      "Article 59000:\tLength: 220\tAvg Compression: 0.285614\n",
      "Article 60000:\tLength: 249\tAvg Compression: 0.283918\n",
      "Article 61000:\tLength: 280\tAvg Compression: 0.283400\n",
      "Article 62000:\tLength: 314\tAvg Compression: 0.283166\n",
      "Article 63000:\tLength: 349\tAvg Compression: 0.283643\n",
      "Article 64000:\tLength: 384\tAvg Compression: 0.276759\n",
      "Article 65000:\tLength: 421\tAvg Compression: 0.272107\n",
      "Article 66000:\tLength: 458\tAvg Compression: 0.270928\n",
      "Article 67000:\tLength: 495\tAvg Compression: 0.266572\n",
      "Article 68000:\tLength: 532\tAvg Compression: 0.265356\n",
      "Article 69000:\tLength: 568\tAvg Compression: 0.268406\n",
      "Article 70000:\tLength: 598\tAvg Compression: 0.265018\n",
      "Article 71000:\tLength: 631\tAvg Compression: 0.263020\n",
      "Article 72000:\tLength: 666\tAvg Compression: 0.262190\n",
      "Article 73000:\tLength: 701\tAvg Compression: 0.261513\n",
      "Article 74000:\tLength: 738\tAvg Compression: 0.259521\n",
      "Article 75000:\tLength: 778\tAvg Compression: 0.258803\n",
      "Article 76000:\tLength: 816\tAvg Compression: 0.258618\n",
      "Article 77000:\tLength: 853\tAvg Compression: 0.262338\n",
      "Article 78000:\tLength: 891\tAvg Compression: 0.260422\n",
      "Article 79000:\tLength: 926\tAvg Compression: 0.257660\n",
      "Article 80000:\tLength: 966\tAvg Compression: 0.259357\n",
      "Article 81000:\tLength: 1007\tAvg Compression: 0.258777\n",
      "Article 82000:\tLength: 1047\tAvg Compression: 0.259137\n",
      "Article 83000:\tLength: 1086\tAvg Compression: 0.258893\n",
      "Article 84000:\tLength: 1129\tAvg Compression: 0.258795\n",
      "Article 85000:\tLength: 1168\tAvg Compression: 0.257227\n",
      "Article 86000:\tLength: 1208\tAvg Compression: 0.257465\n",
      "Article 87000:\tLength: 1251\tAvg Compression: 0.257376\n",
      "Article 88000:\tLength: 1295\tAvg Compression: 0.258804\n",
      "Article 89000:\tLength: 1339\tAvg Compression: 0.261669\n",
      "Article 90000:\tLength: 1387\tAvg Compression: 0.259087\n",
      "Article 91000:\tLength: 1430\tAvg Compression: 0.258953\n",
      "Article 92000:\tLength: 1477\tAvg Compression: 0.258689\n",
      "Article 93000:\tLength: 1524\tAvg Compression: 0.257762\n",
      "Article 94000:\tLength: 1571\tAvg Compression: 0.258172\n",
      "Article 95000:\tLength: 1616\tAvg Compression: 0.258241\n",
      "Article 96000:\tLength: 1662\tAvg Compression: 0.256224\n",
      "Article 97000:\tLength: 1711\tAvg Compression: 0.254946\n",
      "Article 98000:\tLength: 1761\tAvg Compression: 0.256168\n",
      "Article 99000:\tLength: 1810\tAvg Compression: 0.255803\n",
      "Article 100000:\tLength: 1862\tAvg Compression: 0.256964\n",
      "Article 101000:\tLength: 1915\tAvg Compression: 0.256038\n",
      "Article 102000:\tLength: 1970\tAvg Compression: 0.256543\n",
      "Article 103000:\tLength: 2026\tAvg Compression: 0.255160\n",
      "Article 104000:\tLength: 2079\tAvg Compression: 0.254992\n",
      "Article 105000:\tLength: 2133\tAvg Compression: 0.255529\n",
      "Article 106000:\tLength: 2192\tAvg Compression: 0.254382\n",
      "Article 107000:\tLength: 2249\tAvg Compression: 0.254504\n",
      "Article 108000:\tLength: 2305\tAvg Compression: 0.252835\n",
      "Article 109000:\tLength: 2358\tAvg Compression: 0.252707\n",
      "Article 110000:\tLength: 2415\tAvg Compression: 0.253045\n",
      "Article 111000:\tLength: 2457\tAvg Compression: 0.249098\n",
      "Article 112000:\tLength: 2478\tAvg Compression: 0.249318\n",
      "Article 113000:\tLength: 2501\tAvg Compression: 0.245726\n",
      "Article 114000:\tLength: 2511\tAvg Compression: 0.242371\n",
      "Article 115000:\tLength: 2520\tAvg Compression: 0.239228\n",
      "Article 116000:\tLength: 2532\tAvg Compression: 0.236311\n",
      "Article 117000:\tLength: 2546\tAvg Compression: 0.237728\n",
      "Article 118000:\tLength: 2563\tAvg Compression: 0.235058\n",
      "Article 119000:\tLength: 2578\tAvg Compression: 0.232450\n",
      "Article 120000:\tLength: 2592\tAvg Compression: 0.233395\n",
      "Article 121000:\tLength: 2603\tAvg Compression: 0.231039\n",
      "Article 122000:\tLength: 2613\tAvg Compression: 0.228890\n",
      "Article 123000:\tLength: 2621\tAvg Compression: 0.226760\n",
      "Article 124000:\tLength: 2628\tAvg Compression: 0.224810\n",
      "Article 125000:\tLength: 2636\tAvg Compression: 0.222942\n",
      "Article 126000:\tLength: 2643\tAvg Compression: 0.221263\n",
      "Article 127000:\tLength: 2652\tAvg Compression: 0.219533\n",
      "Article 128000:\tLength: 2661\tAvg Compression: 0.217904\n",
      "Article 129000:\tLength: 2672\tAvg Compression: 0.216379\n",
      "Article 130000:\tLength: 2685\tAvg Compression: 0.214893\n",
      "Article 131000:\tLength: 2697\tAvg Compression: 0.213540\n",
      "Article 132000:\tLength: 2710\tAvg Compression: 0.212198\n",
      "Article 133000:\tLength: 2725\tAvg Compression: 0.213108\n",
      "Article 134000:\tLength: 2741\tAvg Compression: 0.211815\n",
      "Article 135000:\tLength: 2760\tAvg Compression: 0.212916\n",
      "Article 136000:\tLength: 2781\tAvg Compression: 0.211908\n",
      "Article 137000:\tLength: 2804\tAvg Compression: 0.210641\n",
      "Article 138000:\tLength: 2831\tAvg Compression: 0.212097\n",
      "Article 139000:\tLength: 2860\tAvg Compression: 0.212995\n",
      "Article 140000:\tLength: 2892\tAvg Compression: 0.213763\n",
      "Article 141000:\tLength: 2927\tAvg Compression: 0.214656\n",
      "Article 142000:\tLength: 2963\tAvg Compression: 0.215781\n",
      "Article 143000:\tLength: 3005\tAvg Compression: 0.217023\n",
      "Article 144000:\tLength: 3047\tAvg Compression: 0.218344\n",
      "Article 145000:\tLength: 3092\tAvg Compression: 0.219065\n",
      "Article 146000:\tLength: 3141\tAvg Compression: 0.219984\n",
      "Article 147000:\tLength: 3192\tAvg Compression: 0.220547\n",
      "Article 148000:\tLength: 3240\tAvg Compression: 0.219624\n",
      "Article 149000:\tLength: 3290\tAvg Compression: 0.220530\n",
      "Article 150000:\tLength: 3345\tAvg Compression: 0.219564\n",
      "Article 151000:\tLength: 3398\tAvg Compression: 0.221003\n",
      "Article 152000:\tLength: 3452\tAvg Compression: 0.221377\n",
      "Article 153000:\tLength: 3509\tAvg Compression: 0.223038\n",
      "Article 154000:\tLength: 3568\tAvg Compression: 0.224167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 155000:\tLength: 3628\tAvg Compression: 0.225310\n",
      "Article 156000:\tLength: 3687\tAvg Compression: 0.225934\n",
      "Article 157000:\tLength: 3753\tAvg Compression: 0.224945\n",
      "Article 158000:\tLength: 3822\tAvg Compression: 0.224373\n",
      "Article 159000:\tLength: 3892\tAvg Compression: 0.224605\n",
      "Article 160000:\tLength: 3967\tAvg Compression: 0.225246\n",
      "Article 161000:\tLength: 4040\tAvg Compression: 0.224518\n",
      "Article 162000:\tLength: 4121\tAvg Compression: 0.224684\n",
      "Article 163000:\tLength: 4201\tAvg Compression: 0.225479\n",
      "Article 164000:\tLength: 4285\tAvg Compression: 0.226165\n",
      "Article 165000:\tLength: 4373\tAvg Compression: 0.226335\n",
      "Article 166000:\tLength: 4462\tAvg Compression: 0.226452\n",
      "Article 167000:\tLength: 4556\tAvg Compression: 0.226725\n",
      "Article 168000:\tLength: 4646\tAvg Compression: 0.228203\n",
      "Article 169000:\tLength: 4743\tAvg Compression: 0.228899\n",
      "Article 170000:\tLength: 4851\tAvg Compression: 0.229095\n",
      "Article 171000:\tLength: 4956\tAvg Compression: 0.229669\n",
      "Article 172000:\tLength: 5075\tAvg Compression: 0.228992\n",
      "Article 173000:\tLength: 5191\tAvg Compression: 0.229841\n",
      "Article 174000:\tLength: 5312\tAvg Compression: 0.229988\n",
      "Article 175000:\tLength: 5440\tAvg Compression: 0.230005\n",
      "Article 176000:\tLength: 5575\tAvg Compression: 0.229678\n",
      "Article 177000:\tLength: 5713\tAvg Compression: 0.230248\n",
      "Article 178000:\tLength: 5858\tAvg Compression: 0.230404\n",
      "Article 179000:\tLength: 6018\tAvg Compression: 0.230924\n",
      "Article 180000:\tLength: 6181\tAvg Compression: 0.231601\n",
      "Article 181000:\tLength: 6355\tAvg Compression: 0.231528\n",
      "Article 182000:\tLength: 6525\tAvg Compression: 0.232206\n",
      "Article 183000:\tLength: 6707\tAvg Compression: 0.232929\n",
      "Article 184000:\tLength: 6892\tAvg Compression: 0.232404\n",
      "Article 185000:\tLength: 7096\tAvg Compression: 0.232870\n",
      "Article 186000:\tLength: 7299\tAvg Compression: 0.233730\n",
      "Article 187000:\tLength: 7525\tAvg Compression: 0.234267\n",
      "Article 188000:\tLength: 7763\tAvg Compression: 0.234710\n",
      "Article 189000:\tLength: 7993\tAvg Compression: 0.234998\n",
      "Article 190000:\tLength: 8237\tAvg Compression: 0.235430\n",
      "Article 191000:\tLength: 8501\tAvg Compression: 0.235927\n",
      "Article 192000:\tLength: 8798\tAvg Compression: 0.236579\n",
      "Article 193000:\tLength: 9091\tAvg Compression: 0.236660\n",
      "Article 194000:\tLength: 9432\tAvg Compression: 0.236944\n",
      "Article 195000:\tLength: 9787\tAvg Compression: 0.237508\n",
      "Article 196000:\tLength: 10137\tAvg Compression: 0.237838\n",
      "Article 197000:\tLength: 10532\tAvg Compression: 0.238323\n",
      "Article 198000:\tLength: 10960\tAvg Compression: 0.238128\n",
      "Article 199000:\tLength: 11388\tAvg Compression: 0.238578\n",
      "Article 200000:\tLength: 11900\tAvg Compression: 0.239295\n",
      "Article 201000:\tLength: 12435\tAvg Compression: 0.239929\n",
      "Article 202000:\tLength: 12999\tAvg Compression: 0.239822\n",
      "Article 203000:\tLength: 13620\tAvg Compression: 0.240564\n",
      "Article 204000:\tLength: 14278\tAvg Compression: 0.239963\n",
      "Article 205000:\tLength: 15011\tAvg Compression: 0.242716\n",
      "Article 206000:\tLength: 15892\tAvg Compression: 0.242863\n",
      "Article 207000:\tLength: 16820\tAvg Compression: 0.243461\n",
      "Article 208000:\tLength: 17971\tAvg Compression: 0.244093\n",
      "Article 209000:\tLength: 19191\tAvg Compression: 0.244262\n",
      "Article 210000:\tLength: 20634\tAvg Compression: 0.245626\n",
      "Article 211000:\tLength: 22413\tAvg Compression: 0.246053\n",
      "Article 212000:\tLength: 24413\tAvg Compression: 0.246607\n",
      "Article 213000:\tLength: 26962\tAvg Compression: 0.247116\n",
      "Article 214000:\tLength: 30243\tAvg Compression: 0.248015\n",
      "Article 215000:\tLength: 34965\tAvg Compression: 0.248700\n",
      "Article 216000:\tLength: 42586\tAvg Compression: 0.249679\n",
      "Article 217000:\tLength: 63658\tAvg Compression: 0.248310\n"
     ]
    }
   ],
   "source": [
    "total_raw = 0\n",
    "total_compressed = 0\n",
    "\n",
    "huffman = Huffman(72)\n",
    "for index, article in enumerate(articles.articles_generator(1)):\n",
    "    if index % 1000 == 0:\n",
    "        if len(article) == 0:\n",
    "            continue\n",
    "        total_raw += len(article) * 8\n",
    "        total_compressed += huffman.archive_size(model, article)\n",
    "        print('Article %d:\\tLength: %d\\tAvg Compression: %f' % (index, len(article), total_compressed/total_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU без embedding слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "def average_final_batch_ratio(true_labels, predictions):\n",
    "    return 0 ** tf.math.abs(true_labels[-1, -1])\n",
    "\n",
    "class ModelStateResetter(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.last_final_batch_count = 0\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        average_final_batch_ratio = logs.get('average_final_batch_ratio', 0)\n",
    "        final_batch_count = int(round(average_final_batch_ratio * (batch + 1)))\n",
    "        is_final = final_batch_count - self.last_final_batch_count\n",
    "        self.last_final_batch_count = final_batch_count\n",
    "        \n",
    "        if is_final:\n",
    "            self.model.reset_states()\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, articles, checkpoint_dir, vocab_size, rnn_units):\n",
    "        self._articles = articles\n",
    "        self._batch_size = None\n",
    "        self._batched_item_length = None\n",
    "        self._training_model = None\n",
    "        self._predicting_model = None\n",
    "        self._vocab_size = vocab_size\n",
    "        self._rnn_units = rnn_units\n",
    "\n",
    "        self._checkpoint_dir = checkpoint_dir\n",
    "        self._checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\") # Name of the checkpoint files\n",
    "\n",
    "    def training_model(self, batch_size, batched_item_length):\n",
    "        if self._training_model == None or batch_size != self._batch_size or batched_item_length != self._batched_item_length:\n",
    "            self._batch_size = batch_size\n",
    "            self._batched_item_length = batched_item_length\n",
    "            self._training_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Masking(mask_value=0, batch_input_shape=[batch_size, batched_item_length]),\n",
    "                tf.keras.layers.Embedding(self._vocab_size, self._vocab_size, embeddings_initializer='identity', trainable=False, name='onehot'),\n",
    "                tf.keras.layers.GRU(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.GRU(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.Dense(self._vocab_size),\n",
    "            ])\n",
    "\n",
    "            if os.path.isdir(self._checkpoint_dir):\n",
    "                self._training_model.load_weights(tf.train.latest_checkpoint(self._checkpoint_dir))\n",
    "\n",
    "            self._training_model.compile(optimizer='adam', loss=loss, metrics=[average_final_batch_ratio])\n",
    "            self._predicting_model = None\n",
    "        \n",
    "        return self._training_model\n",
    "\n",
    "    @property\n",
    "    def callbacks(self):\n",
    "        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=self._checkpoint_prefix, save_weights_only=True)\n",
    "        model_state_resetter_callback = ModelStateResetter()\n",
    "        \n",
    "        return [checkpoint_callback, model_state_resetter_callback]\n",
    "    \n",
    "    def train(self, batch_size, batched_item_length, epochs=1):\n",
    "        dataset = self._articles.dataset(batch_size, batched_item_length)\n",
    "\n",
    "        model = self.training_model(batch_size, batched_item_length)\n",
    "\n",
    "        model.fit(dataset, epochs=epochs, callbacks=self.callbacks)\n",
    "    \n",
    "    @property\n",
    "    def predicting_model(self):\n",
    "        if self._predicting_model == None:\n",
    "            self._predicting_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Masking(mask_value=0, batch_input_shape=[1, 1]),\n",
    "                tf.keras.layers.Embedding(self._vocab_size, self._vocab_size, embeddings_initializer='identity', trainable=False, name='onehot'),\n",
    "                tf.keras.layers.GRU(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.GRU(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.Dense(self._vocab_size),\n",
    "            ])\n",
    "            \n",
    "            self._predicting_model.load_weights(tf.train.latest_checkpoint(self._checkpoint_dir))\n",
    "            self._training_model = None\n",
    "        \n",
    "        return self._predicting_model\n",
    "    \n",
    "    def predict(self, input_eval):\n",
    "        return self.predicting_model(input_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_7 (Masking)          (256, 256)                0         \n",
      "_________________________________________________________________\n",
      "onehot (Embedding)           (256, 256, 72)            5184      \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (256, 256, 1024)          3373056   \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (256, 256, 1024)          6297600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (256, 256, 72)            73800     \n",
      "=================================================================\n",
      "Total params: 9,749,640\n",
      "Trainable params: 9,744,456\n",
      "Non-trainable params: 5,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(articles, './training_checkpoints-22', vocab_size=72, rnn_units=1024)\n",
    "model.training_model(256, 256).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "16559/16559 [==============================] - 11186s 676ms/step - loss: 0.8801 - average_final_batch_ratio: 0.0513\n",
      "Epoch 2/4\n",
      "16559/16559 [==============================] - 11077s 669ms/step - loss: 0.7785 - average_final_batch_ratio: 0.0513\n",
      "Epoch 3/4\n",
      "16559/16559 [==============================] - 10945s 661ms/step - loss: 0.7564 - average_final_batch_ratio: 0.0513\n",
      "Epoch 4/4\n",
      "16559/16559 [==============================] - 10465s 632ms/step - loss: nan - average_final_batch_ratio: 0.0513\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (256, 256)                0         \n",
      "_________________________________________________________________\n",
      "onehot (Embedding)           (256, 256, 72)            5184      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (256, 256, 1024)          3373056   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (256, 256, 1024)          6297600   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (256, 256, 72)            73800     \n",
      "=================================================================\n",
      "Total params: 9,749,640\n",
      "Trainable params: 9,744,456\n",
      "Non-trainable params: 5,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(articles, './training_checkpoints-23', vocab_size=72, rnn_units=1024)\n",
    "model.training_model(256, 256).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "16559/16559 [==============================] - 11230s 678ms/step - loss: 0.9197 - average_final_batch_ratio: 0.0513\n",
      "Epoch 2/4\n",
      "16559/16559 [==============================] - 11163s 674ms/step - loss: 0.8101 - average_final_batch_ratio: 0.0513\n",
      "Epoch 3/4\n",
      "16559/16559 [==============================] - 11113s 671ms/step - loss: 0.7729 - average_final_batch_ratio: 0.0513\n",
      "Epoch 4/4\n",
      "    1/16559 [..............................] - ETA: 4:58:35"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run Identity: GPU sync failed [Op:Identity]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-9f94ba8ab8a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-52739733a493>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, batch_size, batched_item_length, epochs)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched_item_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m                       total_epochs=1)\n\u001b[0;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m--> 397\u001b[1;33m                                  prefix='val_')\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    769\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    990\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 992\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    993\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m       \u001b[1;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1036\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nEpoch %05d: saving model to %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1038\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1039\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave_weights\u001b[1;34m(self, filepath, overwrite, save_format)\u001b[0m\n\u001b[0;32m   1121\u001b[0m              'saved.\\n\\nConsider using a TensorFlow optimizer from `tf.train`.')\n\u001b[0;32m   1122\u001b[0m             % (optimizer,))\n\u001b[1;32m-> 1123\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m       \u001b[1;31m# Record this checkpoint so it's visible from tf.train.latest_checkpoint.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       checkpoint_management.update_checkpoint_state_internal(\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, checkpoint_number, session)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[1;32m-> 1168\u001b[1;33m         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\n\u001b[0m\u001b[0;32m   1169\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[1;34m(self, file_prefix, object_graph_tensor)\u001b[0m\n\u001b[0;32m   1114\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[0;32m   1115\u001b[0m       \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1116\u001b[1;33m       \u001b[0msave_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1117\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;31m# _SingleDeviceSaver will use the CPU device when necessary, but initial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;31m# read operations should be placed on the SaveableObject's device.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0msharded_saves\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix)\u001b[0m\n\u001b[0;32m     67\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msaveable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mtensor_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mtensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mtensor_slices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\saveable_object.py\u001b[0m in \u001b[0;36mtensor\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\saveable_object_util.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;31m# we copy them to CPU on the same machine first.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/device:CPU:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m               \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m   \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m   \u001b[1;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_handle_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   3824\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3825\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3826\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3827\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3828\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run Identity: GPU sync failed [Op:Identity]"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16559/16559 [==============================] - 11159s 674ms/step - loss: 0.7485 - average_final_batch_ratio: 0.0513\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 1000:\tLength: 18\tAvg Compression: 0.305556\n",
      "Article 2000:\tLength: 19\tAvg Compression: 0.314189\n",
      "Article 3000:\tLength: 20\tAvg Compression: 0.315789\n",
      "Article 4000:\tLength: 21\tAvg Compression: 0.350962\n",
      "Article 5000:\tLength: 21\tAvg Compression: 0.351010\n",
      "Article 6000:\tLength: 22\tAvg Compression: 0.335744\n",
      "Article 7000:\tLength: 22\tAvg Compression: 0.329545\n",
      "Article 8000:\tLength: 23\tAvg Compression: 0.323795\n",
      "Article 9000:\tLength: 23\tAvg Compression: 0.316799\n",
      "Article 10000:\tLength: 24\tAvg Compression: 0.323357\n",
      "Article 11000:\tLength: 24\tAvg Compression: 0.319620\n",
      "Article 12000:\tLength: 25\tAvg Compression: 0.316317\n",
      "Article 13000:\tLength: 25\tAvg Compression: 0.310976\n",
      "Article 14000:\tLength: 26\tAvg Compression: 0.305911\n",
      "Article 15000:\tLength: 26\tAvg Compression: 0.301991\n",
      "Article 16000:\tLength: 27\tAvg Compression: 0.300888\n",
      "Article 17000:\tLength: 27\tAvg Compression: 0.302163\n",
      "Article 18000:\tLength: 27\tAvg Compression: 0.297917\n",
      "Article 19000:\tLength: 28\tAvg Compression: 0.296038\n",
      "Article 20000:\tLength: 28\tAvg Compression: 0.294118\n",
      "Article 21000:\tLength: 29\tAvg Compression: 0.294307\n",
      "Article 22000:\tLength: 29\tAvg Compression: 0.290964\n",
      "Article 23000:\tLength: 30\tAvg Compression: 0.289672\n",
      "Article 24000:\tLength: 30\tAvg Compression: 0.287458\n",
      "Article 25000:\tLength: 30\tAvg Compression: 0.289864\n",
      "Article 26000:\tLength: 31\tAvg Compression: 0.287786\n",
      "Article 27000:\tLength: 31\tAvg Compression: 0.285532\n",
      "Article 28000:\tLength: 32\tAvg Compression: 0.285864\n",
      "Article 29000:\tLength: 32\tAvg Compression: 0.284667\n",
      "Article 30000:\tLength: 33\tAvg Compression: 0.283844\n",
      "Article 31000:\tLength: 33\tAvg Compression: 0.284773\n",
      "Article 32000:\tLength: 34\tAvg Compression: 0.284706\n",
      "Article 33000:\tLength: 34\tAvg Compression: 0.283230\n",
      "Article 34000:\tLength: 35\tAvg Compression: 0.282916\n",
      "Article 35000:\tLength: 36\tAvg Compression: 0.281414\n",
      "Article 36000:\tLength: 36\tAvg Compression: 0.279390\n",
      "Article 37000:\tLength: 37\tAvg Compression: 0.278453\n",
      "Article 38000:\tLength: 38\tAvg Compression: 0.276853\n",
      "Article 39000:\tLength: 39\tAvg Compression: 0.273869\n",
      "Article 40000:\tLength: 40\tAvg Compression: 0.273144\n",
      "Article 41000:\tLength: 41\tAvg Compression: 0.271290\n",
      "Article 42000:\tLength: 42\tAvg Compression: 0.271173\n",
      "Article 43000:\tLength: 43\tAvg Compression: 0.269375\n",
      "Article 44000:\tLength: 44\tAvg Compression: 0.269011\n",
      "Article 45000:\tLength: 46\tAvg Compression: 0.267818\n",
      "Article 46000:\tLength: 48\tAvg Compression: 0.265348\n",
      "Article 47000:\tLength: 50\tAvg Compression: 0.264736\n",
      "Article 48000:\tLength: 52\tAvg Compression: 0.262905\n",
      "Article 49000:\tLength: 56\tAvg Compression: 0.266672\n",
      "Article 50000:\tLength: 60\tAvg Compression: 0.263522\n",
      "Article 51000:\tLength: 66\tAvg Compression: 0.262847\n",
      "Article 52000:\tLength: 75\tAvg Compression: 0.262090\n",
      "Article 53000:\tLength: 90\tAvg Compression: 0.265541\n",
      "Article 54000:\tLength: 110\tAvg Compression: 0.268356\n",
      "Article 55000:\tLength: 133\tAvg Compression: 0.271656\n",
      "Article 56000:\tLength: 153\tAvg Compression: 0.275122\n",
      "Article 57000:\tLength: 173\tAvg Compression: 0.276885\n",
      "Article 58000:\tLength: 196\tAvg Compression: 0.275114\n",
      "Article 59000:\tLength: 220\tAvg Compression: 0.272599\n",
      "Article 60000:\tLength: 249\tAvg Compression: 0.274175\n",
      "Article 61000:\tLength: 280\tAvg Compression: 0.275578\n",
      "Article 62000:\tLength: 314\tAvg Compression: 0.271534\n",
      "Article 63000:\tLength: 349\tAvg Compression: 0.271283\n",
      "Article 64000:\tLength: 384\tAvg Compression: 0.273280\n",
      "Article 65000:\tLength: 421\tAvg Compression: 0.266400\n",
      "Article 66000:\tLength: 458\tAvg Compression: 0.264086\n",
      "Article 67000:\tLength: 495\tAvg Compression: 0.264328\n",
      "Article 68000:\tLength: 532\tAvg Compression: 0.259664\n",
      "Article 69000:\tLength: 568\tAvg Compression: 0.261261\n",
      "Article 70000:\tLength: 598\tAvg Compression: 0.256141\n",
      "Article 71000:\tLength: 631\tAvg Compression: 0.251939\n",
      "Article 72000:\tLength: 666\tAvg Compression: 0.248848\n",
      "Article 73000:\tLength: 701\tAvg Compression: 0.248419\n",
      "Article 74000:\tLength: 738\tAvg Compression: 0.248729\n",
      "Article 75000:\tLength: 778\tAvg Compression: 0.252022\n",
      "Article 76000:\tLength: 816\tAvg Compression: 0.250381\n",
      "Article 77000:\tLength: 853\tAvg Compression: 0.248363\n",
      "Article 78000:\tLength: 891\tAvg Compression: 0.247180\n",
      "Article 79000:\tLength: 926\tAvg Compression: 0.244798\n",
      "Article 80000:\tLength: 966\tAvg Compression: 0.244638\n",
      "Article 81000:\tLength: 1007\tAvg Compression: 0.243782\n",
      "Article 82000:\tLength: 1047\tAvg Compression: 0.242440\n",
      "Article 83000:\tLength: 1086\tAvg Compression: 0.243426\n",
      "Article 84000:\tLength: 1129\tAvg Compression: 0.241756\n",
      "Article 85000:\tLength: 1168\tAvg Compression: 0.241505\n",
      "Article 86000:\tLength: 1208\tAvg Compression: 0.241799\n",
      "Article 87000:\tLength: 1251\tAvg Compression: 0.241966\n",
      "Article 88000:\tLength: 1295\tAvg Compression: 0.240628\n",
      "Article 89000:\tLength: 1339\tAvg Compression: 0.241140\n",
      "Article 90000:\tLength: 1387\tAvg Compression: 0.242621\n",
      "Article 91000:\tLength: 1430\tAvg Compression: 0.242380\n",
      "Article 92000:\tLength: 1477\tAvg Compression: 0.242537\n",
      "Article 93000:\tLength: 1524\tAvg Compression: 0.243688\n",
      "Article 94000:\tLength: 1571\tAvg Compression: 0.243375\n",
      "Article 95000:\tLength: 1616\tAvg Compression: 0.242355\n",
      "Article 96000:\tLength: 1662\tAvg Compression: 0.239926\n",
      "Article 97000:\tLength: 1711\tAvg Compression: 0.240691\n",
      "Article 98000:\tLength: 1761\tAvg Compression: 0.240608\n",
      "Article 99000:\tLength: 1810\tAvg Compression: 0.241287\n",
      "Article 100000:\tLength: 1862\tAvg Compression: 0.241806\n",
      "Article 101000:\tLength: 1915\tAvg Compression: 0.240834\n",
      "Article 102000:\tLength: 1970\tAvg Compression: 0.241003\n",
      "Article 103000:\tLength: 2026\tAvg Compression: 0.240608\n",
      "Article 104000:\tLength: 2079\tAvg Compression: 0.239054\n",
      "Article 105000:\tLength: 2133\tAvg Compression: 0.239352\n",
      "Article 106000:\tLength: 2192\tAvg Compression: 0.240537\n",
      "Article 107000:\tLength: 2249\tAvg Compression: 0.241469\n",
      "Article 108000:\tLength: 2305\tAvg Compression: 0.241523\n",
      "Article 109000:\tLength: 2358\tAvg Compression: 0.241960\n",
      "Article 110000:\tLength: 2415\tAvg Compression: 0.241590\n",
      "Article 111000:\tLength: 2457\tAvg Compression: 0.238046\n",
      "Article 112000:\tLength: 2478\tAvg Compression: 0.237306\n",
      "Article 113000:\tLength: 2501\tAvg Compression: 0.234105\n",
      "Article 114000:\tLength: 2511\tAvg Compression: 0.231099\n",
      "Article 115000:\tLength: 2520\tAvg Compression: 0.228325\n",
      "Article 116000:\tLength: 2532\tAvg Compression: 0.225870\n",
      "Article 117000:\tLength: 2546\tAvg Compression: 0.225792\n",
      "Article 118000:\tLength: 2563\tAvg Compression: 0.226288\n",
      "Article 119000:\tLength: 2578\tAvg Compression: 0.224040\n",
      "Article 120000:\tLength: 2592\tAvg Compression: 0.221924\n",
      "Article 121000:\tLength: 2603\tAvg Compression: 0.219833\n",
      "Article 122000:\tLength: 2613\tAvg Compression: 0.217872\n",
      "Article 123000:\tLength: 2621\tAvg Compression: 0.216061\n",
      "Article 124000:\tLength: 2628\tAvg Compression: 0.214290\n",
      "Article 125000:\tLength: 2636\tAvg Compression: 0.212687\n",
      "Article 126000:\tLength: 2643\tAvg Compression: 0.211149\n",
      "Article 127000:\tLength: 2652\tAvg Compression: 0.209604\n",
      "Article 128000:\tLength: 2661\tAvg Compression: 0.210587\n",
      "Article 129000:\tLength: 2672\tAvg Compression: 0.209214\n",
      "Article 130000:\tLength: 2685\tAvg Compression: 0.207833\n",
      "Article 131000:\tLength: 2697\tAvg Compression: 0.206561\n",
      "Article 132000:\tLength: 2710\tAvg Compression: 0.205366\n",
      "Article 133000:\tLength: 2725\tAvg Compression: 0.204155\n",
      "Article 134000:\tLength: 2741\tAvg Compression: 0.204812\n",
      "Article 135000:\tLength: 2760\tAvg Compression: 0.203613\n",
      "Article 136000:\tLength: 2781\tAvg Compression: 0.204630\n",
      "Article 137000:\tLength: 2804\tAvg Compression: 0.203673\n",
      "Article 138000:\tLength: 2831\tAvg Compression: 0.204124\n",
      "Article 139000:\tLength: 2860\tAvg Compression: 0.203176\n",
      "Article 140000:\tLength: 2892\tAvg Compression: 0.202261\n",
      "Article 141000:\tLength: 2927\tAvg Compression: 0.201374\n",
      "Article 142000:\tLength: 2963\tAvg Compression: 0.202048\n",
      "Article 143000:\tLength: 3005\tAvg Compression: 0.203190\n",
      "Article 144000:\tLength: 3047\tAvg Compression: 0.203764\n",
      "Article 145000:\tLength: 3092\tAvg Compression: 0.204513\n",
      "Article 146000:\tLength: 3141\tAvg Compression: 0.204993\n",
      "Article 147000:\tLength: 3192\tAvg Compression: 0.205752\n",
      "Article 148000:\tLength: 3240\tAvg Compression: 0.204947\n",
      "Article 149000:\tLength: 3290\tAvg Compression: 0.205283\n",
      "Article 150000:\tLength: 3345\tAvg Compression: 0.204493\n",
      "Article 151000:\tLength: 3398\tAvg Compression: 0.206097\n",
      "Article 152000:\tLength: 3452\tAvg Compression: 0.206914\n",
      "Article 153000:\tLength: 3509\tAvg Compression: 0.207869\n",
      "Article 154000:\tLength: 3568\tAvg Compression: 0.209070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 155000:\tLength: 3628\tAvg Compression: 0.208545\n",
      "Article 156000:\tLength: 3687\tAvg Compression: 0.209015\n",
      "Article 157000:\tLength: 3753\tAvg Compression: 0.209741\n",
      "Article 158000:\tLength: 3822\tAvg Compression: 0.209137\n",
      "Article 159000:\tLength: 3892\tAvg Compression: 0.209859\n",
      "Article 160000:\tLength: 3967\tAvg Compression: 0.210367\n",
      "Article 161000:\tLength: 4040\tAvg Compression: 0.210346\n",
      "Article 162000:\tLength: 4121\tAvg Compression: 0.211201\n",
      "Article 163000:\tLength: 4201\tAvg Compression: 0.211453\n",
      "Article 164000:\tLength: 4285\tAvg Compression: 0.211825\n",
      "Article 165000:\tLength: 4373\tAvg Compression: 0.212595\n",
      "Article 166000:\tLength: 4462\tAvg Compression: 0.213179\n",
      "Article 167000:\tLength: 4556\tAvg Compression: 0.214475\n",
      "Article 168000:\tLength: 4646\tAvg Compression: 0.215261\n",
      "Article 169000:\tLength: 4743\tAvg Compression: 0.215590\n",
      "Article 170000:\tLength: 4851\tAvg Compression: 0.215449\n",
      "Article 171000:\tLength: 4956\tAvg Compression: 0.215686\n",
      "Article 172000:\tLength: 5075\tAvg Compression: 0.215918\n",
      "Article 173000:\tLength: 5191\tAvg Compression: 0.216776\n",
      "Article 174000:\tLength: 5312\tAvg Compression: 0.216846\n",
      "Article 175000:\tLength: 5440\tAvg Compression: 0.216363\n",
      "Article 176000:\tLength: 5575\tAvg Compression: 0.216986\n",
      "Article 177000:\tLength: 5713\tAvg Compression: 0.217682\n",
      "Article 178000:\tLength: 5858\tAvg Compression: 0.217701\n",
      "Article 179000:\tLength: 6018\tAvg Compression: 0.218367\n",
      "Article 180000:\tLength: 6181\tAvg Compression: 0.219148\n",
      "Article 181000:\tLength: 6355\tAvg Compression: 0.219334\n",
      "Article 182000:\tLength: 6525\tAvg Compression: 0.219161\n",
      "Article 183000:\tLength: 6707\tAvg Compression: 0.219227\n",
      "Article 184000:\tLength: 6892\tAvg Compression: 0.219727\n",
      "Article 185000:\tLength: 7096\tAvg Compression: 0.220177\n",
      "Article 186000:\tLength: 7299\tAvg Compression: 0.220750\n",
      "Article 187000:\tLength: 7525\tAvg Compression: 0.221033\n",
      "Article 188000:\tLength: 7763\tAvg Compression: 0.221589\n",
      "Article 189000:\tLength: 7993\tAvg Compression: 0.221861\n",
      "Article 190000:\tLength: 8237\tAvg Compression: 0.222455\n",
      "Article 191000:\tLength: 8501\tAvg Compression: 0.223276\n",
      "Article 192000:\tLength: 8798\tAvg Compression: 0.223472\n",
      "Article 193000:\tLength: 9091\tAvg Compression: 0.223405\n",
      "Article 194000:\tLength: 9432\tAvg Compression: 0.223743\n",
      "Article 195000:\tLength: 9787\tAvg Compression: 0.224662\n",
      "Article 196000:\tLength: 10137\tAvg Compression: 0.225147\n",
      "Article 197000:\tLength: 10532\tAvg Compression: 0.225704\n",
      "Article 198000:\tLength: 10960\tAvg Compression: 0.226278\n",
      "Article 199000:\tLength: 11388\tAvg Compression: 0.226403\n",
      "Article 200000:\tLength: 11900\tAvg Compression: 0.226986\n",
      "Article 201000:\tLength: 12435\tAvg Compression: 0.227576\n",
      "Article 202000:\tLength: 12999\tAvg Compression: 0.228011\n",
      "Article 203000:\tLength: 13620\tAvg Compression: 0.227918\n",
      "Article 204000:\tLength: 14278\tAvg Compression: 0.228101\n",
      "Article 205000:\tLength: 15011\tAvg Compression: 0.230641\n",
      "Article 206000:\tLength: 15892\tAvg Compression: 0.230773\n",
      "Article 207000:\tLength: 16820\tAvg Compression: 0.231256\n",
      "Article 208000:\tLength: 17971\tAvg Compression: 0.231428\n",
      "Article 209000:\tLength: 19191\tAvg Compression: 0.231618\n",
      "Article 210000:\tLength: 20634\tAvg Compression: 0.232481\n",
      "Article 211000:\tLength: 22413\tAvg Compression: 0.232824\n",
      "Article 212000:\tLength: 24413\tAvg Compression: 0.233336\n",
      "Article 213000:\tLength: 26962\tAvg Compression: 0.233907\n",
      "Article 214000:\tLength: 30243\tAvg Compression: 0.234380\n",
      "Article 215000:\tLength: 34965\tAvg Compression: 0.234922\n",
      "Article 216000:\tLength: 42586\tAvg Compression: 0.236120\n",
      "Article 217000:\tLength: 63658\tAvg Compression: 0.235014\n"
     ]
    }
   ],
   "source": [
    "total_raw = 0\n",
    "total_compressed = 0\n",
    "\n",
    "huffman = Huffman(72)\n",
    "for index, article in enumerate(articles.articles_generator(1)):\n",
    "    if index % 1000 == 0:\n",
    "        if len(article) == 0:\n",
    "            continue\n",
    "        total_raw += len(article) * 8\n",
    "        total_compressed += huffman.archive_size(model, article)\n",
    "        print('Article %d:\\tLength: %d\\tAvg Compression: %f' % (index, len(article), total_compressed/total_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16559/16559 [==============================] - 11153s 674ms/step - loss: 0.7673 - average_final_batch_ratio: 0.0513\n",
      "Epoch 2/3\n",
      "16559/16559 [==============================] - 11029s 666ms/step - loss: 1.0158 - average_final_batch_ratio: 0.0513\n",
      "Epoch 3/3\n",
      "16559/16559 [==============================] - 11017s 665ms/step - loss: 0.7773 - average_final_batch_ratio: 0.0513\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "16559/16559 [==============================] - 11143s 673ms/step - loss: 0.7909 - average_final_batch_ratio: 0.0513\n",
      "Epoch 2/3\n",
      "    1/16559 [..............................] - ETA: 4:59:41"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run Identity: GPU sync failed [Op:Identity]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2773c629ef83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-52739733a493>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, batch_size, batched_item_length, epochs)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched_item_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m                       total_epochs=1)\n\u001b[0;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m--> 397\u001b[1;33m                                  prefix='val_')\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    769\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    990\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 992\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    993\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m       \u001b[1;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1036\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nEpoch %05d: saving model to %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1038\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1039\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave_weights\u001b[1;34m(self, filepath, overwrite, save_format)\u001b[0m\n\u001b[0;32m   1121\u001b[0m              'saved.\\n\\nConsider using a TensorFlow optimizer from `tf.train`.')\n\u001b[0;32m   1122\u001b[0m             % (optimizer,))\n\u001b[1;32m-> 1123\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m       \u001b[1;31m# Record this checkpoint so it's visible from tf.train.latest_checkpoint.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       checkpoint_management.update_checkpoint_state_internal(\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, checkpoint_number, session)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[1;32m-> 1168\u001b[1;33m         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\n\u001b[0m\u001b[0;32m   1169\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[1;34m(self, file_prefix, object_graph_tensor)\u001b[0m\n\u001b[0;32m   1114\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[0;32m   1115\u001b[0m       \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1116\u001b[1;33m       \u001b[0msave_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1117\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;31m# _SingleDeviceSaver will use the CPU device when necessary, but initial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;31m# read operations should be placed on the SaveableObject's device.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0msharded_saves\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix)\u001b[0m\n\u001b[0;32m     67\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msaveable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mtensor_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mtensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mtensor_slices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\saveable_object.py\u001b[0m in \u001b[0;36mtensor\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\saveable_object_util.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;31m# we copy them to CPU on the same machine first.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/device:CPU:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m               \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m   \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m   \u001b[1;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_handle_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   3824\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3825\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3826\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3827\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3828\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run Identity: GPU sync failed [Op:Identity]"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "16559/16559 [==============================] - 11041s 667ms/step - loss: 1.4163 - average_final_batch_ratio: 0.0513\n",
      "Epoch 2/2\n",
      "16559/16559 [==============================] - 11522s 696ms/step - loss: 0.9281 - average_final_batch_ratio: 0.0513\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "16559/16559 [==============================] - 11123s 672ms/step - loss: 0.8110 - average_final_batch_ratio: 0.0513\n",
      "Epoch 2/2\n",
      "    1/16559 [..............................] - ETA: 6:56:26"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run Identity: GPU sync failed [Op:Identity]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-74b0dc6b32b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-52739733a493>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, batch_size, batched_item_length, epochs)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched_item_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m                       total_epochs=1)\n\u001b[0;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m--> 397\u001b[1;33m                                  prefix='val_')\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    769\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    990\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 992\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    993\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m       \u001b[1;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1036\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nEpoch %05d: saving model to %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1038\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1039\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave_weights\u001b[1;34m(self, filepath, overwrite, save_format)\u001b[0m\n\u001b[0;32m   1121\u001b[0m              'saved.\\n\\nConsider using a TensorFlow optimizer from `tf.train`.')\n\u001b[0;32m   1122\u001b[0m             % (optimizer,))\n\u001b[1;32m-> 1123\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m       \u001b[1;31m# Record this checkpoint so it's visible from tf.train.latest_checkpoint.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       checkpoint_management.update_checkpoint_state_internal(\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, checkpoint_number, session)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[1;32m-> 1168\u001b[1;33m         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\n\u001b[0m\u001b[0;32m   1169\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[1;34m(self, file_prefix, object_graph_tensor)\u001b[0m\n\u001b[0;32m   1114\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[0;32m   1115\u001b[0m       \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1116\u001b[1;33m       \u001b[0msave_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1117\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;31m# _SingleDeviceSaver will use the CPU device when necessary, but initial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;31m# read operations should be placed on the SaveableObject's device.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0msharded_saves\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix)\u001b[0m\n\u001b[0;32m     67\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msaveable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mtensor_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mtensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mtensor_slices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\saveable_object.py\u001b[0m in \u001b[0;36mtensor\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\saveable_object_util.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;31m# we copy them to CPU on the same machine first.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/device:CPU:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m               \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m   \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m   \u001b[1;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_handle_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   3824\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3825\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3826\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3827\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3828\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run Identity: GPU sync failed [Op:Identity]"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "21170/21170 [==============================] - 11198s 529ms/step - loss: 0.8066 - average_final_batch_ratio: 0.0535\n",
      "Epoch 2/2\n",
      "    1/21170 [..............................] - ETA: 4:36:36"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run Identity: GPU sync failed [Op:Identity]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c38e405741df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m192\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-52739733a493>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, batch_size, batched_item_length, epochs)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched_item_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m                       total_epochs=1)\n\u001b[0;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m--> 397\u001b[1;33m                                  prefix='val_')\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    769\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    990\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 992\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    993\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    994\u001b[0m       \u001b[1;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1036\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nEpoch %05d: saving model to %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1038\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1039\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave_weights\u001b[1;34m(self, filepath, overwrite, save_format)\u001b[0m\n\u001b[0;32m   1121\u001b[0m              'saved.\\n\\nConsider using a TensorFlow optimizer from `tf.train`.')\n\u001b[0;32m   1122\u001b[0m             % (optimizer,))\n\u001b[1;32m-> 1123\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m       \u001b[1;31m# Record this checkpoint so it's visible from tf.train.latest_checkpoint.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       checkpoint_management.update_checkpoint_state_internal(\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, checkpoint_number, session)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[1;32m-> 1168\u001b[1;33m         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\n\u001b[0m\u001b[0;32m   1169\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[1;34m(self, file_prefix, object_graph_tensor)\u001b[0m\n\u001b[0;32m   1114\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[0;32m   1115\u001b[0m       \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1116\u001b[1;33m       \u001b[0msave_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1117\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;31m# _SingleDeviceSaver will use the CPU device when necessary, but initial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;31m# read operations should be placed on the SaveableObject's device.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0msharded_saves\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix)\u001b[0m\n\u001b[0;32m     67\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msaveable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mtensor_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mtensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mtensor_slices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\saveable_object.py\u001b[0m in \u001b[0;36mtensor\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\saveable_object_util.py\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[1;31m# we copy them to CPU on the same machine first.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/device:CPU:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m               \u001b[1;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m   \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m   \u001b[1;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_handle_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   3824\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3825\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3826\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3827\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3828\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:GPU:0 to /job:localhost/replica:0/task:0/device:CPU:0 in order to run Identity: GPU sync failed [Op:Identity]"
     ]
    }
   ],
   "source": [
    "model.train(192, 256, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "21170/21170 [==============================] - 11319s 535ms/step - loss: 1.5496 - average_final_batch_ratio: 0.0535\n"
     ]
    }
   ],
   "source": [
    "model.train(192, 256, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Повече слоеве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "def average_final_batch_ratio(true_labels, predictions):\n",
    "    return 0 ** tf.math.abs(true_labels[-1, -1])\n",
    "\n",
    "class ModelStateResetter(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.last_final_batch_count = 0\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        average_final_batch_ratio = logs.get('average_final_batch_ratio', 0)\n",
    "        final_batch_count = int(round(average_final_batch_ratio * (batch + 1)))\n",
    "        is_final = final_batch_count - self.last_final_batch_count\n",
    "        self.last_final_batch_count = final_batch_count\n",
    "        \n",
    "        if is_final:\n",
    "            self.model.reset_states()\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, articles, checkpoint_dir, vocab_size, rnn_units):\n",
    "        self._articles = articles\n",
    "        self._batch_size = None\n",
    "        self._batched_item_length = None\n",
    "        self._training_model = None\n",
    "        self._predicting_model = None\n",
    "        self._vocab_size = vocab_size\n",
    "        self._rnn_units = rnn_units\n",
    "\n",
    "        self._checkpoint_dir = checkpoint_dir\n",
    "        self._checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\") # Name of the checkpoint files\n",
    "\n",
    "    def training_model(self, batch_size, batched_item_length):\n",
    "        if self._training_model == None or batch_size != self._batch_size or batched_item_length != self._batched_item_length:\n",
    "            self._batch_size = batch_size\n",
    "            self._batched_item_length = batched_item_length\n",
    "            self._training_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Masking(mask_value=0, batch_input_shape=[batch_size, batched_item_length]),\n",
    "                tf.keras.layers.Embedding(self._vocab_size, self._vocab_size, embeddings_initializer='identity', trainable=False, name='onehot'),\n",
    "                tf.keras.layers.GRU(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.GRU(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.GRU(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.GRU(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.Dense(self._vocab_size),\n",
    "            ])\n",
    "\n",
    "            if os.path.isdir(self._checkpoint_dir):\n",
    "                self._training_model.load_weights(tf.train.latest_checkpoint(self._checkpoint_dir))\n",
    "\n",
    "            self._training_model.compile(optimizer='adam', loss=loss, metrics=[average_final_batch_ratio])\n",
    "            self._predicting_model = None\n",
    "        \n",
    "        return self._training_model\n",
    "\n",
    "    @property\n",
    "    def callbacks(self):\n",
    "        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=self._checkpoint_prefix, save_weights_only=True)\n",
    "        model_state_resetter_callback = ModelStateResetter()\n",
    "        \n",
    "        return [checkpoint_callback, model_state_resetter_callback]\n",
    "    \n",
    "    def train(self, batch_size, batched_item_length, epochs=1):\n",
    "        dataset = self._articles.dataset(batch_size, batched_item_length)\n",
    "\n",
    "        model = self.training_model(batch_size, batched_item_length)\n",
    "\n",
    "        model.fit(dataset, epochs=epochs, callbacks=self.callbacks)\n",
    "    \n",
    "    @property\n",
    "    def predicting_model(self):\n",
    "        if self._predicting_model == None:\n",
    "            self._predicting_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Masking(mask_value=0, batch_input_shape=[1, 1]),\n",
    "                tf.keras.layers.Embedding(self._vocab_size, self._vocab_size, embeddings_initializer='identity', trainable=False, name='onehot'),\n",
    "                tf.keras.layers.GRU(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.GRU(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.GRU(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.GRU(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.Dense(self._vocab_size),\n",
    "            ])\n",
    "            \n",
    "            self._predicting_model.load_weights(tf.train.latest_checkpoint(self._checkpoint_dir))\n",
    "            self._training_model = None\n",
    "        \n",
    "        return self._predicting_model\n",
    "    \n",
    "    def predict(self, input_eval):\n",
    "        return self.predicting_model(input_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_1 (Masking)          (192, 256)                0         \n",
      "_________________________________________________________________\n",
      "onehot (Embedding)           (192, 256, 72)            5184      \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (192, 256, 768)           1939968   \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (192, 256, 768)           3543552   \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (192, 256, 768)           3543552   \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (192, 256, 768)           3543552   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (192, 256, 72)            55368     \n",
      "=================================================================\n",
      "Total params: 12,631,176\n",
      "Trainable params: 12,625,992\n",
      "Non-trainable params: 5,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(articles, './training_checkpoints-24', vocab_size=72, rnn_units=768)\n",
    "model.training_model(192, 256).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "21170/21170 [==============================] - 15734s 743ms/step - loss: 0.9465 - average_final_batch_ratio: 0.0535\n",
      "Epoch 2/5\n",
      "21170/21170 [==============================] - 15321s 724ms/step - loss: 0.8606 - average_final_batch_ratio: 0.0535\n",
      "Epoch 3/5\n",
      "21170/21170 [==============================] - 15679s 741ms/step - loss: 0.9088 - average_final_batch_ratio: 0.0535\n",
      "Epoch 4/5\n",
      "21170/21170 [==============================] - 15523s 733ms/step - loss: nan - average_final_batch_ratio: 0.0535\n",
      "Epoch 5/5\n",
      "    8/21170 [..............................] - ETA: 4:47:11 - loss: nan - average_final_batch_ratio: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-541c435af55b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m192\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-863c4674bcc9>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, batch_size, batched_item_length, epochs)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched_item_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m   \u001b[0mconstant_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[1;34m(tensor, partial)\u001b[0m\n\u001b[0;32m    820\u001b[0m   \"\"\"\n\u001b[0;32m    821\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    940\u001b[0m     \"\"\"\n\u001b[0;32m    941\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(192, 256, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
