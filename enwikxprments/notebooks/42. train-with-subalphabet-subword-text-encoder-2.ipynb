{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "import re\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "class SubalphabetSubwordTextEncoder:\n",
    "    HTML_ESCAPE_PATTERN = re.compile('&(((#\\d+)|([A-Za-z]+));&?)+')\n",
    "    SPECIAL_CHAR = 'X'\n",
    "\n",
    "    def __init__(self, subalphabet, vocab_list=None):\n",
    "        self._subword_text_encoder = tfds.features.text.SubwordTextEncoder(vocab_list)\n",
    "        self._subalphabet = subalphabet\n",
    "\n",
    "    def encode(self, s):\n",
    "        subword_max_code = len(self.subwords)\n",
    "        codes = self._build_encoding_dict(self._subalphabet)\n",
    "        preprocessed_string = self.preprocess_string(s)\n",
    "\n",
    "        result = []\n",
    "        unicode_buffer = bytearray()\n",
    "        for id in self._subword_text_encoder.encode(preprocessed_string):\n",
    "            if id <= subword_max_code:\n",
    "                result.append(id)\n",
    "            else:\n",
    "                unicode_buffer.append(id - subword_max_code - 1)\n",
    "                try:\n",
    "                    id = ord(unicode_buffer.decode())\n",
    "                    result.append(subword_max_code + codes[id] + 1)\n",
    "                    unicode_buffer = bytearray()\n",
    "                except UnicodeDecodeError:\n",
    "                    pass\n",
    "        return result\n",
    "\n",
    "    def decode(self, ids):\n",
    "        subword_max_code = len(self.subwords)\n",
    "\n",
    "        processed_ids = []\n",
    "        for id in ids:\n",
    "            if id <= subword_max_code:\n",
    "                processed_ids.append(id)\n",
    "            else:\n",
    "                char = self._subalphabet[id - subword_max_code - 1].encode()\n",
    "                processed_ids += [codepoint + subword_max_code + 1 for codepoint in char]\n",
    "\n",
    "        return self._subword_text_encoder.decode(processed_ids)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_from_corpus(cls, corpus_generator, subalphabet_size, target_vocab_size, max_subword_length=20, max_corpus_chars=None, reserved_tokens=None):\n",
    "        simplified_strings = []\n",
    "        char_counts = defaultdict(lambda: 0)\n",
    "\n",
    "        for string in corpus_generator:\n",
    "            simplified_string = cls._unescape_string(string.lower())\n",
    "            simplified_strings.append(simplified_string)\n",
    "            for char in simplified_string:\n",
    "                char_counts[char] += 1\n",
    "\n",
    "        sorted_char_counts = sorted(char_counts.items(), key = lambda item: item[1], reverse = True)\n",
    "        chars = [char for char, char_count in sorted_char_counts[:subalphabet_size - 1]]\n",
    "        chars = list(reversed(chars)) # We reverse the chars so that the most common ones are last\n",
    "        chars = cls._ensure_special_character_presence(chars)\n",
    "\n",
    "        def simplified_corpus():\n",
    "            for string in simplified_strings:\n",
    "                yield cls._compact_string(chars, string)\n",
    "\n",
    "        subword_text_encoder = tfds.features.text.SubwordTextEncoder.build_from_corpus(simplified_corpus(), target_vocab_size + 256 - subalphabet_size)\n",
    "        \n",
    "        return cls(chars, subword_text_encoder.subwords)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_from_file(cls, filename_prefix):\n",
    "        subword_text_encoder = tfds.features.text.SubwordTextEncoder.load_from_file(filename_prefix)\n",
    "        with open(filename_prefix + '.subalphabet', 'rb') as text_file:\n",
    "            subalphabet = ['\\0', cls.SPECIAL_CHAR] + text_file.read().decode().split('\\0')\n",
    "\n",
    "        return cls(subalphabet, subword_text_encoder.subwords)\n",
    "    \n",
    "    def save_to_file(self, filename_prefix):\n",
    "        self._subword_text_encoder.save_to_file(filename_prefix)\n",
    "        with open(filename_prefix + '.subalphabet', 'wb') as text_file:\n",
    "            text_file.write('\\0'.join(self._subalphabet[2:]).encode())\n",
    "\n",
    "    def preprocess_string(self, string):\n",
    "        return self._compact_string(self._subalphabet, self._unescape_string(string.lower()))\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return self._subword_text_encoder.vocab_size - 256 + len(self._subalphabet)\n",
    "    \n",
    "    @property\n",
    "    def subwords(self):\n",
    "        return self._subword_text_encoder.subwords\n",
    "\n",
    "    @classmethod\n",
    "    def _ensure_special_character_presence(cls, chars):\n",
    "        if '\\0' in chars:\n",
    "            chars = [char for char in chars if char != '\\0']\n",
    "        else:\n",
    "            chars = chars[1:]\n",
    "\n",
    "        return ['\\0', cls.SPECIAL_CHAR] + chars\n",
    "    \n",
    "    @classmethod\n",
    "    def _unescape_html_symbol(cls, escaped):\n",
    "        escaped_symbols = escaped.group(0).split(';')\n",
    "        escaped_symbols = escaped_symbols[:-1] # strip the last string empty string\n",
    "        escaped_symbols = (escaped_symbol + ';' for escaped_symbol in escaped_symbols)\n",
    "        result = ''\n",
    "\n",
    "        for escaped_symbol in escaped_symbols:\n",
    "            code = escaped_symbol[1:] if escaped_symbol[0] == '&' else escaped_symbol\n",
    "\n",
    "            if code[0] == '#':\n",
    "                result += chr(int(code[1:-1]))\n",
    "            elif code in html.entities.html5:\n",
    "                result += html.entities.html5[code]\n",
    "            else:\n",
    "                result += escaped_symbol\n",
    "\n",
    "        return result\n",
    "    \n",
    "    @classmethod\n",
    "    def _unescape_string(cls, string):\n",
    "        return cls.HTML_ESCAPE_PATTERN.sub(cls._unescape_html_symbol, string)\n",
    "    \n",
    "    @classmethod\n",
    "    def _compact_string(cls, chars, string):\n",
    "        if len(string) == 0:\n",
    "            return string\n",
    "        else:\n",
    "            compacted_string = string[0]\n",
    "\n",
    "            for char in string[1:]:\n",
    "                if char not in chars or char == cls.SPECIAL_CHAR:\n",
    "                    if compacted_string[-1] != cls.SPECIAL_CHAR:\n",
    "                        compacted_string += cls.SPECIAL_CHAR\n",
    "                else:\n",
    "                    compacted_string += char\n",
    "\n",
    "            return compacted_string\n",
    "    \n",
    "    @classmethod\n",
    "    def _build_encoding_dict(cls, chars):\n",
    "        return {ord(char): index for index, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SubalphabetSubwordTextEncoder.load_from_file('72_256')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for physical_device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_device, enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE=np.int16\n",
    "\n",
    "class Articles:\n",
    "    EMPTY_ARTICLE = np.array([], dtype=TYPE) # used for padding\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        with open(path, 'rb') as text_file:\n",
    "            data = text_file.read().decode()\n",
    "\n",
    "        self.articles = sorted(set(data.split('\\0')[:20000]), key=len)\n",
    "        self._encoded_articles = None\n",
    "\n",
    "    @property\n",
    "    def encoded_articles(self):\n",
    "        if self._encoded_articles == None:\n",
    "            self._encoded_articles = [np.array(encoder.encode(article), dtype=TYPE) for article in self.articles]\n",
    "        \n",
    "        return self._encoded_articles\n",
    "\n",
    "    def articles_generator(self, batch_size = 1, start = 0, end = None):\n",
    "        end = end or len(self.articles)\n",
    "\n",
    "        for _ in range(batch_size - ((end - start - 1) % batch_size + 1)):\n",
    "            yield self.EMPTY_ARTICLE\n",
    "\n",
    "        for article in itertools.islice(self.encoded_articles, start, end):\n",
    "            yield article\n",
    "\n",
    "    def subbatch_generator(self, batch_size, batch_length, start = 0, end = None):\n",
    "        end = end or len(self.articles)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(self.articles_generator, args=(batch_size, start, end), output_types=TYPE)\n",
    "        dataset = dataset.padded_batch(batch_size, padded_shapes=([None]), drop_remainder=True)\n",
    "        dataset = dataset.shuffle(100)\n",
    "\n",
    "        for batch in dataset.as_numpy_iterator():\n",
    "            remaining = batch\n",
    "            while remaining.shape[1] > batch_length + 1:\n",
    "                yield remaining[:, :batch_length + 1]\n",
    "                remaining = remaining[:, batch_length:]\n",
    "\n",
    "            if remaining.shape[1] == batch_length + 1:\n",
    "                yield remaining\n",
    "                yield np.zeros((batch_size, batch_length + 1), dtype=TYPE)\n",
    "            else:\n",
    "                yield np.hstack([remaining, np.zeros([batch_size, batch_length - remaining.shape[1] + 1])])\n",
    "\n",
    "    def steps(self, batch_size, batch_length):\n",
    "        articles = self.articles_generator(batch_size, batch_length)\n",
    "        return sum(math.ceil(len(article) / batch_length + 1) for i, article in enumerate(articles) if (i + 1) % batch_size == 0)\n",
    "\n",
    "    def dataset(self, batch_size, batch_length, start = 0, end = None):\n",
    "        end = end or len(self.articles)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(self.subbatch_generator, args=(batch_size, batch_length, start, end), output_types=TYPE, output_shapes=(batch_size, batch_length + 1))\n",
    "        return dataset.map(lambda batch: (batch[:, :-1], batch[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "def average_final_batch_ratio(true_labels, predictions):\n",
    "    return 0 ** tf.math.abs(true_labels[-1, -1])\n",
    "\n",
    "class ModelStateResetter(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.last_final_batch_count = 0\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        average_final_batch_ratio = logs.get('average_final_batch_ratio', 0)\n",
    "        final_batch_count = int(round(average_final_batch_ratio * (batch + 1)))\n",
    "        is_final = final_batch_count - self.last_final_batch_count\n",
    "        self.last_final_batch_count = final_batch_count\n",
    "        \n",
    "        if is_final:\n",
    "            self.model.reset_states()\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, articles, checkpoint_dir, vocab_size, embedding_dim, rnn_units):\n",
    "        self._articles = articles\n",
    "        self._batch_size = None\n",
    "        self._batched_item_length = None\n",
    "        self._training_model = None\n",
    "        self._predicting_model = None\n",
    "        self._vocab_size = vocab_size\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._rnn_units = rnn_units\n",
    "\n",
    "        self._checkpoint_dir = checkpoint_dir\n",
    "        self._checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\") # Name of the checkpoint files\n",
    "\n",
    "    def training_model(self, batch_size, batched_item_length):\n",
    "        if self._training_model == None or batch_size != self._batch_size or batched_item_length != self._batched_item_length:\n",
    "            self._batch_size = batch_size\n",
    "            self._batched_item_length = batched_item_length\n",
    "            self._training_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Masking(mask_value=0, batch_input_shape=[batch_size, batched_item_length]),\n",
    "                tf.keras.layers.Embedding(self._vocab_size, self._embedding_dim),\n",
    "                tf.keras.layers.GRU(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.GRU(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.GRU(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.GRU(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.Dense(self._vocab_size),\n",
    "            ])\n",
    "\n",
    "            if os.path.isdir(self._checkpoint_dir):\n",
    "                self._training_model.load_weights(tf.train.latest_checkpoint(self._checkpoint_dir))\n",
    "\n",
    "            self._training_model.compile(optimizer='adam', loss=loss, metrics=[average_final_batch_ratio])\n",
    "            self._predicting_model = None\n",
    "        \n",
    "        return self._training_model\n",
    "\n",
    "    @property\n",
    "    def callbacks(self):\n",
    "        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=self._checkpoint_prefix, save_weights_only=True)\n",
    "        model_state_resetter_callback = ModelStateResetter()\n",
    "        \n",
    "        return [checkpoint_callback, model_state_resetter_callback]\n",
    "    \n",
    "    def train(self, batch_size, batched_item_length, epochs=1):\n",
    "        dataset = self._articles.dataset(batch_size, batched_item_length)\n",
    "\n",
    "        model = self.training_model(batch_size, batched_item_length)\n",
    "\n",
    "        model.fit(dataset, epochs=epochs, callbacks=self.callbacks)\n",
    "    \n",
    "    @property\n",
    "    def predicting_model(self):\n",
    "        if self._predicting_model == None:\n",
    "            self._predicting_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Masking(mask_value=0, batch_input_shape=[1, 1]),\n",
    "                tf.keras.layers.Embedding(self._vocab_size, self._embedding_dim),\n",
    "                tf.keras.layers.GRU(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.GRU(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.GRU(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.GRU(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.Dense(self._vocab_size),\n",
    "            ])\n",
    "            \n",
    "            self._predicting_model.load_weights(tf.train.latest_checkpoint(self._checkpoint_dir))\n",
    "            self._training_model = None\n",
    "        \n",
    "        return self._predicting_model\n",
    "    \n",
    "    def predict(self, input_eval):\n",
    "        return self.predicting_model(input_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = Articles('page_revisions_text_with_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(articles, './training_checkpoints-26', vocab_size = encoder.vocab_size, embedding_dim=64, rnn_units=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (256, 256)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (256, 256, 64)            16320     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (256, 256, 512)           887808    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (256, 256, 512)           1575936   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (256, 256, 512)           1575936   \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (256, 256, 512)           1575936   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (256, 256, 255)           130815    \n",
      "=================================================================\n",
      "Total params: 5,762,751\n",
      "Trainable params: 5,762,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.training_model(256, 256).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1902/1902 [==============================] - 1116s 587ms/step - loss: 2.6060 - average_final_batch_ratio: 0.1646\n",
      "Epoch 2/30\n",
      "1902/1902 [==============================] - 895s 471ms/step - loss: 1.8007 - average_final_batch_ratio: 0.1646\n",
      "Epoch 3/30\n",
      "1902/1902 [==============================] - 901s 474ms/step - loss: 1.6343 - average_final_batch_ratio: 0.1646\n",
      "Epoch 4/30\n",
      "1902/1902 [==============================] - 892s 469ms/step - loss: 1.5545 - average_final_batch_ratio: 0.1646\n",
      "Epoch 5/30\n",
      "1902/1902 [==============================] - 898s 472ms/step - loss: 1.5133 - average_final_batch_ratio: 0.1646\n",
      "Epoch 6/30\n",
      "1902/1902 [==============================] - 901s 474ms/step - loss: 1.4781 - average_final_batch_ratio: 0.1646\n",
      "Epoch 7/30\n",
      "1902/1902 [==============================] - 885s 465ms/step - loss: 1.4568 - average_final_batch_ratio: 0.1646\n",
      "Epoch 8/30\n",
      "1902/1902 [==============================] - 918s 483ms/step - loss: 1.4347 - average_final_batch_ratio: 0.1646\n",
      "Epoch 9/30\n",
      "1902/1902 [==============================] - 888s 467ms/step - loss: 1.4177 - average_final_batch_ratio: 0.1646\n",
      "Epoch 10/30\n",
      "1902/1902 [==============================] - 894s 470ms/step - loss: 1.4050 - average_final_batch_ratio: 0.1646\n",
      "Epoch 11/30\n",
      "1902/1902 [==============================] - 891s 468ms/step - loss: 1.3930 - average_final_batch_ratio: 0.1646\n",
      "Epoch 12/30\n",
      "1902/1902 [==============================] - 897s 471ms/step - loss: 1.3801 - average_final_batch_ratio: 0.1646\n",
      "Epoch 13/30\n",
      "1902/1902 [==============================] - 910s 478ms/step - loss: 1.3720 - average_final_batch_ratio: 0.1646\n",
      "Epoch 14/30\n",
      "1902/1902 [==============================] - 900s 473ms/step - loss: 1.3648 - average_final_batch_ratio: 0.1646\n",
      "Epoch 15/30\n",
      "1902/1902 [==============================] - 900s 473ms/step - loss: 1.3577 - average_final_batch_ratio: 0.1646\n",
      "Epoch 16/30\n",
      "1902/1902 [==============================] - 880s 463ms/step - loss: 1.3490 - average_final_batch_ratio: 0.1646\n",
      "Epoch 17/30\n",
      "1902/1902 [==============================] - 894s 470ms/step - loss: 1.3438 - average_final_batch_ratio: 0.1646\n",
      "Epoch 18/30\n",
      "1902/1902 [==============================] - 891s 468ms/step - loss: 1.3392 - average_final_batch_ratio: 0.1646\n",
      "Epoch 19/30\n",
      "1902/1902 [==============================] - 899s 473ms/step - loss: 1.3325 - average_final_batch_ratio: 0.1646\n",
      "Epoch 20/30\n",
      "1902/1902 [==============================] - 902s 474ms/step - loss: 1.3297 - average_final_batch_ratio: 0.1646\n",
      "Epoch 21/30\n",
      "1902/1902 [==============================] - 885s 465ms/step - loss: 1.3252 - average_final_batch_ratio: 0.1646\n",
      "Epoch 22/30\n",
      "1902/1902 [==============================] - 907s 477ms/step - loss: 1.3333 - average_final_batch_ratio: 0.1646\n",
      "Epoch 23/30\n",
      "1902/1902 [==============================] - 889s 467ms/step - loss: 1.3233 - average_final_batch_ratio: 0.1646\n",
      "Epoch 24/30\n",
      "1902/1902 [==============================] - 904s 475ms/step - loss: 1.3160 - average_final_batch_ratio: 0.1646\n",
      "Epoch 25/30\n",
      "1902/1902 [==============================] - 912s 480ms/step - loss: 1.3089 - average_final_batch_ratio: 0.1646\n",
      "Epoch 26/30\n",
      "1902/1902 [==============================] - 909s 478ms/step - loss: 1.3114 - average_final_batch_ratio: 0.1646\n",
      "Epoch 27/30\n",
      "1902/1902 [==============================] - 912s 479ms/step - loss: 1.3245 - average_final_batch_ratio: 0.1646\n",
      "Epoch 28/30\n",
      "1902/1902 [==============================] - 906s 476ms/step - loss: 1.4646 - average_final_batch_ratio: 0.1646\n",
      "Epoch 29/30\n",
      "1902/1902 [==============================] - 928s 488ms/step - loss: 1.4128 - average_final_batch_ratio: 0.1646\n",
      "Epoch 30/30\n",
      "1902/1902 [==============================] - 914s 480ms/step - loss: 1.3931 - average_final_batch_ratio: 0.1646\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1902/1902 [==============================] - 906s 476ms/step - loss: 1.3793 - average_final_batch_ratio: 0.1646\n",
      "Epoch 2/10\n",
      "1902/1902 [==============================] - 905s 476ms/step - loss: 1.4925 - average_final_batch_ratio: 0.1646\n",
      "Epoch 3/10\n",
      "1902/1902 [==============================] - 907s 477ms/step - loss: 1.4661 - average_final_batch_ratio: 0.1646\n",
      "Epoch 4/10\n",
      "1902/1902 [==============================] - 911s 479ms/step - loss: 1.4477 - average_final_batch_ratio: 0.1646\n",
      "Epoch 5/10\n",
      "1902/1902 [==============================] - 894s 470ms/step - loss: 1.4336 - average_final_batch_ratio: 0.1646\n",
      "Epoch 6/10\n",
      "1902/1902 [==============================] - 912s 480ms/step - loss: 1.4201 - average_final_batch_ratio: 0.1646\n",
      "Epoch 7/10\n",
      "1902/1902 [==============================] - 911s 479ms/step - loss: 1.4068 - average_final_batch_ratio: 0.1646\n",
      "Epoch 8/10\n",
      "1902/1902 [==============================] - 919s 483ms/step - loss: 1.3954 - average_final_batch_ratio: 0.1646\n",
      "Epoch 9/10\n",
      "1902/1902 [==============================] - 898s 472ms/step - loss: 1.3847 - average_final_batch_ratio: 0.1646\n",
      "Epoch 10/10\n",
      "1902/1902 [==============================] - 909s 478ms/step - loss: 1.3735 - average_final_batch_ratio: 0.1646\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "\n",
    "class Huffman:\n",
    "    huffman = ctypes.CDLL('x64/Release/huffman')\n",
    "    \n",
    "    huffman.create_tree.restype = ctypes.c_void_p\n",
    "    huffman.destroy_tree.restype = None\n",
    "    huffman.load_weights.restype = None\n",
    "    huffman.create_code_string.restype = ctypes.c_char_p\n",
    "    \n",
    "    def __init__(self, category_count):\n",
    "        self.category_count = category_count\n",
    "        self.tree = ctypes.c_void_p(self.huffman.create_tree(category_count))\n",
    "\n",
    "    def __del__(self):\n",
    "        self.huffman.destroy_tree(self.tree)\n",
    "        \n",
    "    def load_weights(self, weights):\n",
    "        self.huffman.load_weights(self.tree, weights.ctypes.data_as(ctypes.POINTER(ctypes.c_float)))\n",
    "    \n",
    "    def get_code_length(self, category):\n",
    "        return self.huffman.get_code_length(self.tree, category)\n",
    "\n",
    "    def get_code_zero_count(self, category):\n",
    "        return self.huffman.get_code_zero_count(self.tree, category)\n",
    "    \n",
    "    def archive_size(self, model, text):\n",
    "        archived_size = math.ceil(math.log2(self.category_count))\n",
    "        input_eval = np.array([[text[0]]], dtype=TYPE)\n",
    "\n",
    "        model.predicting_model.reset_states()\n",
    "\n",
    "        for byte in text[1:]:\n",
    "            predictions = model.predict(input_eval)\n",
    "            predictions = tf.squeeze(predictions, 0) # remove the batch dimension\n",
    "\n",
    "            weights = tf.nn.softmax(predictions[0]).numpy()\n",
    "            self.load_weights(weights)\n",
    "            archived_size += self.get_code_length(byte.item())\n",
    "\n",
    "            input_eval = tf.expand_dims([byte], 0)\n",
    "\n",
    "        return archived_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 0:\tLength: 12\tAvg Compression: 0.572917\n",
      "Article 100:\tLength: 28\tAvg Compression: 0.590625\n",
      "Article 200:\tLength: 30\tAvg Compression: 0.580357\n",
      "Article 300:\tLength: 31\tAvg Compression: 0.606436\n",
      "Article 400:\tLength: 32\tAvg Compression: 0.612782\n",
      "Article 500:\tLength: 33\tAvg Compression: 0.608434\n",
      "Article 600:\tLength: 34\tAvg Compression: 0.613750\n",
      "Article 700:\tLength: 35\tAvg Compression: 0.608511\n",
      "Article 800:\tLength: 36\tAvg Compression: 0.613930\n",
      "Article 900:\tLength: 37\tAvg Compression: 0.602679\n",
      "Article 1000:\tLength: 38\tAvg Compression: 0.600072\n",
      "Article 1100:\tLength: 39\tAvg Compression: 0.599026\n",
      "Article 1200:\tLength: 39\tAvg Compression: 0.600236\n",
      "Article 1300:\tLength: 40\tAvg Compression: 0.599946\n",
      "Article 1400:\tLength: 41\tAvg Compression: 0.594802\n",
      "Article 1500:\tLength: 41\tAvg Compression: 0.599359\n",
      "Article 1600:\tLength: 42\tAvg Compression: 0.602466\n",
      "Article 1700:\tLength: 42\tAvg Compression: 0.599405\n",
      "Article 1800:\tLength: 43\tAvg Compression: 0.603269\n",
      "Article 1900:\tLength: 44\tAvg Compression: 0.604951\n",
      "Article 2000:\tLength: 44\tAvg Compression: 0.607917\n",
      "Article 2100:\tLength: 45\tAvg Compression: 0.604529\n",
      "Article 2200:\tLength: 46\tAvg Compression: 0.601086\n",
      "Article 2300:\tLength: 46\tAvg Compression: 0.601754\n",
      "Article 2400:\tLength: 47\tAvg Compression: 0.599339\n",
      "Article 2500:\tLength: 47\tAvg Compression: 0.598790\n",
      "Article 2600:\tLength: 48\tAvg Compression: 0.593870\n",
      "Article 2700:\tLength: 49\tAvg Compression: 0.588154\n",
      "Article 2800:\tLength: 49\tAvg Compression: 0.586336\n",
      "Article 2900:\tLength: 50\tAvg Compression: 0.581860\n",
      "Article 3000:\tLength: 50\tAvg Compression: 0.581179\n",
      "Article 3100:\tLength: 51\tAvg Compression: 0.579034\n",
      "Article 3200:\tLength: 51\tAvg Compression: 0.575560\n",
      "Article 3300:\tLength: 52\tAvg Compression: 0.570133\n",
      "Article 3400:\tLength: 52\tAvg Compression: 0.572888\n",
      "Article 3500:\tLength: 53\tAvg Compression: 0.571226\n",
      "Article 3600:\tLength: 54\tAvg Compression: 0.569552\n",
      "Article 3700:\tLength: 54\tAvg Compression: 0.570171\n",
      "Article 3800:\tLength: 55\tAvg Compression: 0.569051\n",
      "Article 3900:\tLength: 56\tAvg Compression: 0.568473\n",
      "Article 4000:\tLength: 56\tAvg Compression: 0.569272\n",
      "Article 4100:\tLength: 57\tAvg Compression: 0.569710\n",
      "Article 4200:\tLength: 58\tAvg Compression: 0.569157\n",
      "Article 4300:\tLength: 59\tAvg Compression: 0.566868\n",
      "Article 4400:\tLength: 60\tAvg Compression: 0.565740\n",
      "Article 4500:\tLength: 61\tAvg Compression: 0.565917\n",
      "Article 4600:\tLength: 62\tAvg Compression: 0.564232\n",
      "Article 4700:\tLength: 63\tAvg Compression: 0.562956\n",
      "Article 4800:\tLength: 64\tAvg Compression: 0.559563\n",
      "Article 4900:\tLength: 66\tAvg Compression: 0.559916\n",
      "Article 5000:\tLength: 67\tAvg Compression: 0.559491\n",
      "Article 5100:\tLength: 69\tAvg Compression: 0.560161\n",
      "Article 5200:\tLength: 72\tAvg Compression: 0.556176\n",
      "Article 5300:\tLength: 75\tAvg Compression: 0.555614\n",
      "Article 5400:\tLength: 79\tAvg Compression: 0.554350\n",
      "Article 5500:\tLength: 83\tAvg Compression: 0.549512\n",
      "Article 5600:\tLength: 86\tAvg Compression: 0.547143\n",
      "Article 5700:\tLength: 94\tAvg Compression: 0.546488\n",
      "Article 5800:\tLength: 109\tAvg Compression: 0.544748\n",
      "Article 5900:\tLength: 192\tAvg Compression: 0.546490\n",
      "Article 6000:\tLength: 293\tAvg Compression: 0.540631\n",
      "Article 6100:\tLength: 379\tAvg Compression: 0.550287\n",
      "Article 6200:\tLength: 456\tAvg Compression: 0.542562\n",
      "Article 6300:\tLength: 517\tAvg Compression: 0.538039\n",
      "Article 6400:\tLength: 566\tAvg Compression: 0.532653\n",
      "Article 6500:\tLength: 605\tAvg Compression: 0.532775\n",
      "Article 6600:\tLength: 668\tAvg Compression: 0.536263\n",
      "Article 6700:\tLength: 729\tAvg Compression: 0.541801\n",
      "Article 6800:\tLength: 776\tAvg Compression: 0.536983\n",
      "Article 6900:\tLength: 828\tAvg Compression: 0.538045\n",
      "Article 7000:\tLength: 880\tAvg Compression: 0.533459\n",
      "Article 7100:\tLength: 941\tAvg Compression: 0.529074\n",
      "Article 7200:\tLength: 1004\tAvg Compression: 0.526630\n",
      "Article 7300:\tLength: 1055\tAvg Compression: 0.527202\n",
      "Article 7400:\tLength: 1106\tAvg Compression: 0.534446\n",
      "Article 7500:\tLength: 1161\tAvg Compression: 0.531751\n",
      "Article 7600:\tLength: 1239\tAvg Compression: 0.531077\n",
      "Article 7700:\tLength: 1296\tAvg Compression: 0.531660\n",
      "Article 7800:\tLength: 1368\tAvg Compression: 0.529224\n",
      "Article 7900:\tLength: 1441\tAvg Compression: 0.527005\n",
      "Article 8000:\tLength: 1498\tAvg Compression: 0.525432\n",
      "Article 8100:\tLength: 1568\tAvg Compression: 0.521082\n",
      "Article 8200:\tLength: 1637\tAvg Compression: 0.520463\n",
      "Article 8300:\tLength: 1694\tAvg Compression: 0.517201\n",
      "Article 8400:\tLength: 1756\tAvg Compression: 0.515483\n",
      "Article 8500:\tLength: 1826\tAvg Compression: 0.516702\n",
      "Article 8600:\tLength: 1893\tAvg Compression: 0.516514\n",
      "Article 8700:\tLength: 1971\tAvg Compression: 0.516062\n",
      "Article 8800:\tLength: 2052\tAvg Compression: 0.513882\n",
      "Article 8900:\tLength: 2139\tAvg Compression: 0.514612\n",
      "Article 9000:\tLength: 2197\tAvg Compression: 0.513626\n",
      "Article 9100:\tLength: 2268\tAvg Compression: 0.512565\n",
      "Article 9200:\tLength: 2344\tAvg Compression: 0.515226\n",
      "Article 9300:\tLength: 2364\tAvg Compression: 0.512436\n",
      "Article 9400:\tLength: 2375\tAvg Compression: 0.512343\n",
      "Article 9500:\tLength: 2463\tAvg Compression: 0.513724\n",
      "Article 9600:\tLength: 2640\tAvg Compression: 0.511742\n",
      "Article 9700:\tLength: 2729\tAvg Compression: 0.512011\n",
      "Article 9800:\tLength: 2765\tAvg Compression: 0.512499\n",
      "Article 9900:\tLength: 2895\tAvg Compression: 0.510740\n",
      "Article 10000:\tLength: 2988\tAvg Compression: 0.509654\n",
      "Article 10100:\tLength: 3033\tAvg Compression: 0.509255\n",
      "Article 10200:\tLength: 3155\tAvg Compression: 0.508087\n",
      "Article 10300:\tLength: 3241\tAvg Compression: 0.506534\n",
      "Article 10400:\tLength: 3289\tAvg Compression: 0.507014\n",
      "Article 10500:\tLength: 3414\tAvg Compression: 0.506695\n",
      "Article 10600:\tLength: 3518\tAvg Compression: 0.508321\n",
      "Article 10700:\tLength: 3614\tAvg Compression: 0.506927\n",
      "Article 10800:\tLength: 3625\tAvg Compression: 0.507465\n",
      "Article 10900:\tLength: 3753\tAvg Compression: 0.507387\n",
      "Article 11000:\tLength: 3892\tAvg Compression: 0.508958\n",
      "Article 11100:\tLength: 3965\tAvg Compression: 0.508362\n",
      "Article 11200:\tLength: 4104\tAvg Compression: 0.508988\n",
      "Article 11300:\tLength: 4163\tAvg Compression: 0.510214\n",
      "Article 11400:\tLength: 4254\tAvg Compression: 0.510956\n",
      "Article 11500:\tLength: 4337\tAvg Compression: 0.510702\n",
      "Article 11600:\tLength: 4502\tAvg Compression: 0.511929\n",
      "Article 11700:\tLength: 4613\tAvg Compression: 0.512208\n",
      "Article 11800:\tLength: 4604\tAvg Compression: 0.511503\n",
      "Article 11900:\tLength: 4790\tAvg Compression: 0.511233\n",
      "Article 12000:\tLength: 4939\tAvg Compression: 0.513846\n",
      "Article 12100:\tLength: 5056\tAvg Compression: 0.513194\n",
      "Article 12200:\tLength: 5159\tAvg Compression: 0.513692\n",
      "Article 12300:\tLength: 5294\tAvg Compression: 0.513790\n",
      "Article 12400:\tLength: 5413\tAvg Compression: 0.512662\n",
      "Article 12500:\tLength: 5606\tAvg Compression: 0.512946\n",
      "Article 12600:\tLength: 5673\tAvg Compression: 0.512351\n",
      "Article 12700:\tLength: 5872\tAvg Compression: 0.511769\n",
      "Article 12800:\tLength: 6046\tAvg Compression: 0.511273\n",
      "Article 12900:\tLength: 6198\tAvg Compression: 0.511565\n",
      "Article 13000:\tLength: 6351\tAvg Compression: 0.511139\n",
      "Article 13100:\tLength: 6476\tAvg Compression: 0.511948\n",
      "Article 13200:\tLength: 6665\tAvg Compression: 0.511579\n",
      "Article 13300:\tLength: 6795\tAvg Compression: 0.513133\n",
      "Article 13400:\tLength: 6674\tAvg Compression: 0.516325\n",
      "Article 13500:\tLength: 7124\tAvg Compression: 0.514973\n",
      "Article 13600:\tLength: 7324\tAvg Compression: 0.515433\n",
      "Article 13700:\tLength: 7508\tAvg Compression: 0.517401\n",
      "Article 13800:\tLength: 7522\tAvg Compression: 0.519471\n",
      "Article 13900:\tLength: 7856\tAvg Compression: 0.519474\n",
      "Article 14000:\tLength: 8043\tAvg Compression: 0.519573\n",
      "Article 14100:\tLength: 8118\tAvg Compression: 0.519273\n",
      "Article 14200:\tLength: 8385\tAvg Compression: 0.518537\n",
      "Article 14300:\tLength: 8576\tAvg Compression: 0.517566\n",
      "Article 14400:\tLength: 8753\tAvg Compression: 0.521215\n",
      "Article 14500:\tLength: 8984\tAvg Compression: 0.520872\n",
      "Article 14600:\tLength: 9178\tAvg Compression: 0.521528\n",
      "Article 14700:\tLength: 9411\tAvg Compression: 0.521717\n",
      "Article 14800:\tLength: 9678\tAvg Compression: 0.522233\n",
      "Article 14900:\tLength: 9895\tAvg Compression: 0.521252\n",
      "Article 15000:\tLength: 10150\tAvg Compression: 0.521834\n",
      "Article 15100:\tLength: 10324\tAvg Compression: 0.521957\n",
      "Article 15200:\tLength: 10616\tAvg Compression: 0.522100\n",
      "Article 15300:\tLength: 10909\tAvg Compression: 0.522258\n",
      "Article 15400:\tLength: 11080\tAvg Compression: 0.521813\n",
      "Article 15500:\tLength: 11179\tAvg Compression: 0.521397\n",
      "Article 15600:\tLength: 11670\tAvg Compression: 0.521070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 15700:\tLength: 11993\tAvg Compression: 0.520490\n",
      "Article 15800:\tLength: 12274\tAvg Compression: 0.519436\n",
      "Article 15900:\tLength: 12522\tAvg Compression: 0.519417\n",
      "Article 16000:\tLength: 12843\tAvg Compression: 0.519216\n",
      "Article 16100:\tLength: 13022\tAvg Compression: 0.519412\n",
      "Article 16200:\tLength: 13335\tAvg Compression: 0.520001\n",
      "Article 16300:\tLength: 13582\tAvg Compression: 0.520906\n",
      "Article 16400:\tLength: 13943\tAvg Compression: 0.520872\n",
      "Article 16500:\tLength: 14159\tAvg Compression: 0.521914\n",
      "Article 16600:\tLength: 14497\tAvg Compression: 0.523003\n",
      "Article 16700:\tLength: 14766\tAvg Compression: 0.522815\n",
      "Article 16800:\tLength: 15138\tAvg Compression: 0.522954\n",
      "Article 16900:\tLength: 15589\tAvg Compression: 0.523196\n",
      "Article 17000:\tLength: 15906\tAvg Compression: 0.523986\n",
      "Article 17100:\tLength: 16145\tAvg Compression: 0.523922\n",
      "Article 17200:\tLength: 16798\tAvg Compression: 0.524581\n",
      "Article 17300:\tLength: 17120\tAvg Compression: 0.524358\n",
      "Article 17400:\tLength: 17810\tAvg Compression: 0.525381\n",
      "Article 17500:\tLength: 18049\tAvg Compression: 0.526281\n",
      "Article 17600:\tLength: 18844\tAvg Compression: 0.525954\n",
      "Article 17700:\tLength: 19503\tAvg Compression: 0.525222\n",
      "Article 17800:\tLength: 20117\tAvg Compression: 0.525570\n",
      "Article 17900:\tLength: 20626\tAvg Compression: 0.525664\n",
      "Article 18000:\tLength: 20350\tAvg Compression: 0.525926\n",
      "Article 18100:\tLength: 22076\tAvg Compression: 0.526130\n",
      "Article 18200:\tLength: 22940\tAvg Compression: 0.526351\n",
      "Article 18300:\tLength: 23355\tAvg Compression: 0.526085\n",
      "Article 18400:\tLength: 24560\tAvg Compression: 0.527909\n",
      "Article 18500:\tLength: 25488\tAvg Compression: 0.527687\n",
      "Article 18600:\tLength: 26439\tAvg Compression: 0.527599\n",
      "Article 18700:\tLength: 27252\tAvg Compression: 0.527505\n",
      "Article 18800:\tLength: 28415\tAvg Compression: 0.528461\n",
      "Article 18900:\tLength: 29287\tAvg Compression: 0.528383\n",
      "Article 19000:\tLength: 30865\tAvg Compression: 0.528183\n",
      "Article 19100:\tLength: 32381\tAvg Compression: 0.528123\n",
      "Article 19200:\tLength: 34164\tAvg Compression: 0.527885\n",
      "Article 19300:\tLength: 35990\tAvg Compression: 0.527970\n",
      "Article 19400:\tLength: 38524\tAvg Compression: 0.527471\n",
      "Article 19500:\tLength: 41139\tAvg Compression: 0.527592\n",
      "Article 19600:\tLength: 43795\tAvg Compression: 0.527675\n",
      "Article 19700:\tLength: 47945\tAvg Compression: 0.527690\n",
      "Article 19800:\tLength: 52573\tAvg Compression: 0.528044\n",
      "Article 19900:\tLength: 61215\tAvg Compression: 0.527741\n"
     ]
    }
   ],
   "source": [
    "total_raw = 0\n",
    "total_compressed = 0\n",
    "\n",
    "huffman = Huffman(encoder.vocab_size)\n",
    "for index, encoded_article in enumerate(articles.articles_generator(1)):\n",
    "    if index % 100 == 0:\n",
    "        article = encoder.decode(encoded_article)\n",
    "        if len(article) == 0:\n",
    "            continue\n",
    "        total_raw += len(article) * 8\n",
    "        total_compressed += huffman.archive_size(model, encoded_article)\n",
    "        print('Article %d:\\tLength: %d\\tAvg Compression: %f' % (index, len(article), total_compressed/total_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1902/1902 [==============================] - 907s 477ms/step - loss: 1.3621 - average_final_batch_ratio: 0.1646\n",
      "Epoch 2/20\n",
      "1902/1902 [==============================] - 888s 467ms/step - loss: 1.3554 - average_final_batch_ratio: 0.1646\n",
      "Epoch 3/20\n",
      "1902/1902 [==============================] - 906s 476ms/step - loss: 1.3571 - average_final_batch_ratio: 0.1646\n",
      "Epoch 4/20\n",
      "1902/1902 [==============================] - 908s 477ms/step - loss: 1.3426 - average_final_batch_ratio: 0.1646\n",
      "Epoch 5/20\n",
      "1902/1902 [==============================] - 904s 475ms/step - loss: 1.3330 - average_final_batch_ratio: 0.1646\n",
      "Epoch 6/20\n",
      "1902/1902 [==============================] - 915s 481ms/step - loss: 1.3277 - average_final_batch_ratio: 0.1646\n",
      "Epoch 7/20\n",
      "1902/1902 [==============================] - 929s 488ms/step - loss: 1.3222 - average_final_batch_ratio: 0.1646\n",
      "Epoch 8/20\n",
      "1902/1902 [==============================] - 922s 485ms/step - loss: 1.3163 - average_final_batch_ratio: 0.1646\n",
      "Epoch 9/20\n",
      "1902/1902 [==============================] - 894s 470ms/step - loss: 1.3133 - average_final_batch_ratio: 0.1646\n",
      "Epoch 10/20\n",
      "1902/1902 [==============================] - 912s 479ms/step - loss: 1.3110 - average_final_batch_ratio: 0.1646\n",
      "Epoch 11/20\n",
      "1902/1902 [==============================] - 893s 469ms/step - loss: 1.3094 - average_final_batch_ratio: 0.1646\n",
      "Epoch 12/20\n",
      "1902/1902 [==============================] - 918s 483ms/step - loss: 1.3021 - average_final_batch_ratio: 0.1646\n",
      "Epoch 13/20\n",
      "1902/1902 [==============================] - 900s 473ms/step - loss: 1.3049 - average_final_batch_ratio: 0.1646\n",
      "Epoch 14/20\n",
      "1902/1902 [==============================] - 917s 482ms/step - loss: 1.3058 - average_final_batch_ratio: 0.1646\n",
      "Epoch 15/20\n",
      "1902/1902 [==============================] - 914s 481ms/step - loss: 1.2968 - average_final_batch_ratio: 0.1646\n",
      "Epoch 16/20\n",
      "1902/1902 [==============================] - 917s 482ms/step - loss: 1.2982 - average_final_batch_ratio: 0.1646\n",
      "Epoch 17/20\n",
      "1902/1902 [==============================] - 911s 479ms/step - loss: 1.2927 - average_final_batch_ratio: 0.1646\n",
      "Epoch 18/20\n",
      "1902/1902 [==============================] - 895s 471ms/step - loss: 1.4006 - average_final_batch_ratio: 0.1646\n",
      "Epoch 19/20\n",
      "1902/1902 [==============================] - 912s 480ms/step - loss: 1.6103 - average_final_batch_ratio: 0.1646\n",
      "Epoch 20/20\n",
      "1902/1902 [==============================] - 902s 474ms/step - loss: 1.5384 - average_final_batch_ratio: 0.1646\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 0:\tLength: 12\tAvg Compression: 0.218750\n",
      "Article 100:\tLength: 28\tAvg Compression: 0.253125\n",
      "Article 200:\tLength: 30\tAvg Compression: 0.282143\n",
      "Article 300:\tLength: 31\tAvg Compression: 0.285891\n",
      "Article 400:\tLength: 32\tAvg Compression: 0.266917\n",
      "Article 500:\tLength: 33\tAvg Compression: 0.264307\n",
      "Article 600:\tLength: 34\tAvg Compression: 0.268125\n",
      "Article 700:\tLength: 35\tAvg Compression: 0.255851\n",
      "Article 800:\tLength: 36\tAvg Compression: 0.252306\n",
      "Article 900:\tLength: 37\tAvg Compression: 0.256899\n",
      "Article 1000:\tLength: 38\tAvg Compression: 0.251445\n",
      "Article 1100:\tLength: 39\tAvg Compression: 0.252273\n",
      "Article 1200:\tLength: 39\tAvg Compression: 0.248821\n",
      "Article 1300:\tLength: 40\tAvg Compression: 0.242726\n",
      "Article 1400:\tLength: 41\tAvg Compression: 0.250248\n",
      "Article 1500:\tLength: 41\tAvg Compression: 0.253663\n",
      "Article 1600:\tLength: 42\tAvg Compression: 0.250850\n",
      "Article 1700:\tLength: 42\tAvg Compression: 0.254762\n",
      "Article 1800:\tLength: 43\tAvg Compression: 0.255572\n",
      "Article 1900:\tLength: 44\tAvg Compression: 0.252964\n",
      "Article 2000:\tLength: 44\tAvg Compression: 0.254763\n",
      "Article 2100:\tLength: 45\tAvg Compression: 0.253877\n",
      "Article 2200:\tLength: 46\tAvg Compression: 0.258803\n",
      "Article 2300:\tLength: 46\tAvg Compression: 0.259465\n",
      "Article 2400:\tLength: 47\tAvg Compression: 0.254233\n",
      "Article 2500:\tLength: 47\tAvg Compression: 0.258443\n",
      "Article 2600:\tLength: 48\tAvg Compression: 0.261779\n",
      "Article 2700:\tLength: 49\tAvg Compression: 0.261478\n",
      "Article 2800:\tLength: 49\tAvg Compression: 0.260105\n",
      "Article 2900:\tLength: 50\tAvg Compression: 0.257997\n",
      "Article 3000:\tLength: 50\tAvg Compression: 0.255957\n",
      "Article 3100:\tLength: 51\tAvg Compression: 0.253782\n",
      "Article 3200:\tLength: 51\tAvg Compression: 0.250466\n",
      "Article 3300:\tLength: 52\tAvg Compression: 0.248384\n",
      "Article 3400:\tLength: 52\tAvg Compression: 0.248182\n",
      "Article 3500:\tLength: 53\tAvg Compression: 0.246326\n",
      "Article 3600:\tLength: 54\tAvg Compression: 0.244600\n",
      "Article 3700:\tLength: 54\tAvg Compression: 0.243925\n",
      "Article 3800:\tLength: 55\tAvg Compression: 0.244578\n",
      "Article 3900:\tLength: 56\tAvg Compression: 0.242133\n",
      "Article 4000:\tLength: 56\tAvg Compression: 0.239983\n",
      "Article 4100:\tLength: 57\tAvg Compression: 0.243507\n",
      "Article 4200:\tLength: 58\tAvg Compression: 0.242051\n",
      "Article 4300:\tLength: 59\tAvg Compression: 0.239979\n",
      "Article 4400:\tLength: 60\tAvg Compression: 0.238410\n",
      "Article 4500:\tLength: 61\tAvg Compression: 0.236030\n",
      "Article 4600:\tLength: 62\tAvg Compression: 0.235322\n",
      "Article 4700:\tLength: 63\tAvg Compression: 0.236485\n",
      "Article 4800:\tLength: 64\tAvg Compression: 0.234929\n",
      "Article 4900:\tLength: 66\tAvg Compression: 0.235896\n",
      "Article 5000:\tLength: 67\tAvg Compression: 0.239064\n",
      "Article 5100:\tLength: 69\tAvg Compression: 0.240694\n",
      "Article 5200:\tLength: 72\tAvg Compression: 0.239328\n",
      "Article 5300:\tLength: 75\tAvg Compression: 0.238052\n",
      "Article 5400:\tLength: 79\tAvg Compression: 0.235143\n",
      "Article 5500:\tLength: 83\tAvg Compression: 0.237938\n",
      "Article 5600:\tLength: 86\tAvg Compression: 0.238170\n",
      "Article 5700:\tLength: 94\tAvg Compression: 0.238166\n",
      "Article 5800:\tLength: 109\tAvg Compression: 0.237852\n",
      "Article 5900:\tLength: 192\tAvg Compression: 0.239532\n",
      "Article 6000:\tLength: 293\tAvg Compression: 0.237927\n",
      "Article 6100:\tLength: 378\tAvg Compression: 0.236891\n",
      "Article 6200:\tLength: 456\tAvg Compression: 0.234286\n",
      "Article 6300:\tLength: 517\tAvg Compression: 0.239319\n",
      "Article 6400:\tLength: 566\tAvg Compression: 0.234358\n",
      "Article 6500:\tLength: 605\tAvg Compression: 0.238372\n",
      "Article 6600:\tLength: 641\tAvg Compression: 0.235979\n",
      "Article 6700:\tLength: 729\tAvg Compression: 0.235235\n",
      "Article 6800:\tLength: 776\tAvg Compression: 0.231895\n",
      "Article 6900:\tLength: 828\tAvg Compression: 0.228450\n",
      "Article 7000:\tLength: 880\tAvg Compression: 0.228043\n",
      "Article 7100:\tLength: 935\tAvg Compression: 0.226433\n",
      "Article 7200:\tLength: 1004\tAvg Compression: 0.224053\n",
      "Article 7300:\tLength: 1055\tAvg Compression: 0.226967\n",
      "Article 7400:\tLength: 1106\tAvg Compression: 0.228892\n",
      "Article 7500:\tLength: 1160\tAvg Compression: 0.227869\n",
      "Article 7600:\tLength: 1231\tAvg Compression: 0.228715\n",
      "Article 7700:\tLength: 1306\tAvg Compression: 0.232641\n",
      "Article 7800:\tLength: 1368\tAvg Compression: 0.234501\n",
      "Article 7900:\tLength: 1441\tAvg Compression: 0.234871\n",
      "Article 8000:\tLength: 1498\tAvg Compression: 0.235854\n",
      "Article 8100:\tLength: 1568\tAvg Compression: 0.234066\n",
      "Article 8200:\tLength: 1637\tAvg Compression: 0.233504\n",
      "Article 8300:\tLength: 1677\tAvg Compression: 0.234142\n",
      "Article 8400:\tLength: 1756\tAvg Compression: 0.234791\n",
      "Article 8500:\tLength: 1826\tAvg Compression: 0.235321\n",
      "Article 8600:\tLength: 1900\tAvg Compression: 0.235483\n",
      "Article 8700:\tLength: 1971\tAvg Compression: 0.236982\n",
      "Article 8800:\tLength: 2052\tAvg Compression: 0.238509\n",
      "Article 8900:\tLength: 2139\tAvg Compression: 0.238793\n",
      "Article 9000:\tLength: 2095\tAvg Compression: 0.242083\n",
      "Article 9100:\tLength: 2228\tAvg Compression: 0.241652\n",
      "Article 9200:\tLength: 2344\tAvg Compression: 0.240913\n",
      "Article 9300:\tLength: 2364\tAvg Compression: 0.240602\n",
      "Article 9400:\tLength: 2375\tAvg Compression: 0.241785\n",
      "Article 9500:\tLength: 2463\tAvg Compression: 0.242638\n",
      "Article 9600:\tLength: 2564\tAvg Compression: 0.243075\n",
      "Article 9700:\tLength: 2729\tAvg Compression: 0.242820\n",
      "Article 9800:\tLength: 2765\tAvg Compression: 0.241976\n",
      "Article 9900:\tLength: 2895\tAvg Compression: 0.242715\n",
      "Article 10000:\tLength: 2988\tAvg Compression: 0.242763\n",
      "Article 10100:\tLength: 3033\tAvg Compression: 0.243102\n",
      "Article 10200:\tLength: 3155\tAvg Compression: 0.242537\n",
      "Article 10300:\tLength: 3210\tAvg Compression: 0.243255\n",
      "Article 10400:\tLength: 3289\tAvg Compression: 0.242569\n",
      "Article 10500:\tLength: 3414\tAvg Compression: 0.242110\n",
      "Article 10600:\tLength: 3518\tAvg Compression: 0.243065\n",
      "Article 10700:\tLength: 3614\tAvg Compression: 0.241719\n",
      "Article 10800:\tLength: 3625\tAvg Compression: 0.241097\n",
      "Article 10900:\tLength: 3753\tAvg Compression: 0.240987\n",
      "Article 11000:\tLength: 3892\tAvg Compression: 0.241587\n",
      "Article 11100:\tLength: 3965\tAvg Compression: 0.241888\n",
      "Article 11200:\tLength: 4104\tAvg Compression: 0.242508\n",
      "Article 11300:\tLength: 4163\tAvg Compression: 0.243399\n",
      "Article 11400:\tLength: 4266\tAvg Compression: 0.244262\n",
      "Article 11500:\tLength: 4337\tAvg Compression: 0.243339\n",
      "Article 11600:\tLength: 4502\tAvg Compression: 0.242569\n",
      "Article 11700:\tLength: 4625\tAvg Compression: 0.242461\n",
      "Article 11800:\tLength: 4723\tAvg Compression: 0.242743\n",
      "Article 11900:\tLength: 4790\tAvg Compression: 0.242980\n",
      "Article 12000:\tLength: 4939\tAvg Compression: 0.244400\n",
      "Article 12100:\tLength: 5056\tAvg Compression: 0.243954\n",
      "Article 12200:\tLength: 5159\tAvg Compression: 0.244211\n",
      "Article 12300:\tLength: 5294\tAvg Compression: 0.245209\n",
      "Article 12400:\tLength: 5413\tAvg Compression: 0.244252\n",
      "Article 12500:\tLength: 5606\tAvg Compression: 0.244177\n",
      "Article 12600:\tLength: 5673\tAvg Compression: 0.243493\n",
      "Article 12700:\tLength: 5872\tAvg Compression: 0.243190\n",
      "Article 12800:\tLength: 6046\tAvg Compression: 0.243139\n",
      "Article 12900:\tLength: 6212\tAvg Compression: 0.242967\n",
      "Article 13000:\tLength: 6351\tAvg Compression: 0.242911\n",
      "Article 13100:\tLength: 6476\tAvg Compression: 0.243579\n",
      "Article 13200:\tLength: 6637\tAvg Compression: 0.244183\n",
      "Article 13300:\tLength: 6795\tAvg Compression: 0.244699\n",
      "Article 13400:\tLength: 6968\tAvg Compression: 0.244504\n",
      "Article 13500:\tLength: 7124\tAvg Compression: 0.243875\n",
      "Article 13600:\tLength: 7320\tAvg Compression: 0.244342\n",
      "Article 13700:\tLength: 7508\tAvg Compression: 0.244155\n",
      "Article 13800:\tLength: 7522\tAvg Compression: 0.245216\n",
      "Article 13900:\tLength: 7839\tAvg Compression: 0.244426\n",
      "Article 14000:\tLength: 8043\tAvg Compression: 0.245261\n",
      "Article 14100:\tLength: 8200\tAvg Compression: 0.245896\n",
      "Article 14200:\tLength: 8369\tAvg Compression: 0.245695\n",
      "Article 14300:\tLength: 8573\tAvg Compression: 0.245159\n",
      "Article 14400:\tLength: 8753\tAvg Compression: 0.245629\n",
      "Article 14500:\tLength: 8984\tAvg Compression: 0.245601\n",
      "Article 14600:\tLength: 9178\tAvg Compression: 0.245092\n",
      "Article 14700:\tLength: 9411\tAvg Compression: 0.245638\n",
      "Article 14800:\tLength: 9678\tAvg Compression: 0.245082\n",
      "Article 14900:\tLength: 9895\tAvg Compression: 0.244264\n",
      "Article 15000:\tLength: 10150\tAvg Compression: 0.245130\n",
      "Article 15100:\tLength: 10324\tAvg Compression: 0.244919\n",
      "Article 15200:\tLength: 10616\tAvg Compression: 0.244920\n",
      "Article 15300:\tLength: 10909\tAvg Compression: 0.245857\n",
      "Article 15400:\tLength: 11080\tAvg Compression: 0.245467\n",
      "Article 15500:\tLength: 11179\tAvg Compression: 0.245191\n",
      "Article 15600:\tLength: 11670\tAvg Compression: 0.244900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 15700:\tLength: 11993\tAvg Compression: 0.245166\n",
      "Article 15800:\tLength: 12274\tAvg Compression: 0.244517\n",
      "Article 15900:\tLength: 12522\tAvg Compression: 0.244238\n",
      "Article 16000:\tLength: 12843\tAvg Compression: 0.243548\n",
      "Article 16100:\tLength: 13022\tAvg Compression: 0.243688\n",
      "Article 16200:\tLength: 13335\tAvg Compression: 0.244104\n",
      "Article 16300:\tLength: 13582\tAvg Compression: 0.243245\n",
      "Article 16400:\tLength: 13868\tAvg Compression: 0.243745\n",
      "Article 16500:\tLength: 14159\tAvg Compression: 0.242819\n",
      "Article 16600:\tLength: 14497\tAvg Compression: 0.241756\n",
      "Article 16700:\tLength: 14766\tAvg Compression: 0.242192\n",
      "Article 16800:\tLength: 15189\tAvg Compression: 0.242298\n",
      "Article 16900:\tLength: 15589\tAvg Compression: 0.242662\n",
      "Article 17000:\tLength: 15922\tAvg Compression: 0.241899\n",
      "Article 17100:\tLength: 16145\tAvg Compression: 0.241635\n",
      "Article 17200:\tLength: 16798\tAvg Compression: 0.240856\n",
      "Article 17300:\tLength: 17120\tAvg Compression: 0.240251\n",
      "Article 17400:\tLength: 17810\tAvg Compression: 0.240965\n",
      "Article 17500:\tLength: 18180\tAvg Compression: 0.241117\n",
      "Article 17600:\tLength: 18912\tAvg Compression: 0.241525\n",
      "Article 17700:\tLength: 19503\tAvg Compression: 0.241486\n",
      "Article 17800:\tLength: 20117\tAvg Compression: 0.242091\n",
      "Article 17900:\tLength: 20626\tAvg Compression: 0.241727\n",
      "Article 18000:\tLength: 20350\tAvg Compression: 0.241463\n",
      "Article 18100:\tLength: 22076\tAvg Compression: 0.241660\n",
      "Article 18200:\tLength: 22940\tAvg Compression: 0.241769\n",
      "Article 18300:\tLength: 23355\tAvg Compression: 0.242270\n",
      "Article 18400:\tLength: 24560\tAvg Compression: 0.242268\n",
      "Article 18500:\tLength: 25488\tAvg Compression: 0.242728\n",
      "Article 18600:\tLength: 26439\tAvg Compression: 0.243226\n",
      "Article 18700:\tLength: 27252\tAvg Compression: 0.243936\n",
      "Article 18800:\tLength: 28415\tAvg Compression: 0.244102\n",
      "Article 18900:\tLength: 29287\tAvg Compression: 0.244288\n",
      "Article 19000:\tLength: 30534\tAvg Compression: 0.244600\n",
      "Article 19100:\tLength: 32381\tAvg Compression: 0.245078\n",
      "Article 19200:\tLength: 34164\tAvg Compression: 0.244435\n",
      "Article 19300:\tLength: 35990\tAvg Compression: 0.243473\n",
      "Article 19400:\tLength: 38524\tAvg Compression: 0.243734\n",
      "Article 19500:\tLength: 41139\tAvg Compression: 0.244029\n",
      "Article 19600:\tLength: 43795\tAvg Compression: 0.244378\n",
      "Article 19700:\tLength: 47945\tAvg Compression: 0.244880\n",
      "Article 19800:\tLength: 52573\tAvg Compression: 0.244836\n",
      "Article 19900:\tLength: 61215\tAvg Compression: 0.245297\n"
     ]
    }
   ],
   "source": [
    "total_raw = 0\n",
    "total_compressed = 0\n",
    "\n",
    "huffman = Huffman(encoder.vocab_size)\n",
    "for index, encoded_article in enumerate(articles.articles_generator(1)):\n",
    "    if index % 100 == 0:\n",
    "        article = encoder.decode(encoded_article)\n",
    "        total_raw += len(article) * 8\n",
    "        total_compressed += huffman.archive_size(model, encoded_article)\n",
    "        print('Article %d:\\tLength: %d\\tAvg Compression: %f' % (index, len(article), total_compressed/total_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "1902/1902 [==============================] - 889s 467ms/step - loss: 1.5974 - average_final_batch_ratio: 0.1646\n",
      "Epoch 2/30\n",
      "1902/1902 [==============================] - 885s 465ms/step - loss: 1.6071 - average_final_batch_ratio: 0.1646\n",
      "Epoch 3/30\n",
      "1902/1902 [==============================] - 883s 465ms/step - loss: 1.5557 - average_final_batch_ratio: 0.1646\n",
      "Epoch 4/30\n",
      "1902/1902 [==============================] - 895s 471ms/step - loss: 1.5194 - average_final_batch_ratio: 0.1646\n",
      "Epoch 5/30\n",
      "1902/1902 [==============================] - 883s 464ms/step - loss: 1.4900 - average_final_batch_ratio: 0.1646\n",
      "Epoch 6/30\n",
      "1902/1902 [==============================] - 898s 472ms/step - loss: 1.4650 - average_final_batch_ratio: 0.1646\n",
      "Epoch 7/30\n",
      "1902/1902 [==============================] - 891s 469ms/step - loss: 1.4420 - average_final_batch_ratio: 0.1646\n",
      "Epoch 8/30\n",
      "1902/1902 [==============================] - 889s 467ms/step - loss: 1.4234 - average_final_batch_ratio: 0.1646\n",
      "Epoch 9/30\n",
      "1902/1902 [==============================] - 887s 466ms/step - loss: 1.4060 - average_final_batch_ratio: 0.1646\n",
      "Epoch 10/30\n",
      "1902/1902 [==============================] - 894s 470ms/step - loss: 1.3929 - average_final_batch_ratio: 0.1646\n",
      "Epoch 11/30\n",
      "1902/1902 [==============================] - 895s 470ms/step - loss: 1.3778 - average_final_batch_ratio: 0.1646\n",
      "Epoch 12/30\n",
      "1902/1902 [==============================] - 879s 462ms/step - loss: 1.3635 - average_final_batch_ratio: 0.1646\n",
      "Epoch 13/30\n",
      "1902/1902 [==============================] - 897s 471ms/step - loss: 1.3522 - average_final_batch_ratio: 0.1646\n",
      "Epoch 14/30\n",
      "1902/1902 [==============================] - 890s 468ms/step - loss: 1.3414 - average_final_batch_ratio: 0.1646\n",
      "Epoch 15/30\n",
      "1902/1902 [==============================] - 881s 463ms/step - loss: 1.3481 - average_final_batch_ratio: 0.1646\n",
      "Epoch 16/30\n",
      "1902/1902 [==============================] - 878s 461ms/step - loss: 1.3320 - average_final_batch_ratio: 0.1646\n",
      "Epoch 17/30\n",
      "1902/1902 [==============================] - 874s 460ms/step - loss: 1.3187 - average_final_batch_ratio: 0.1646\n",
      "Epoch 18/30\n",
      "1902/1902 [==============================] - 887s 466ms/step - loss: 1.3081 - average_final_batch_ratio: 0.1646\n",
      "Epoch 19/30\n",
      "1902/1902 [==============================] - 877s 461ms/step - loss: 1.3010 - average_final_batch_ratio: 0.1646\n",
      "Epoch 20/30\n",
      "1902/1902 [==============================] - 904s 475ms/step - loss: 1.2958 - average_final_batch_ratio: 0.1646\n",
      "Epoch 21/30\n",
      "1902/1902 [==============================] - 909s 478ms/step - loss: 1.2929 - average_final_batch_ratio: 0.1646\n",
      "Epoch 22/30\n",
      "1902/1902 [==============================] - 885s 465ms/step - loss: 1.2885 - average_final_batch_ratio: 0.1646\n",
      "Epoch 23/30\n",
      "1902/1902 [==============================] - 882s 464ms/step - loss: 1.2879 - average_final_batch_ratio: 0.1646\n",
      "Epoch 24/30\n",
      "1902/1902 [==============================] - 875s 460ms/step - loss: 2.1594 - average_final_batch_ratio: 0.1646\n",
      "Epoch 25/30\n",
      "1902/1902 [==============================] - 886s 466ms/step - loss: 2.0780 - average_final_batch_ratio: 0.1646\n",
      "Epoch 26/30\n",
      "1902/1902 [==============================] - 876s 461ms/step - loss: 2.0018 - average_final_batch_ratio: 0.1646\n",
      "Epoch 27/30\n",
      "1902/1902 [==============================] - 894s 470ms/step - loss: 1.9351 - average_final_batch_ratio: 0.1646\n",
      "Epoch 28/30\n",
      "1902/1902 [==============================] - 895s 471ms/step - loss: 1.8740 - average_final_batch_ratio: 0.1646\n",
      "Epoch 29/30\n",
      "1902/1902 [==============================] - 900s 473ms/step - loss: 1.8150 - average_final_batch_ratio: 0.1646\n",
      "Epoch 30/30\n",
      "1902/1902 [==============================] - 880s 463ms/step - loss: 1.7583 - average_final_batch_ratio: 0.1646\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1902/1902 [==============================] - 895s 471ms/step - loss: 1.7055 - average_final_batch_ratio: 0.1646\n",
      "Epoch 2/10\n",
      "1902/1902 [==============================] - 900s 473ms/step - loss: 1.6582 - average_final_batch_ratio: 0.1646\n",
      "Epoch 3/10\n",
      "1902/1902 [==============================] - 880s 463ms/step - loss: 1.8234 - average_final_batch_ratio: 0.1646\n",
      "Epoch 4/10\n",
      "1902/1902 [==============================] - 898s 472ms/step - loss: 1.6964 - average_final_batch_ratio: 0.1646\n",
      "Epoch 5/10\n",
      "1902/1902 [==============================] - 890s 468ms/step - loss: 1.6358 - average_final_batch_ratio: 0.1646\n",
      "Epoch 6/10\n",
      "1902/1902 [==============================] - 893s 470ms/step - loss: 1.5933 - average_final_batch_ratio: 0.1646\n",
      "Epoch 7/10\n",
      "1902/1902 [==============================] - 904s 475ms/step - loss: 1.5602 - average_final_batch_ratio: 0.1646\n",
      "Epoch 8/10\n",
      "1902/1902 [==============================] - 917s 482ms/step - loss: 1.5393 - average_final_batch_ratio: 0.1646\n",
      "Epoch 9/10\n",
      "1902/1902 [==============================] - 908s 478ms/step - loss: 1.5157 - average_final_batch_ratio: 0.1646\n",
      "Epoch 10/10\n",
      "1902/1902 [==============================] - 900s 473ms/step - loss: 1.4953 - average_final_batch_ratio: 0.1646\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 0:\tLength: 12\tAvg Compression: 0.270833\n",
      "Article 100:\tLength: 28\tAvg Compression: 0.281250\n",
      "Article 200:\tLength: 30\tAvg Compression: 0.292857\n",
      "Article 300:\tLength: 31\tAvg Compression: 0.303218\n",
      "Article 400:\tLength: 32\tAvg Compression: 0.285714\n",
      "Article 500:\tLength: 33\tAvg Compression: 0.288404\n",
      "Article 600:\tLength: 34\tAvg Compression: 0.293125\n",
      "Article 700:\tLength: 35\tAvg Compression: 0.279255\n",
      "Article 800:\tLength: 36\tAvg Compression: 0.276753\n",
      "Article 900:\tLength: 37\tAvg Compression: 0.274351\n",
      "Article 1000:\tLength: 38\tAvg Compression: 0.269870\n",
      "Article 1100:\tLength: 39\tAvg Compression: 0.267208\n",
      "Article 1200:\tLength: 39\tAvg Compression: 0.263856\n",
      "Article 1300:\tLength: 40\tAvg Compression: 0.257812\n",
      "Article 1400:\tLength: 41\tAvg Compression: 0.265099\n",
      "Article 1500:\tLength: 41\tAvg Compression: 0.264194\n",
      "Article 1600:\tLength: 42\tAvg Compression: 0.260842\n",
      "Article 1700:\tLength: 42\tAvg Compression: 0.266071\n",
      "Article 1800:\tLength: 43\tAvg Compression: 0.269688\n",
      "Article 1900:\tLength: 44\tAvg Compression: 0.266562\n",
      "Article 2000:\tLength: 44\tAvg Compression: 0.266426\n",
      "Article 2100:\tLength: 45\tAvg Compression: 0.263958\n",
      "Article 2200:\tLength: 46\tAvg Compression: 0.271860\n",
      "Article 2300:\tLength: 46\tAvg Compression: 0.271437\n",
      "Article 2400:\tLength: 47\tAvg Compression: 0.267593\n",
      "Article 2500:\tLength: 47\tAvg Compression: 0.270035\n",
      "Article 2600:\tLength: 48\tAvg Compression: 0.271394\n",
      "Article 2700:\tLength: 49\tAvg Compression: 0.273301\n",
      "Article 2800:\tLength: 49\tAvg Compression: 0.270980\n",
      "Article 2900:\tLength: 50\tAvg Compression: 0.268098\n",
      "Article 3000:\tLength: 50\tAvg Compression: 0.265549\n",
      "Article 3100:\tLength: 51\tAvg Compression: 0.263092\n",
      "Article 3200:\tLength: 51\tAvg Compression: 0.260261\n",
      "Article 3300:\tLength: 52\tAvg Compression: 0.256735\n",
      "Article 3400:\tLength: 52\tAvg Compression: 0.256406\n",
      "Article 3500:\tLength: 53\tAvg Compression: 0.253758\n",
      "Article 3600:\tLength: 54\tAvg Compression: 0.252176\n",
      "Article 3700:\tLength: 54\tAvg Compression: 0.252648\n",
      "Article 3800:\tLength: 55\tAvg Compression: 0.252334\n",
      "Article 3900:\tLength: 56\tAvg Compression: 0.250437\n",
      "Article 4000:\tLength: 56\tAvg Compression: 0.248095\n",
      "Article 4100:\tLength: 57\tAvg Compression: 0.251230\n",
      "Article 4200:\tLength: 58\tAvg Compression: 0.249073\n",
      "Article 4300:\tLength: 59\tAvg Compression: 0.247045\n",
      "Article 4400:\tLength: 60\tAvg Compression: 0.245015\n",
      "Article 4500:\tLength: 61\tAvg Compression: 0.242199\n",
      "Article 4600:\tLength: 62\tAvg Compression: 0.241721\n",
      "Article 4700:\tLength: 63\tAvg Compression: 0.243043\n",
      "Article 4800:\tLength: 64\tAvg Compression: 0.240747\n",
      "Article 4900:\tLength: 66\tAvg Compression: 0.241925\n",
      "Article 5000:\tLength: 67\tAvg Compression: 0.244872\n",
      "Article 5100:\tLength: 69\tAvg Compression: 0.246542\n",
      "Article 5200:\tLength: 72\tAvg Compression: 0.246097\n",
      "Article 5300:\tLength: 75\tAvg Compression: 0.244434\n",
      "Article 5400:\tLength: 79\tAvg Compression: 0.241710\n",
      "Article 5500:\tLength: 83\tAvg Compression: 0.244172\n",
      "Article 5600:\tLength: 86\tAvg Compression: 0.244217\n",
      "Article 5700:\tLength: 94\tAvg Compression: 0.243298\n",
      "Article 5800:\tLength: 109\tAvg Compression: 0.242801\n",
      "Article 5900:\tLength: 192\tAvg Compression: 0.244535\n",
      "Article 6000:\tLength: 293\tAvg Compression: 0.242657\n",
      "Article 6100:\tLength: 378\tAvg Compression: 0.243398\n",
      "Article 6200:\tLength: 456\tAvg Compression: 0.240600\n",
      "Article 6300:\tLength: 517\tAvg Compression: 0.244813\n",
      "Article 6400:\tLength: 566\tAvg Compression: 0.242809\n",
      "Article 6500:\tLength: 605\tAvg Compression: 0.244289\n",
      "Article 6600:\tLength: 641\tAvg Compression: 0.241199\n",
      "Article 6700:\tLength: 729\tAvg Compression: 0.239809\n",
      "Article 6800:\tLength: 776\tAvg Compression: 0.236280\n",
      "Article 6900:\tLength: 828\tAvg Compression: 0.233554\n",
      "Article 7000:\tLength: 880\tAvg Compression: 0.233400\n",
      "Article 7100:\tLength: 935\tAvg Compression: 0.233275\n",
      "Article 7200:\tLength: 1004\tAvg Compression: 0.232034\n",
      "Article 7300:\tLength: 1055\tAvg Compression: 0.234877\n",
      "Article 7400:\tLength: 1106\tAvg Compression: 0.236454\n",
      "Article 7500:\tLength: 1160\tAvg Compression: 0.235636\n",
      "Article 7600:\tLength: 1231\tAvg Compression: 0.236310\n",
      "Article 7700:\tLength: 1306\tAvg Compression: 0.240057\n",
      "Article 7800:\tLength: 1368\tAvg Compression: 0.240868\n",
      "Article 7900:\tLength: 1441\tAvg Compression: 0.240961\n",
      "Article 8000:\tLength: 1498\tAvg Compression: 0.241860\n",
      "Article 8100:\tLength: 1568\tAvg Compression: 0.240043\n",
      "Article 8200:\tLength: 1637\tAvg Compression: 0.239584\n",
      "Article 8300:\tLength: 1677\tAvg Compression: 0.239588\n",
      "Article 8400:\tLength: 1756\tAvg Compression: 0.239872\n",
      "Article 8500:\tLength: 1826\tAvg Compression: 0.239667\n",
      "Article 8600:\tLength: 1900\tAvg Compression: 0.240003\n",
      "Article 8700:\tLength: 1971\tAvg Compression: 0.242323\n",
      "Article 8800:\tLength: 2052\tAvg Compression: 0.243738\n",
      "Article 8900:\tLength: 2139\tAvg Compression: 0.244114\n",
      "Article 9000:\tLength: 2095\tAvg Compression: 0.247189\n",
      "Article 9100:\tLength: 2228\tAvg Compression: 0.246271\n",
      "Article 9200:\tLength: 2344\tAvg Compression: 0.245447\n",
      "Article 9300:\tLength: 2364\tAvg Compression: 0.245205\n",
      "Article 9400:\tLength: 2375\tAvg Compression: 0.246066\n",
      "Article 9500:\tLength: 2463\tAvg Compression: 0.247422\n",
      "Article 9600:\tLength: 2564\tAvg Compression: 0.248377\n",
      "Article 9700:\tLength: 2729\tAvg Compression: 0.247745\n",
      "Article 9800:\tLength: 2765\tAvg Compression: 0.246796\n",
      "Article 9900:\tLength: 2895\tAvg Compression: 0.247426\n",
      "Article 10000:\tLength: 2988\tAvg Compression: 0.247355\n",
      "Article 10100:\tLength: 3033\tAvg Compression: 0.247964\n",
      "Article 10200:\tLength: 3155\tAvg Compression: 0.247141\n",
      "Article 10300:\tLength: 3210\tAvg Compression: 0.247591\n",
      "Article 10400:\tLength: 3289\tAvg Compression: 0.246758\n",
      "Article 10500:\tLength: 3414\tAvg Compression: 0.246019\n",
      "Article 10600:\tLength: 3518\tAvg Compression: 0.247175\n",
      "Article 10700:\tLength: 3614\tAvg Compression: 0.245825\n",
      "Article 10800:\tLength: 3625\tAvg Compression: 0.245171\n",
      "Article 10900:\tLength: 3753\tAvg Compression: 0.245281\n",
      "Article 11000:\tLength: 3892\tAvg Compression: 0.245930\n",
      "Article 11100:\tLength: 3965\tAvg Compression: 0.245990\n",
      "Article 11200:\tLength: 4104\tAvg Compression: 0.246813\n",
      "Article 11300:\tLength: 4163\tAvg Compression: 0.247713\n",
      "Article 11400:\tLength: 4266\tAvg Compression: 0.248374\n",
      "Article 11500:\tLength: 4337\tAvg Compression: 0.247293\n",
      "Article 11600:\tLength: 4502\tAvg Compression: 0.246548\n",
      "Article 11700:\tLength: 4625\tAvg Compression: 0.246468\n",
      "Article 11800:\tLength: 4723\tAvg Compression: 0.246754\n",
      "Article 11900:\tLength: 4790\tAvg Compression: 0.246851\n",
      "Article 12000:\tLength: 4939\tAvg Compression: 0.248528\n",
      "Article 12100:\tLength: 5056\tAvg Compression: 0.248196\n",
      "Article 12200:\tLength: 5159\tAvg Compression: 0.248141\n",
      "Article 12300:\tLength: 5294\tAvg Compression: 0.249158\n",
      "Article 12400:\tLength: 5413\tAvg Compression: 0.248360\n",
      "Article 12500:\tLength: 5606\tAvg Compression: 0.248158\n",
      "Article 12600:\tLength: 5673\tAvg Compression: 0.247576\n",
      "Article 12700:\tLength: 5872\tAvg Compression: 0.247070\n",
      "Article 12800:\tLength: 6046\tAvg Compression: 0.247140\n",
      "Article 12900:\tLength: 6212\tAvg Compression: 0.246897\n",
      "Article 13000:\tLength: 6351\tAvg Compression: 0.246765\n",
      "Article 13100:\tLength: 6476\tAvg Compression: 0.247451\n",
      "Article 13200:\tLength: 6637\tAvg Compression: 0.247997\n",
      "Article 13300:\tLength: 6795\tAvg Compression: 0.248558\n",
      "Article 13400:\tLength: 6968\tAvg Compression: 0.248318\n",
      "Article 13500:\tLength: 7124\tAvg Compression: 0.247700\n",
      "Article 13600:\tLength: 7320\tAvg Compression: 0.247990\n",
      "Article 13700:\tLength: 7508\tAvg Compression: 0.247807\n",
      "Article 13800:\tLength: 7522\tAvg Compression: 0.249010\n",
      "Article 13900:\tLength: 7839\tAvg Compression: 0.248108\n",
      "Article 14000:\tLength: 8043\tAvg Compression: 0.248735\n",
      "Article 14100:\tLength: 8200\tAvg Compression: 0.249259\n",
      "Article 14200:\tLength: 8369\tAvg Compression: 0.248839\n",
      "Article 14300:\tLength: 8573\tAvg Compression: 0.248505\n",
      "Article 14400:\tLength: 8753\tAvg Compression: 0.248773\n",
      "Article 14500:\tLength: 8984\tAvg Compression: 0.248793\n",
      "Article 14600:\tLength: 9178\tAvg Compression: 0.248449\n",
      "Article 14700:\tLength: 9411\tAvg Compression: 0.248838\n",
      "Article 14800:\tLength: 9678\tAvg Compression: 0.248368\n",
      "Article 14900:\tLength: 9895\tAvg Compression: 0.247537\n",
      "Article 15000:\tLength: 10150\tAvg Compression: 0.248244\n",
      "Article 15100:\tLength: 10324\tAvg Compression: 0.248063\n",
      "Article 15200:\tLength: 10616\tAvg Compression: 0.248093\n",
      "Article 15300:\tLength: 10909\tAvg Compression: 0.248839\n",
      "Article 15400:\tLength: 11080\tAvg Compression: 0.248466\n",
      "Article 15500:\tLength: 11179\tAvg Compression: 0.248251\n",
      "Article 15600:\tLength: 11670\tAvg Compression: 0.247778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 15700:\tLength: 11993\tAvg Compression: 0.248042\n",
      "Article 15800:\tLength: 12274\tAvg Compression: 0.247397\n",
      "Article 15900:\tLength: 12522\tAvg Compression: 0.247175\n",
      "Article 16000:\tLength: 12843\tAvg Compression: 0.246457\n",
      "Article 16100:\tLength: 13022\tAvg Compression: 0.246357\n",
      "Article 16200:\tLength: 13335\tAvg Compression: 0.246753\n",
      "Article 16300:\tLength: 13582\tAvg Compression: 0.246131\n",
      "Article 16400:\tLength: 13868\tAvg Compression: 0.246546\n",
      "Article 16500:\tLength: 14159\tAvg Compression: 0.245897\n",
      "Article 16600:\tLength: 14497\tAvg Compression: 0.245093\n",
      "Article 16700:\tLength: 14766\tAvg Compression: 0.245473\n",
      "Article 16800:\tLength: 15189\tAvg Compression: 0.245603\n",
      "Article 16900:\tLength: 15589\tAvg Compression: 0.245865\n",
      "Article 17000:\tLength: 15922\tAvg Compression: 0.245350\n",
      "Article 17100:\tLength: 16145\tAvg Compression: 0.245023\n",
      "Article 17200:\tLength: 16798\tAvg Compression: 0.244476\n",
      "Article 17300:\tLength: 17120\tAvg Compression: 0.243867\n",
      "Article 17400:\tLength: 17810\tAvg Compression: 0.244692\n",
      "Article 17500:\tLength: 18180\tAvg Compression: 0.245001\n",
      "Article 17600:\tLength: 18912\tAvg Compression: 0.245376\n",
      "Article 17700:\tLength: 19503\tAvg Compression: 0.245277\n",
      "Article 17800:\tLength: 20117\tAvg Compression: 0.245643\n",
      "Article 17900:\tLength: 20626\tAvg Compression: 0.245204\n",
      "Article 18000:\tLength: 20350\tAvg Compression: 0.244979\n",
      "Article 18100:\tLength: 22076\tAvg Compression: 0.245181\n",
      "Article 18200:\tLength: 22940\tAvg Compression: 0.245320\n",
      "Article 18300:\tLength: 23355\tAvg Compression: 0.245765\n",
      "Article 18400:\tLength: 24560\tAvg Compression: 0.245884\n",
      "Article 18500:\tLength: 25488\tAvg Compression: 0.246247\n",
      "Article 18600:\tLength: 26439\tAvg Compression: 0.246703\n",
      "Article 18700:\tLength: 27252\tAvg Compression: 0.247333\n",
      "Article 18800:\tLength: 28415\tAvg Compression: 0.247700\n",
      "Article 18900:\tLength: 29287\tAvg Compression: 0.247894\n",
      "Article 19000:\tLength: 30534\tAvg Compression: 0.248366\n",
      "Article 19100:\tLength: 32381\tAvg Compression: 0.248994\n",
      "Article 19200:\tLength: 34164\tAvg Compression: 0.248393\n",
      "Article 19300:\tLength: 35990\tAvg Compression: 0.247347\n",
      "Article 19400:\tLength: 38524\tAvg Compression: 0.247543\n",
      "Article 19500:\tLength: 41139\tAvg Compression: 0.247865\n",
      "Article 19600:\tLength: 43795\tAvg Compression: 0.248055\n",
      "Article 19700:\tLength: 47945\tAvg Compression: 0.248462\n",
      "Article 19800:\tLength: 52573\tAvg Compression: 0.248398\n",
      "Article 19900:\tLength: 61215\tAvg Compression: 0.248653\n"
     ]
    }
   ],
   "source": [
    "total_raw = 0\n",
    "total_compressed = 0\n",
    "\n",
    "huffman = Huffman(encoder.vocab_size)\n",
    "for index, encoded_article in enumerate(articles.articles_generator(1)):\n",
    "    if index % 100 == 0:\n",
    "        article = encoder.decode(encoded_article)\n",
    "        total_raw += len(article) * 8\n",
    "        total_compressed += huffman.archive_size(model, encoded_article)\n",
    "        print('Article %d:\\tLength: %d\\tAvg Compression: %f' % (index, len(article), total_compressed/total_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1902/1902 [==============================] - 1135s 597ms/step - loss: 1.4816 - average_final_batch_ratio: 0.1667\n",
      "Epoch 2/10\n",
      "1902/1902 [==============================] - 897s 472ms/step - loss: 1.7947 - average_final_batch_ratio: 0.1667\n",
      "Epoch 3/10\n",
      "1902/1902 [==============================] - 915s 481ms/step - loss: 2.0383 - average_final_batch_ratio: 0.1667\n",
      "Epoch 4/10\n",
      "1902/1902 [==============================] - 900s 473ms/step - loss: 1.9310 - average_final_batch_ratio: 0.1667\n",
      "Epoch 5/10\n",
      "1902/1902 [==============================] - 912s 480ms/step - loss: 1.8722 - average_final_batch_ratio: 0.1667\n",
      "Epoch 6/10\n",
      "1902/1902 [==============================] - 906s 476ms/step - loss: 1.8283 - average_final_batch_ratio: 0.1667\n",
      "Epoch 7/10\n",
      "1902/1902 [==============================] - 894s 470ms/step - loss: 1.8167 - average_final_batch_ratio: 0.1667\n",
      "Epoch 8/10\n",
      "1902/1902 [==============================] - 907s 477ms/step - loss: 1.7877 - average_final_batch_ratio: 0.1667\n",
      "Epoch 9/10\n",
      "1902/1902 [==============================] - 894s 470ms/step - loss: 1.7817 - average_final_batch_ratio: 0.1667\n",
      "Epoch 10/10\n",
      "1902/1902 [==============================] - 920s 484ms/step - loss: 1.7182 - average_final_batch_ratio: 0.1667\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 0:\tLength: 12\tAvg Compression: 0.260417\n",
      "Article 1000:\tLength: 38\tAvg Compression: 0.310000\n",
      "Article 2000:\tLength: 44\tAvg Compression: 0.272606\n",
      "Article 3000:\tLength: 50\tAvg Compression: 0.309896\n",
      "Article 4000:\tLength: 56\tAvg Compression: 0.316875\n",
      "Article 5000:\tLength: 67\tAvg Compression: 0.333801\n",
      "Article 6000:\tLength: 293\tAvg Compression: 0.286607\n",
      "Article 7000:\tLength: 880\tAvg Compression: 0.268316\n",
      "Article 8000:\tLength: 1498\tAvg Compression: 0.268465\n",
      "Article 9000:\tLength: 2197\tAvg Compression: 0.274221\n",
      "Article 10000:\tLength: 2988\tAvg Compression: 0.274560\n",
      "Article 11000:\tLength: 3898\tAvg Compression: 0.268447\n",
      "Article 12000:\tLength: 4954\tAvg Compression: 0.276038\n",
      "Article 13000:\tLength: 6351\tAvg Compression: 0.272255\n",
      "Article 14000:\tLength: 8043\tAvg Compression: 0.278312\n",
      "Article 15000:\tLength: 10150\tAvg Compression: 0.282560\n",
      "Article 16000:\tLength: 12843\tAvg Compression: 0.273624\n",
      "Article 17000:\tLength: 15922\tAvg Compression: 0.267840\n",
      "Article 18000:\tLength: 20350\tAvg Compression: 0.266594\n",
      "Article 19000:\tLength: 30534\tAvg Compression: 0.272704\n"
     ]
    }
   ],
   "source": [
    "total_raw = 0\n",
    "total_compressed = 0\n",
    "\n",
    "huffman = Huffman(encoder.vocab_size)\n",
    "for index, encoded_article in enumerate(articles.articles_generator(1)):\n",
    "    if index % 1000 == 0:\n",
    "        article = encoder.decode(encoded_article)\n",
    "        total_raw += len(article) * 8\n",
    "        total_compressed += huffman.archive_size(model, encoded_article)\n",
    "        print('Article %d:\\tLength: %d\\tAvg Compression: %f' % (index, len(article), total_compressed/total_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1902/1902 [==============================] - 928s 488ms/step - loss: 1.6736 - average_final_batch_ratio: 0.1667\n",
      "Epoch 2/10\n",
      "1902/1902 [==============================] - 906s 476ms/step - loss: 1.6368 - average_final_batch_ratio: 0.1667\n",
      "Epoch 3/10\n",
      "1902/1902 [==============================] - 915s 481ms/step - loss: 1.6101 - average_final_batch_ratio: 0.1667\n",
      "Epoch 4/10\n",
      "1902/1902 [==============================] - 903s 475ms/step - loss: 1.5759 - average_final_batch_ratio: 0.1667\n",
      "Epoch 5/10\n",
      "1902/1902 [==============================] - 899s 473ms/step - loss: 1.5477 - average_final_batch_ratio: 0.1667\n",
      "Epoch 6/10\n",
      "1902/1902 [==============================] - 900s 473ms/step - loss: 1.5244 - average_final_batch_ratio: 0.1667\n",
      "Epoch 7/10\n",
      "1902/1902 [==============================] - 900s 473ms/step - loss: 1.5032 - average_final_batch_ratio: 0.1667\n",
      "Epoch 8/10\n",
      "1902/1902 [==============================] - 911s 479ms/step - loss: 1.4877 - average_final_batch_ratio: 0.1667\n",
      "Epoch 9/10\n",
      "1902/1902 [==============================] - 892s 469ms/step - loss: 1.4755 - average_final_batch_ratio: 0.1667\n",
      "Epoch 10/10\n",
      "1902/1902 [==============================] - 938s 493ms/step - loss: 1.4580 - average_final_batch_ratio: 0.1667\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 0:\tLength: 12\tAvg Compression: 0.260417\n",
      "Article 1000:\tLength: 38\tAvg Compression: 0.272500\n",
      "Article 2000:\tLength: 44\tAvg Compression: 0.242021\n",
      "Article 3000:\tLength: 50\tAvg Compression: 0.261285\n",
      "Article 4000:\tLength: 56\tAvg Compression: 0.263125\n",
      "Article 5000:\tLength: 67\tAvg Compression: 0.277154\n",
      "Article 6000:\tLength: 293\tAvg Compression: 0.241518\n",
      "Article 7000:\tLength: 880\tAvg Compression: 0.235851\n",
      "Article 8000:\tLength: 1498\tAvg Compression: 0.240853\n",
      "Article 9000:\tLength: 2197\tAvg Compression: 0.242040\n",
      "Article 10000:\tLength: 2988\tAvg Compression: 0.240567\n",
      "Article 11000:\tLength: 3898\tAvg Compression: 0.229463\n",
      "Article 12000:\tLength: 4954\tAvg Compression: 0.236811\n",
      "Article 13000:\tLength: 6351\tAvg Compression: 0.235563\n",
      "Article 14000:\tLength: 8043\tAvg Compression: 0.240927\n",
      "Article 15000:\tLength: 10150\tAvg Compression: 0.244400\n",
      "Article 16000:\tLength: 12843\tAvg Compression: 0.237013\n",
      "Article 17000:\tLength: 15922\tAvg Compression: 0.231153\n",
      "Article 18000:\tLength: 20350\tAvg Compression: 0.229122\n",
      "Article 19000:\tLength: 30534\tAvg Compression: 0.233256\n"
     ]
    }
   ],
   "source": [
    "total_raw = 0\n",
    "total_compressed = 0\n",
    "\n",
    "huffman = Huffman(encoder.vocab_size)\n",
    "for index, encoded_article in enumerate(articles.articles_generator(1)):\n",
    "    if index % 1000 == 0:\n",
    "        article = encoder.decode(encoded_article)\n",
    "        total_raw += len(article) * 8\n",
    "        total_compressed += huffman.archive_size(model, encoded_article)\n",
    "        print('Article %d:\\tLength: %d\\tAvg Compression: %f' % (index, len(article), total_compressed/total_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Да опитаме да тренираме върху целия набор от данни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE=np.int16\n",
    "\n",
    "class Articles:\n",
    "    EMPTY_ARTICLE = np.array([], dtype=TYPE) # used for padding\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        with open(path, 'rb') as text_file:\n",
    "            data = text_file.read().decode()\n",
    "\n",
    "        self.articles = sorted(set(data.split('\\0')), key=len)\n",
    "        self._encoded_articles = None\n",
    "\n",
    "    @property\n",
    "    def encoded_articles(self):\n",
    "        if self._encoded_articles == None:\n",
    "            self._encoded_articles = [np.array(encoder.encode(article), dtype=TYPE) for article in self.articles]\n",
    "        \n",
    "        return self._encoded_articles\n",
    "\n",
    "    def articles_generator(self, batch_size = 1, start = 0, end = None):\n",
    "        end = end or len(self.articles)\n",
    "\n",
    "        for _ in range(batch_size - ((end - start - 1) % batch_size + 1)):\n",
    "            yield self.EMPTY_ARTICLE\n",
    "\n",
    "        for article in itertools.islice(self.encoded_articles, start, end):\n",
    "            yield article\n",
    "\n",
    "    def subbatch_generator(self, batch_size, batch_length, start = 0, end = None):\n",
    "        end = end or len(self.articles)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(self.articles_generator, args=(batch_size, start, end), output_types=TYPE)\n",
    "        dataset = dataset.padded_batch(batch_size, padded_shapes=([None]), drop_remainder=True)\n",
    "        dataset = dataset.shuffle(100)\n",
    "\n",
    "        for batch in dataset.as_numpy_iterator():\n",
    "            remaining = batch\n",
    "            while remaining.shape[1] > batch_length + 1:\n",
    "                yield remaining[:, :batch_length + 1]\n",
    "                remaining = remaining[:, batch_length:]\n",
    "\n",
    "            if remaining.shape[1] == batch_length + 1:\n",
    "                yield remaining\n",
    "                yield np.zeros((batch_size, batch_length + 1), dtype=TYPE)\n",
    "            else:\n",
    "                yield np.hstack([remaining, np.zeros([batch_size, batch_length - remaining.shape[1] + 1])])\n",
    "\n",
    "    def steps(self, batch_size, batch_length):\n",
    "        articles = self.articles_generator(batch_size, batch_length)\n",
    "        return sum(math.ceil(len(article) / batch_length + 1) for i, article in enumerate(articles) if (i + 1) % batch_size == 0)\n",
    "\n",
    "    def dataset(self, batch_size, batch_length, start = 0, end = None):\n",
    "        end = end or len(self.articles)\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(self.subbatch_generator, args=(batch_size, batch_length, start, end), output_types=TYPE, output_shapes=(batch_size, batch_length + 1))\n",
    "        return dataset.map(lambda batch: (batch[:, :-1], batch[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = Articles('page_revisions_text_with_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(articles, './training_checkpoints-27', vocab_size = encoder.vocab_size, embedding_dim=128, rnn_units=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_7 (Masking)          (256, 256)                0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (256, 256, 128)           32640     \n",
      "_________________________________________________________________\n",
      "gru_28 (GRU)                 (256, 256, 512)           986112    \n",
      "_________________________________________________________________\n",
      "gru_29 (GRU)                 (256, 256, 512)           1575936   \n",
      "_________________________________________________________________\n",
      "gru_30 (GRU)                 (256, 256, 512)           1575936   \n",
      "_________________________________________________________________\n",
      "gru_31 (GRU)                 (256, 256, 512)           1575936   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (256, 256, 255)           130815    \n",
      "=================================================================\n",
      "Total params: 5,877,375\n",
      "Trainable params: 5,877,375\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.training_model(256, 256).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.kernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "12370/12370 [==============================] - 7398s 598ms/step - loss: 1.4139 - average_final_batch_ratio: 0.2623\n",
      "Epoch 2/50\n",
      "12370/12370 [==============================] - 5828s 471ms/step - loss: 1.1572 - average_final_batch_ratio: 0.2623\n",
      "Epoch 3/50\n",
      "12370/12370 [==============================] - 5917s 478ms/step - loss: 1.1314 - average_final_batch_ratio: 0.2623\n",
      "Epoch 4/50\n",
      "12370/12370 [==============================] - 5916s 478ms/step - loss: 1.1127 - average_final_batch_ratio: 0.2623\n",
      "Epoch 5/50\n",
      "12370/12370 [==============================] - 5952s 481ms/step - loss: 1.1721 - average_final_batch_ratio: 0.2623\n",
      "Epoch 6/50\n",
      "12370/12370 [==============================] - 6054s 489ms/step - loss: nan - average_final_batch_ratio: 0.2623\n",
      "Epoch 7/50\n",
      " 4170/12370 [=========>....................] - ETA: 1:01:32 - loss: nan - average_final_batch_ratio: 0.3608"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-336b783c7953>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-a6e046f60951>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, batch_size, batched_item_length, epochs)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched_item_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\joank_000\\desktop\\rnn-enwik-predictor\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(256, 256, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... не се получава.\n",
    "\n",
    "# Да опитаме с по-различни слоеве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "def average_final_batch_ratio(true_labels, predictions):\n",
    "    return 0 ** tf.math.abs(true_labels[-1, -1])\n",
    "\n",
    "class ModelStateResetter(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.last_final_batch_count = 0\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        average_final_batch_ratio = logs.get('average_final_batch_ratio', 0)\n",
    "        final_batch_count = int(round(average_final_batch_ratio * (batch + 1)))\n",
    "        is_final = final_batch_count - self.last_final_batch_count\n",
    "        self.last_final_batch_count = final_batch_count\n",
    "        \n",
    "        if is_final:\n",
    "            self.model.reset_states()\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, articles, checkpoint_dir, vocab_size, embedding_dim, rnn_units):\n",
    "        self._articles = articles\n",
    "        self._batch_size = None\n",
    "        self._batched_item_length = None\n",
    "        self._training_model = None\n",
    "        self._predicting_model = None\n",
    "        self._vocab_size = vocab_size\n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._rnn_units = rnn_units\n",
    "\n",
    "        self._checkpoint_dir = checkpoint_dir\n",
    "        self._checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\") # Name of the checkpoint files\n",
    "\n",
    "    def training_model(self, batch_size, batched_item_length):\n",
    "        if self._training_model == None or batch_size != self._batch_size or batched_item_length != self._batched_item_length:\n",
    "            self._batch_size = batch_size\n",
    "            self._batched_item_length = batched_item_length\n",
    "            self._training_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Masking(mask_value=0, batch_input_shape=[batch_size, batched_item_length]),\n",
    "                tf.keras.layers.Embedding(self._vocab_size, self._embedding_dim),\n",
    "                tf.keras.layers.GRU(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.GRU(self._rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
    "                tf.keras.layers.Dense(self._vocab_size),\n",
    "            ])\n",
    "\n",
    "            if os.path.isdir(self._checkpoint_dir):\n",
    "                self._training_model.load_weights(tf.train.latest_checkpoint(self._checkpoint_dir))\n",
    "\n",
    "            self._training_model.compile(optimizer='adam', loss=loss, metrics=[average_final_batch_ratio])\n",
    "            self._predicting_model = None\n",
    "        \n",
    "        return self._training_model\n",
    "\n",
    "    @property\n",
    "    def callbacks(self):\n",
    "        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=self._checkpoint_prefix, save_weights_only=True)\n",
    "        model_state_resetter_callback = ModelStateResetter()\n",
    "        \n",
    "        return [checkpoint_callback, model_state_resetter_callback]\n",
    "    \n",
    "    def train(self, batch_size, batched_item_length, epochs=1):\n",
    "        dataset = self._articles.dataset(batch_size, batched_item_length)\n",
    "\n",
    "        model = self.training_model(batch_size, batched_item_length)\n",
    "\n",
    "        model.fit(dataset, epochs=epochs, callbacks=self.callbacks)\n",
    "    \n",
    "    @property\n",
    "    def predicting_model(self):\n",
    "        if self._predicting_model == None:\n",
    "            self._predicting_model = tf.keras.Sequential([\n",
    "                tf.keras.layers.Masking(mask_value=0, batch_input_shape=[1, 1]),\n",
    "                tf.keras.layers.Embedding(self._vocab_size, self._embedding_dim),\n",
    "                tf.keras.layers.GRU(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.GRU(self._rnn_units, stateful=True, return_sequences=True),\n",
    "                tf.keras.layers.Dense(self._vocab_size),\n",
    "            ])\n",
    "            \n",
    "            self._predicting_model.load_weights(tf.train.latest_checkpoint(self._checkpoint_dir))\n",
    "            self._training_model = None\n",
    "        \n",
    "        return self._predicting_model\n",
    "    \n",
    "    def predict(self, input_eval):\n",
    "        return self.predicting_model(input_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(articles, './training_checkpoints-28', vocab_size = encoder.vocab_size, embedding_dim=128, rnn_units=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (256, 192)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (256, 192, 128)           32640     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (256, 192, 1024)          3545088   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (256, 192, 1024)          6297600   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (256, 192, 255)           261375    \n",
      "=================================================================\n",
      "Total params: 10,136,703\n",
      "Trainable params: 10,136,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.training_model(256, 192).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2518/2518 [==============================] - 1538s 611ms/step - loss: 1.9422 - average_final_batch_ratio: 0.1517\n",
      "Epoch 2/10\n",
      "2518/2518 [==============================] - 1309s 520ms/step - loss: 1.4509 - average_final_batch_ratio: 0.1517\n",
      "Epoch 3/10\n",
      "2518/2518 [==============================] - 1311s 521ms/step - loss: 1.3645 - average_final_batch_ratio: 0.1517\n",
      "Epoch 4/10\n",
      "2518/2518 [==============================] - 1299s 516ms/step - loss: 1.3250 - average_final_batch_ratio: 0.1517\n",
      "Epoch 5/10\n",
      "2518/2518 [==============================] - 1315s 522ms/step - loss: 1.2911 - average_final_batch_ratio: 0.1517\n",
      "Epoch 6/10\n",
      "2518/2518 [==============================] - 1304s 518ms/step - loss: 1.2766 - average_final_batch_ratio: 0.1517\n",
      "Epoch 7/10\n",
      "2518/2518 [==============================] - 1305s 518ms/step - loss: 1.2553 - average_final_batch_ratio: 0.1517\n",
      "Epoch 8/10\n",
      "2518/2518 [==============================] - 1295s 514ms/step - loss: 1.2448 - average_final_batch_ratio: 0.1517\n",
      "Epoch 9/10\n",
      "2518/2518 [==============================] - 1295s 514ms/step - loss: 1.2364 - average_final_batch_ratio: 0.1517\n",
      "Epoch 10/10\n",
      "2518/2518 [==============================] - 1304s 518ms/step - loss: 1.2288 - average_final_batch_ratio: 0.1517\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 192, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 0:\tLength: 12\tAvg Compression: 0.250000\n",
      "Article 1000:\tLength: 38\tAvg Compression: 0.202500\n",
      "Article 2000:\tLength: 44\tAvg Compression: 0.166223\n",
      "Article 3000:\tLength: 50\tAvg Compression: 0.161458\n",
      "Article 4000:\tLength: 56\tAvg Compression: 0.155000\n",
      "Article 5000:\tLength: 67\tAvg Compression: 0.173221\n",
      "Article 6000:\tLength: 293\tAvg Compression: 0.180580\n",
      "Article 7000:\tLength: 880\tAvg Compression: 0.190799\n",
      "Article 8000:\tLength: 1498\tAvg Compression: 0.206390\n",
      "Article 9000:\tLength: 2197\tAvg Compression: 0.208909\n",
      "Article 10000:\tLength: 2988\tAvg Compression: 0.204697\n",
      "Article 11000:\tLength: 3892\tAvg Compression: 0.211496\n",
      "Article 12000:\tLength: 4954\tAvg Compression: 0.216807\n",
      "Article 13000:\tLength: 6351\tAvg Compression: 0.215727\n",
      "Article 14000:\tLength: 8043\tAvg Compression: 0.221196\n",
      "Article 15000:\tLength: 10150\tAvg Compression: 0.227567\n",
      "Article 16000:\tLength: 12843\tAvg Compression: 0.217745\n",
      "Article 17000:\tLength: 15922\tAvg Compression: 0.208246\n",
      "Article 18000:\tLength: 20350\tAvg Compression: 0.205666\n",
      "Article 19000:\tLength: 30534\tAvg Compression: 0.206491\n"
     ]
    }
   ],
   "source": [
    "total_raw = 0\n",
    "total_compressed = 0\n",
    "\n",
    "huffman = Huffman(encoder.vocab_size)\n",
    "for index, encoded_article in enumerate(articles.articles_generator(1)):\n",
    "    if index % 1000 == 0:\n",
    "        article = encoder.decode(encoded_article)\n",
    "        total_raw += len(article) * 8\n",
    "        total_compressed += huffman.archive_size(model, encoded_article)\n",
    "        print('Article %d:\\tLength: %d\\tAvg Compression: %f' % (index, len(article), total_compressed/total_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2518/2518 [==============================] - 1291s 513ms/step - loss: 1.2206 - average_final_batch_ratio: 0.1517\n",
      "Epoch 2/10\n",
      "2518/2518 [==============================] - 1299s 516ms/step - loss: 1.2137 - average_final_batch_ratio: 0.1517\n",
      "Epoch 3/10\n",
      "2518/2518 [==============================] - 1286s 511ms/step - loss: 1.2112 - average_final_batch_ratio: 0.1517\n",
      "Epoch 4/10\n",
      "2518/2518 [==============================] - 1291s 513ms/step - loss: 1.2047 - average_final_batch_ratio: 0.1517\n",
      "Epoch 5/10\n",
      "2518/2518 [==============================] - 1283s 510ms/step - loss: 1.2017 - average_final_batch_ratio: 0.1517\n",
      "Epoch 6/10\n",
      "2518/2518 [==============================] - 1294s 514ms/step - loss: 1.2009 - average_final_batch_ratio: 0.1517\n",
      "Epoch 7/10\n",
      "2518/2518 [==============================] - 1294s 514ms/step - loss: 1.1919 - average_final_batch_ratio: 0.1517\n",
      "Epoch 8/10\n",
      "2518/2518 [==============================] - 1291s 513ms/step - loss: 1.1944 - average_final_batch_ratio: 0.1517\n",
      "Epoch 9/10\n",
      "2518/2518 [==============================] - 1298s 516ms/step - loss: 1.1886 - average_final_batch_ratio: 0.1517\n",
      "Epoch 10/10\n",
      "2518/2518 [==============================] - 1288s 512ms/step - loss: 1.1896 - average_final_batch_ratio: 0.1517\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 192, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 0:\tLength: 12\tAvg Compression: 0.239583\n",
      "Article 1000:\tLength: 38\tAvg Compression: 0.180000\n",
      "Article 2000:\tLength: 44\tAvg Compression: 0.156915\n",
      "Article 3000:\tLength: 50\tAvg Compression: 0.151910\n",
      "Article 4000:\tLength: 56\tAvg Compression: 0.143750\n",
      "Article 5000:\tLength: 67\tAvg Compression: 0.159176\n",
      "Article 6000:\tLength: 293\tAvg Compression: 0.176339\n",
      "Article 7000:\tLength: 880\tAvg Compression: 0.182118\n",
      "Article 8000:\tLength: 1498\tAvg Compression: 0.197626\n",
      "Article 9000:\tLength: 2197\tAvg Compression: 0.200730\n",
      "Article 10000:\tLength: 2988\tAvg Compression: 0.200465\n",
      "Article 11000:\tLength: 3892\tAvg Compression: 0.208448\n",
      "Article 12000:\tLength: 4954\tAvg Compression: 0.211739\n",
      "Article 13000:\tLength: 6351\tAvg Compression: 0.210045\n",
      "Article 14000:\tLength: 8043\tAvg Compression: 0.215214\n",
      "Article 15000:\tLength: 10150\tAvg Compression: 0.222105\n",
      "Article 16000:\tLength: 12843\tAvg Compression: 0.213049\n",
      "Article 17000:\tLength: 15922\tAvg Compression: 0.204296\n",
      "Article 18000:\tLength: 20350\tAvg Compression: 0.199842\n",
      "Article 19000:\tLength: 30534\tAvg Compression: 0.200226\n"
     ]
    }
   ],
   "source": [
    "total_raw = 0\n",
    "total_compressed = 0\n",
    "\n",
    "huffman = Huffman(encoder.vocab_size)\n",
    "for index, encoded_article in enumerate(articles.articles_generator(1)):\n",
    "    if index % 1000 == 0:\n",
    "        article = encoder.decode(encoded_article)\n",
    "        total_raw += len(article) * 8\n",
    "        total_compressed += huffman.archive_size(model, encoded_article)\n",
    "        print('Article %d:\\tLength: %d\\tAvg Compression: %f' % (index, len(article), total_compressed/total_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2518/2518 [==============================] - 1309s 520ms/step - loss: 1.1853 - average_final_batch_ratio: 0.1517\n",
      "Epoch 2/10\n",
      "2518/2518 [==============================] - 1293s 514ms/step - loss: 1.1845 - average_final_batch_ratio: 0.1517\n",
      "Epoch 3/10\n",
      "2518/2518 [==============================] - 1291s 513ms/step - loss: 1.1890 - average_final_batch_ratio: 0.1517\n",
      "Epoch 4/10\n",
      "2518/2518 [==============================] - 1299s 516ms/step - loss: 1.1765 - average_final_batch_ratio: 0.1517\n",
      "Epoch 5/10\n",
      "2518/2518 [==============================] - 1289s 512ms/step - loss: 1.1698 - average_final_batch_ratio: 0.1517\n",
      "Epoch 6/10\n",
      "2518/2518 [==============================] - 1292s 513ms/step - loss: 1.1719 - average_final_batch_ratio: 0.1517\n",
      "Epoch 7/10\n",
      "2518/2518 [==============================] - 1286s 511ms/step - loss: 1.1703 - average_final_batch_ratio: 0.1517\n",
      "Epoch 8/10\n",
      "2518/2518 [==============================] - 1299s 516ms/step - loss: 1.1699 - average_final_batch_ratio: 0.1517\n",
      "Epoch 9/10\n",
      "2518/2518 [==============================] - 1297s 515ms/step - loss: 1.1693 - average_final_batch_ratio: 0.1517\n",
      "Epoch 10/10\n",
      "2518/2518 [==============================] - 1288s 512ms/step - loss: 1.1686 - average_final_batch_ratio: 0.1517\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 192, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 0:\tLength: 12\tAvg Compression: 0.250000\n",
      "Article 1000:\tLength: 38\tAvg Compression: 0.215000\n",
      "Article 2000:\tLength: 44\tAvg Compression: 0.180851\n",
      "Article 3000:\tLength: 50\tAvg Compression: 0.167535\n",
      "Article 4000:\tLength: 56\tAvg Compression: 0.159375\n",
      "Article 5000:\tLength: 67\tAvg Compression: 0.179307\n",
      "Article 6000:\tLength: 293\tAvg Compression: 0.186161\n",
      "Article 7000:\tLength: 880\tAvg Compression: 0.190278\n",
      "Article 8000:\tLength: 1498\tAvg Compression: 0.200774\n",
      "Article 9000:\tLength: 2197\tAvg Compression: 0.198174\n",
      "Article 10000:\tLength: 2988\tAvg Compression: 0.195356\n",
      "Article 11000:\tLength: 3892\tAvg Compression: 0.204224\n",
      "Article 12000:\tLength: 4954\tAvg Compression: 0.208778\n",
      "Article 13000:\tLength: 6351\tAvg Compression: 0.206196\n",
      "Article 14000:\tLength: 8043\tAvg Compression: 0.211591\n",
      "Article 15000:\tLength: 10150\tAvg Compression: 0.216429\n",
      "Article 16000:\tLength: 12843\tAvg Compression: 0.207696\n",
      "Article 17000:\tLength: 15922\tAvg Compression: 0.198601\n",
      "Article 18000:\tLength: 20350\tAvg Compression: 0.196571\n",
      "Article 19000:\tLength: 30534\tAvg Compression: 0.197996\n"
     ]
    }
   ],
   "source": [
    "total_raw = 0\n",
    "total_compressed = 0\n",
    "\n",
    "huffman = Huffman(encoder.vocab_size)\n",
    "for index, encoded_article in enumerate(articles.articles_generator(1)):\n",
    "    if index % 1000 == 0:\n",
    "        article = encoder.decode(encoded_article)\n",
    "        total_raw += len(article) * 8\n",
    "        total_compressed += huffman.archive_size(model, encoded_article)\n",
    "        print('Article %d:\\tLength: %d\\tAvg Compression: %f' % (index, len(article), total_compressed/total_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "2518/2518 [==============================] - 1304s 518ms/step - loss: 1.1744 - average_final_batch_ratio: 0.1517\n",
      "Epoch 2/10\n",
      "2518/2518 [==============================] - 1307s 519ms/step - loss: 1.1705 - average_final_batch_ratio: 0.1517\n",
      "Epoch 3/10\n",
      "2518/2518 [==============================] - 1296s 515ms/step - loss: 1.1676 - average_final_batch_ratio: 0.1517\n",
      "Epoch 4/10\n",
      "2518/2518 [==============================] - 1300s 516ms/step - loss: 1.1664 - average_final_batch_ratio: 0.1517\n",
      "Epoch 5/10\n",
      "2518/2518 [==============================] - 1289s 512ms/step - loss: 1.1691 - average_final_batch_ratio: 0.1517\n",
      "Epoch 6/10\n",
      "2518/2518 [==============================] - 1311s 521ms/step - loss: 1.1658 - average_final_batch_ratio: 0.1517\n",
      "Epoch 7/10\n",
      "2518/2518 [==============================] - 1291s 513ms/step - loss: 1.2481 - average_final_batch_ratio: 0.1517\n",
      "Epoch 8/10\n",
      "2518/2518 [==============================] - 1325s 526ms/step - loss: 1.1746 - average_final_batch_ratio: 0.1517\n",
      "Epoch 9/10\n",
      "2518/2518 [==============================] - 1313s 521ms/step - loss: 1.1594 - average_final_batch_ratio: 0.1517\n",
      "Epoch 10/10\n",
      "2518/2518 [==============================] - 1330s 528ms/step - loss: 1.1584 - average_final_batch_ratio: 0.1517\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 192, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 0:\tLength: 12\tAvg Compression: 0.229167\n",
      "Article 1000:\tLength: 38\tAvg Compression: 0.180000\n",
      "Article 2000:\tLength: 44\tAvg Compression: 0.162234\n",
      "Article 3000:\tLength: 50\tAvg Compression: 0.158854\n",
      "Article 4000:\tLength: 56\tAvg Compression: 0.151875\n",
      "Article 5000:\tLength: 67\tAvg Compression: 0.170412\n",
      "Article 6000:\tLength: 293\tAvg Compression: 0.180580\n",
      "Article 7000:\tLength: 880\tAvg Compression: 0.185764\n",
      "Article 8000:\tLength: 1498\tAvg Compression: 0.194733\n",
      "Article 9000:\tLength: 2197\tAvg Compression: 0.194085\n",
      "Article 10000:\tLength: 2988\tAvg Compression: 0.193155\n",
      "Article 11000:\tLength: 3892\tAvg Compression: 0.201332\n",
      "Article 12000:\tLength: 4954\tAvg Compression: 0.205529\n",
      "Article 13000:\tLength: 6351\tAvg Compression: 0.203366\n",
      "Article 14000:\tLength: 8043\tAvg Compression: 0.209618\n",
      "Article 15000:\tLength: 10150\tAvg Compression: 0.214728\n",
      "Article 16000:\tLength: 12843\tAvg Compression: 0.206700\n",
      "Article 17000:\tLength: 15922\tAvg Compression: 0.197307\n",
      "Article 18000:\tLength: 20350\tAvg Compression: 0.193156\n",
      "Article 19000:\tLength: 30534\tAvg Compression: 0.193438\n"
     ]
    }
   ],
   "source": [
    "total_raw = 0\n",
    "total_compressed = 0\n",
    "\n",
    "huffman = Huffman(encoder.vocab_size)\n",
    "for index, encoded_article in enumerate(articles.articles_generator(1)):\n",
    "    if index % 1000 == 0:\n",
    "        article = encoder.decode(encoded_article)\n",
    "        total_raw += len(article) * 8\n",
    "        total_compressed += huffman.archive_size(model, encoded_article)\n",
    "        print('Article %d:\\tLength: %d\\tAvg Compression: %f' % (index, len(article), total_compressed/total_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2518/2518 [==============================] - 1330s 528ms/step - loss: 1.1618 - average_final_batch_ratio: 0.1517\n",
      "Epoch 2/5\n",
      "2518/2518 [==============================] - 1332s 529ms/step - loss: 1.1628 - average_final_batch_ratio: 0.1517\n",
      "Epoch 3/5\n",
      "2518/2518 [==============================] - 1326s 527ms/step - loss: 1.1652 - average_final_batch_ratio: 0.1517\n",
      "Epoch 4/5\n",
      "2518/2518 [==============================] - 1339s 532ms/step - loss: 1.1603 - average_final_batch_ratio: 0.1517\n",
      "Epoch 5/5\n",
      "2518/2518 [==============================] - 1336s 531ms/step - loss: 1.1621 - average_final_batch_ratio: 0.1517\n"
     ]
    }
   ],
   "source": [
    "model.train(256, 192, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
